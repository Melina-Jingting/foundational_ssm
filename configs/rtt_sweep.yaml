# Wandb sweep configuration
program: scripts/downstream_mc_rtt.py
method: bayes
metric:
  name: final/best_r2
  goal: maximize
run_cap: 30  # Limit total number of runs
early_terminate:
  type: hyperband
  min_iter: 10
parameters:
  optimizer.mode:
    values: [all]
  model.ssm_dim:
    values: [32]
  model.ssm_io_dim:
    values: [256]
  model.ssm_num_layers:
    values: [4]
  optimizer.lr:
    distribution: log_uniform_values
    min: 0.0005
    max: 0.01
  model.dropout_p:
    distribution: uniform
    min: 0.0
    max: 0.1
  model.ssm_dropout_p:
    distribution: uniform
    min: 0.0
    max: 0.1
  optimizer.weight_decay:
    distribution: uniform
    min: 0.0
    max: 0.1

# Fixed parameters (not swept)
wandb:
  project: foundational_ssm_rtt_sweep
  tags: [neural, behavior, downstream, decoding, sweep]
  entity: melinajingting-ucl
  run_prefix: sweep_rtt

dataset:
  rtt_trial: /cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_not_trialized_train.h5

model:
  input_dim: 130
  ssm_init_diag_blocks: 4
  output_dim: 2
  rng_seed: 42
  dt_min: 0.001
  dt_max: 0.05

training:
  epochs: 500  # Reduced for sweep
  checkpoint_every: 50
  log_val_every: 25
  log_pred_and_activations_every: 999

downstream_modes:
  scratch:
    from_scratch: true

rng_seed: 42
device: cuda