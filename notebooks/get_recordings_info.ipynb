{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4656a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "# Foundational SSM core imports\n",
    "from foundational_ssm.loaders import get_brainset_data_loader\n",
    "from foundational_ssm.constants import DATA_ROOT\n",
    "from foundational_ssm.samplers import TrialSampler\n",
    "import os \n",
    "import equinox as eqx\n",
    "\n",
    "\n",
    "data_root = '../' + DATA_ROOT # change to the folder holding the brainsets\n",
    "config_dir = '../configs/dataset' # change\n",
    "dataset_args = {\n",
    "    'keep_files_open': False,\n",
    "    'lazy': True,\n",
    "    'split': 'train', # or 'train' \n",
    "}\n",
    "dataloader_args = {\n",
    "    'batch_size': 128, # Adjust per your system capacity\n",
    "    'num_workers': 10,\n",
    "    'persistent_workers': True\n",
    "}\n",
    "sampler = 'SequentialFixedWindowSampler'\n",
    "sampler_args = { \n",
    "                'window_length': 3.280,\n",
    "                'drop_short': False,\n",
    "                'min_window_length': 0.88\n",
    "                }\n",
    "\n",
    "dataset, data_loader, max_neural_input = get_brainset_data_loader(\n",
    "    dataset_args=dataset_args,\n",
    "    sampler = sampler,\n",
    "    sampler_args = sampler_args,\n",
    "    dataloader_args = dataloader_args,\n",
    "    sampling_rate = 200,\n",
    "    dataset_cfg = os.path.join(config_dir, 'pm_t.yaml'),\n",
    "    data_root = data_root\n",
    ")\n",
    "\n",
    "sessions = dataset.get_session_ids() # list of sessions in your dataset\n",
    "sampling_intervals = dataset.get_sampling_intervals() # list of sampling intervals for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e37ce014",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_neural_ids = []\n",
    "for session, interval in sampling_intervals.items():\n",
    "    for start, end in zip(interval.start, interval.end):\n",
    "        sample = dataset.get_recording_data(session).slice(start,end)\n",
    "        neural_input = sample.spikes.unit_index\n",
    "        max_neural_ids.append(neural_input.max())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d1f09a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(54),\n",
       " np.int64(53),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(63),\n",
       " np.int64(63),\n",
       " np.int64(63),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(44),\n",
       " np.int64(35),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(72),\n",
       " np.int64(72),\n",
       " np.int64(72),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(64),\n",
       " np.int64(52),\n",
       " np.int64(52),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(58),\n",
       " np.int64(68),\n",
       " np.int64(68)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_neural_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5099094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_890596/2353987421.py:12: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  batch = {k: jax.device_put(np.array(v)) for k, v in batch.items()}\n",
      "19it [00:01, 12.13it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{10: {'variance': Array([0.99999994, 0.99999994], dtype=float32)},\n",
       " 11: {'variance': Array([1., 1.], dtype=float32)}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp \n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "\n",
    "metrics = {}  # New: store metrics per group\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_dataset_group_idxs = []\n",
    "max_neural_input = []\n",
    "\n",
    "for batch_idx, batch in tqdm(enumerate(data_loader)):\n",
    "    batch = {k: jax.device_put(np.array(v)) for k, v in batch.items()}\n",
    "    dataset_group_idxs = batch[\"dataset_group_idx\"]\n",
    "    inputs = batch[\"neural_input\"]\n",
    "    targets = batch[\"behavior_input\"]\n",
    "\n",
    "    all_targets.append(targets)\n",
    "    all_dataset_group_idxs.append(dataset_group_idxs)\n",
    "    max_neural_input.append(inputs.shape[-2])\n",
    "all_targets = jnp.concatenate(all_targets, axis=0)\n",
    "all_dataset_group_idxs = jnp.concatenate(all_dataset_group_idxs, axis=0)\n",
    "\n",
    "for group_idx in tqdm(jnp.unique(all_dataset_group_idxs)):\n",
    "    group_targets = all_targets[all_dataset_group_idxs == group_idx]\n",
    "    variance = jnp.var(group_targets.reshape(-1, 2), axis=0)\n",
    "    metrics[int(group_idx)] = {\n",
    "        \"variance\": variance\n",
    "    }\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da394f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28menumerate\u001b[39m(data_loader)):\n\u001b[32m      2\u001b[39m     batch = {k: jax.device_put(np.array(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch.items()}\n\u001b[32m      3\u001b[39m     dataset_group_idxs = batch[\u001b[33m\"\u001b[39m\u001b[33mdataset_group_idx\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in tqdm(enumerate(data_loader)):\n",
    "    batch = {k: jax.device_put(np.array(v)) for k, v in batch.items()}\n",
    "    dataset_group_idxs = batch[\"dataset_group_idx\"]\n",
    "    inputs = batch[\"neural_input\"]\n",
    "    targets = batch[\"behavior_input\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544b98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8142d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
