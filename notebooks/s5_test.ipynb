{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c168df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, default_collate\n",
    "from jax.tree_util import tree_map\n",
    "\n",
    "\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "from foundational_ssm.models import S4DNeuroModel, S5\n",
    "from foundational_ssm.utils import h5_to_dict, generate_and_save_activations_wandb\n",
    "from foundational_ssm.trainer import train_decoding\n",
    "from foundational_ssm.data_preprocessing import smooth_spikes\n",
    "\n",
    "\n",
    "# ========== Helper Functions, will be moved to utils.py ==========\n",
    "def numpy_collate(batch):\n",
    "  \"\"\"\n",
    "  Collate function specifies how to combine a list of data samples into a batch.\n",
    "  default_collate creates pytorch tensors, then tree_map converts them into numpy arrays.\n",
    "  \"\"\"\n",
    "  return tree_map(np.asarray, default_collate(batch))\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "processed_data_folder = '/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb' \n",
    "dataset_name = \"mc_maze\"\n",
    "processed_data_path = os.path.join(processed_data_folder,dataset_name + \".h5\")\n",
    "trial_info_path = os.path.join(processed_data_folder,dataset_name + \".csv\")\n",
    "\n",
    "conf = {\n",
    "    'task':'decoding',\n",
    "    'dataset': {\n",
    "        'dataset': dataset_name\n",
    "    },\n",
    "    'model': {\n",
    "        'input_dim': 182,\n",
    "        'output_dim': 2,\n",
    "        'd_state': 64,\n",
    "        'num_layers': 2,\n",
    "        'hidden_dim': 64,\n",
    "        'dropout': 0.1,\n",
    "        'ssm_core':'s5'\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'lr': 0.0005,\n",
    "        'weight_decay': 0.01  # Added common parameter\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 64,\n",
    "        'epochs': 2000\n",
    "    },\n",
    "    'device': 'cuda',\n",
    "    'framework': 'jax'\n",
    "}\n",
    "\n",
    "args = OmegaConf.create(conf)\n",
    "\n",
    "with h5py.File(processed_data_path, 'r') as h5file:\n",
    "    dataset_dict = h5_to_dict(h5file)\n",
    "\n",
    "trial_info = pd.read_csv(trial_info_path)\n",
    "trial_info = trial_info[trial_info['split'].isin(['train','val'])]\n",
    "min_idx = trial_info['trial_id'].min()\n",
    "trial_info['trial_id'] = trial_info['trial_id'] - min_idx\n",
    "\n",
    "train_ids = trial_info[trial_info['split']=='train']['trial_id'].tolist()\n",
    "val_ids = trial_info[trial_info['split']=='val']['trial_id'].tolist()\n",
    "\n",
    "# Concatenate both heldin and heldout spikes since we're using spikes to predict behavior\n",
    "spikes = np.concat([\n",
    "    dataset_dict['train_spikes_heldin'], \n",
    "    dataset_dict['train_spikes_heldout']],axis=2) \n",
    "smoothed_spikes = smooth_spikes(spikes, kern_sd_ms=40, bin_width=5)\n",
    "behavior = dataset_dict['train_behavior']\n",
    "\n",
    "input_dim = smoothed_spikes.shape[2]\n",
    "output_dim = behavior.shape[2]\n",
    "\n",
    "# Split train and val based on splits from nlb\n",
    "# train_dataset = TensorDataset(smoothed_spikes[train_ids], behavior[train_ids])\n",
    "# val_dataset = TensorDataset(smoothed_spikes[val_ids], behavior[val_ids])\n",
    "# full_dataset = TensorDataset(smoothed_spikes, behavior)\n",
    "\n",
    "run_name = f\"nlb_{args.task}_{args.model.ssm_core}_l{args.model.num_layers}_d{args.model.d_state}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56464b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx \n",
    "from jax import random\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "model_key = random.PRNGKey(0)\n",
    "model = S5(\n",
    "    key= model_key,\n",
    "    num_blocks=args.model.num_layers,\n",
    "    N=args.model.input_dim,\n",
    "    ssm_size=args.model.d_state,\n",
    "    ssm_blocks=1,\n",
    "    H=args.model.hidden_dim,\n",
    "    output_dim=args.model.output_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708ad8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the state\n",
    "state = eqx.nn.State(model)\n",
    "\n",
    "# Generate a batch of keys\n",
    "batch_size = smoothed_spikes.shape[0]\n",
    "keys = random.split(random.PRNGKey(0), batch_size)\n",
    "\n",
    "# Run vmap with the batch of keys\n",
    "output, state = jax.vmap(\n",
    "    model, \n",
    "    axis_name=\"batch\", \n",
    "    in_axes=(0, None, 0),  # Map over inputs and keys\n",
    "    out_axes=(0)\n",
    ")(jnp.array(smoothed_spikes), state, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb087e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import equinox as eqx\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function (MSE for regression)\n",
    "def mse_loss(model, state, inputs, targets, key):\n",
    "    preds, _ = model(inputs, state, key)\n",
    "    return jnp.mean((preds - targets) ** 2)\n",
    "\n",
    "# Create training step function\n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def train_step(model, state, opt_state, inputs, targets, key):\n",
    "    # Define loss function with current parameters\n",
    "    def loss_fn(params):\n",
    "        # Recreate model with updated parameters\n",
    "        model = eqx.combine(params, eqx.filter(model_fn, eqx.is_array, invert=True))\n",
    "        preds, _ = model(inputs, state, key)\n",
    "        return jnp.mean((preds - targets) ** 2)\n",
    "    \n",
    "    # Get loss value and gradients\n",
    "    loss_val, grads = eqx.filter_value_and_grad(loss_fn)(eqx.filter(model_fn, eqx.is_array))\n",
    "    \n",
    "    # Update parameters\n",
    "    updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "    new_model = eqx.apply_updates(model_fn, updates)\n",
    "    \n",
    "    return new_model, new_opt_state, loss_val\n",
    "\n",
    "# Create evaluation function\n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def evaluate(model_fn, state, inputs, targets, key):\n",
    "    preds, _ = model_fn(inputs, state, key)\n",
    "    loss = jnp.mean((preds - targets) ** 2)\n",
    "    return loss, preds\n",
    "\n",
    "# Prepare data: convert to jax arrays and add batch dimension if needed\n",
    "def prepare_batch(inputs, targets, batch_indices):\n",
    "    batch_x = jnp.array(inputs[batch_indices])\n",
    "    batch_y = jnp.array(targets[batch_indices])\n",
    "    return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01301740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs = 100  # Start with fewer epochs for testing\n",
    "batch_size = 16  # Smaller batch size since we have sequential data\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "key = random.PRNGKey(42)\n",
    "\n",
    "# Set up optimizer with learning rate schedule\n",
    "schedule = optax.exponential_decay(\n",
    "    init_value=learning_rate,\n",
    "    transition_steps=100,\n",
    "    decay_rate=0.9,\n",
    "    end_value=1e-4\n",
    ")\n",
    "optimizer = optax.adamw(learning_rate=schedule, weight_decay=weight_decay)\n",
    "\n",
    "# Initialize optimizer state\n",
    "opt_state = optimizer.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "# Initialize state\n",
    "state = eqx.nn.State(model)\n",
    "\n",
    "# Prepare training and validation data\n",
    "X_train = smoothed_spikes[train_ids]\n",
    "y_train = behavior[train_ids]\n",
    "X_val = smoothed_spikes[val_ids]\n",
    "y_val = behavior[val_ids]\n",
    "\n",
    "# Keep track of metrics\n",
    "train_losses = []\n",
    "val_losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33c4245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Non-hashable static arguments are not supported. An error occurred while trying to hash an object of type <class 'foundational_ssm.models.s5.S5'>, S5(\n  linear_encoder=Linear(\n    weight=f32[64,182],\n    bias=f32[64],\n    in_features=182,\n    out_features=64,\n    use_bias=True\n  ),\n  blocks=[\n    S5Block(\n      norm=BatchNorm(\n        weight=None,\n        bias=None,\n        first_time_index=StateIndex(\n          marker=<object object at 0x7f408899db10>, init=bool[]\n        ),\n        state_index=StateIndex(\n          marker=<object object at 0x7f408899d840>, init=(f32[64], f32[64])\n        ),\n        axis_name='batch',\n        inference=False,\n        input_size=64,\n        eps=1e-05,\n        channelwise_affine=False,\n        momentum=0.99\n      ),\n      ssm=S5Layer(\n        Lambda_re=f32[32],\n        Lambda_im=f32[32],\n        B=f32[32,64,2],\n        C=f32[64,32,2],\n        D=f32[64],\n        log_step=f32[32,1],\n        H=64,\n        P=32,\n        conj_sym=True,\n        discretisation='zoh'\n      ),\n      glu=GLU(\n        w1=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        ),\n        w2=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        )\n      ),\n      drop=Dropout(p=0.05, inference=False)\n    ),\n    S5Block(\n      norm=BatchNorm(\n        weight=None,\n        bias=None,\n        first_time_index=StateIndex(\n          marker=<object object at 0x7f40246d2310>, init=bool[]\n        ),\n        state_index=StateIndex(\n          marker=<object object at 0x7f40246d2810>, init=(f32[64], f32[64])\n        ),\n        axis_name='batch',\n        inference=False,\n        input_size=64,\n        eps=1e-05,\n        channelwise_affine=False,\n        momentum=0.99\n      ),\n      ssm=S5Layer(\n        Lambda_re=f32[32],\n        Lambda_im=f32[32],\n        B=f32[32,64,2],\n        C=f32[64,32,2],\n        D=f32[64],\n        log_step=f32[32,1],\n        H=64,\n        P=32,\n        conj_sym=True,\n        discretisation='zoh'\n      ),\n      glu=GLU(\n        w1=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        ),\n        w2=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        )\n      ),\n      drop=Dropout(p=0.05, inference=False)\n    )\n  ],\n  linear_layer=Linear(\n    weight=f32[2,64], bias=f32[2], in_features=64, out_features=2, use_bias=True\n  )\n). The error was:\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/tornado/platform/asyncio.py\", line 211, in start\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/asyncio/base_events.py\", line 683, in run_forever\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/asyncio/base_events.py\", line 2042, in _run_once\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/asyncio/events.py\", line 89, in _run\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3100, in run_cell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3155, in _run_cell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3367, in run_cell_async\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3612, in run_ast_nodes\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3672, in run_code\n  File \"/tmp/ipykernel_119725/3001736501.py\", line 23, in <module>\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/equinox/_module.py\", line 1037, in __hash__\nTypeError: unhashable type: 'jaxlib._jax.ArrayImpl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m key, subkey = random.split(key)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Train on batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m model, opt_state, batch_loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m epoch_loss += batch_loss\n\u001b[32m     26\u001b[39m num_batches += \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Non-hashable static arguments are not supported. An error occurred while trying to hash an object of type <class 'foundational_ssm.models.s5.S5'>, S5(\n  linear_encoder=Linear(\n    weight=f32[64,182],\n    bias=f32[64],\n    in_features=182,\n    out_features=64,\n    use_bias=True\n  ),\n  blocks=[\n    S5Block(\n      norm=BatchNorm(\n        weight=None,\n        bias=None,\n        first_time_index=StateIndex(\n          marker=<object object at 0x7f408899db10>, init=bool[]\n        ),\n        state_index=StateIndex(\n          marker=<object object at 0x7f408899d840>, init=(f32[64], f32[64])\n        ),\n        axis_name='batch',\n        inference=False,\n        input_size=64,\n        eps=1e-05,\n        channelwise_affine=False,\n        momentum=0.99\n      ),\n      ssm=S5Layer(\n        Lambda_re=f32[32],\n        Lambda_im=f32[32],\n        B=f32[32,64,2],\n        C=f32[64,32,2],\n        D=f32[64],\n        log_step=f32[32,1],\n        H=64,\n        P=32,\n        conj_sym=True,\n        discretisation='zoh'\n      ),\n      glu=GLU(\n        w1=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        ),\n        w2=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        )\n      ),\n      drop=Dropout(p=0.05, inference=False)\n    ),\n    S5Block(\n      norm=BatchNorm(\n        weight=None,\n        bias=None,\n        first_time_index=StateIndex(\n          marker=<object object at 0x7f40246d2310>, init=bool[]\n        ),\n        state_index=StateIndex(\n          marker=<object object at 0x7f40246d2810>, init=(f32[64], f32[64])\n        ),\n        axis_name='batch',\n        inference=False,\n        input_size=64,\n        eps=1e-05,\n        channelwise_affine=False,\n        momentum=0.99\n      ),\n      ssm=S5Layer(\n        Lambda_re=f32[32],\n        Lambda_im=f32[32],\n        B=f32[32,64,2],\n        C=f32[64,32,2],\n        D=f32[64],\n        log_step=f32[32,1],\n        H=64,\n        P=32,\n        conj_sym=True,\n        discretisation='zoh'\n      ),\n      glu=GLU(\n        w1=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        ),\n        w2=Linear(\n          weight=f32[64,64],\n          bias=f32[64],\n          in_features=64,\n          out_features=64,\n          use_bias=True\n        )\n      ),\n      drop=Dropout(p=0.05, inference=False)\n    )\n  ],\n  linear_layer=Linear(\n    weight=f32[2,64], bias=f32[2], in_features=64, out_features=2, use_bias=True\n  )\n). The error was:\nTraceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/tornado/platform/asyncio.py\", line 211, in start\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/asyncio/base_events.py\", line 683, in run_forever\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/asyncio/base_events.py\", line 2042, in _run_once\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/asyncio/events.py\", line 89, in _run\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3100, in run_cell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3155, in _run_cell\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3367, in run_cell_async\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3612, in run_ast_nodes\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/IPython/core/interactiveshell.py\", line 3672, in run_code\n  File \"/tmp/ipykernel_119725/3001736501.py\", line 23, in <module>\n  File \"/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/equinox/_module.py\", line 1037, in __hash__\nTypeError: unhashable type: 'jaxlib._jax.ArrayImpl'\n"
     ]
    }
   ],
   "source": [
    "# Create batch indices\n",
    "num_train = len(train_ids)\n",
    "indices = np.arange(num_train)\n",
    "\n",
    "# Training loop with fixed JIT compilation\n",
    "print(\"Starting training...\")\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Shuffle train data\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Train batches\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i in range(0, num_train, batch_size):\n",
    "        batch_indices = indices[i:i + batch_size]\n",
    "        batch_x, batch_y = prepare_batch(X_train, y_train, batch_indices)\n",
    "        \n",
    "        # Generate new key for this batch\n",
    "        key, subkey = random.split(key)\n",
    "        \n",
    "        # Train on batch\n",
    "        model, opt_state, batch_loss = train_step(model, state, opt_state, batch_x, batch_y, subkey)\n",
    "        \n",
    "        epoch_loss += batch_loss\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Calculate average loss for epoch\n",
    "    avg_train_loss = epoch_loss / num_batches\n",
    "    train_losses.append(float(avg_train_loss))  # Convert from JAX array to float\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_key = random.split(key)[0]\n",
    "    val_loss, val_preds = evaluate(model, state, X_val, y_val, val_key)\n",
    "    val_losses.append(float(val_loss))  # Convert from JAX array to float\n",
    "    \n",
    "    # Log every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2165ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
