{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa3393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/preprocessing_env/lib/python3.11/site-packages/pynwb/__init__.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "from nlb_tools.make_tensors import make_train_input_tensors, make_eval_input_tensors, make_eval_target_tensors, save_to_h5\n",
    "from nlb_tools.evaluation import evaluate\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from foundational_ssm.collate import pad_collate\n",
    "import torch\n",
    "\n",
    "dataset_folder = '/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/' \n",
    "\n",
    "datasets = [\n",
    "    {'name':'mc_maze', 'subpath':'./000128/sub-Jenkins/'},\n",
    "    {'name':'mc_rtt', 'subpath':'./000129/sub-Indy/'},\n",
    "    {'name':'area2_bump', 'subpath':'./000127/sub-Han/'},\n",
    "    {'name':'dmfc_rsg', 'subpath':'./000130/sub-Haydn/'},\n",
    "]\n",
    "\n",
    "import h5py\n",
    "import torch \n",
    "def dict_to_h5(tensor_dict, output_h5_file):\n",
    "    with h5py.File(output_h5_file, 'w') as f:\n",
    "        # Iterate through the items in your 'batch' dictionary\n",
    "        for key, value in tensor_dict.items():\n",
    "            # Convert PyTorch tensor to NumPy array before saving\n",
    "            # Ensure data type consistency for saving\n",
    "            if torch.is_tensor(value):\n",
    "                # For boolean tensors, convert to int8 if you want them to take less space in HDF5\n",
    "                # (np.bool_ usually takes 1 byte, but some systems/HDF5 viewers prefer integer)\n",
    "                if value.dtype == torch.bool:\n",
    "                    data_to_save = value.to(torch.int8).numpy()\n",
    "                else:\n",
    "                    data_to_save = value.numpy()\n",
    "            else:\n",
    "                data_to_save = value # If any value isn't a tensor (e.g., a simple scalar or list)\n",
    "\n",
    "            f.create_dataset(key, data=data_to_save)\n",
    "            print(f\"  - Saved '{key}' with shape {data_to_save.shape} and dtype {data_to_save.dtype}\")\n",
    "\n",
    "        print(f\"Successfully saved all data from 'batch' to {output_h5_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fc7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets[1]\n",
    "dataset_name = d['name']\n",
    "dataset_subpath = d['subpath']\n",
    "train_trial_split = ['train', 'val']\n",
    "\n",
    "raw_data_path = os.path.join(dataset_folder, 'raw', 'dandi', dataset_subpath) \n",
    "processed_data_folder = os.path.join(dataset_folder, 'processed', 'nlb')\n",
    "processed_data_path = os.path.join(processed_data_folder, dataset_name + '.h5')\n",
    "trial_info_path = os.path.join(processed_data_folder, dataset_name + '.csv')\n",
    "\n",
    "if not os.path.exists(processed_data_folder):\n",
    "    print(f\"Creating directory: {processed_data_folder}\")\n",
    "    os.makedirs(processed_data_folder, exist_ok=True)\n",
    "\n",
    "nwb_dataset = NWBDataset(raw_data_path, split_heldout=False)\n",
    "\n",
    "\n",
    "# Find when target pos changes\n",
    "has_change = nwb_dataset.data.target_pos.fillna(-1000).diff(axis=0).any(axis=1) # filling NaNs with arbitrary scalar to treat as one block\n",
    "# Find if target pos change corresponds to NaN-padded gap between files\n",
    "change_nan = nwb_dataset.data[has_change].isna().any(axis=1)\n",
    "# Drop trials containing the gap and immediately before and after, as those trials may be cut short\n",
    "drop_trial = (change_nan | change_nan.shift(1, fill_value=True) | change_nan.shift(-1, fill_value=True))[:-1]\n",
    "# Add start and end times to trial info\n",
    "change_times = nwb_dataset.data.index[has_change]\n",
    "start_times = change_times[:-1][~drop_trial]\n",
    "end_times = change_times[1:][~drop_trial]\n",
    "# Get target position per trial\n",
    "start_pos = nwb_dataset.data.target_pos.loc[start_times - pd.Timedelta(1, 'ms')].to_numpy().tolist()\n",
    "target_pos = nwb_dataset.data.target_pos.loc[start_times].to_numpy().tolist()\n",
    "# Compute reach distance and angle\n",
    "reach_dist = nwb_dataset.data.target_pos.loc[end_times - pd.Timedelta(1, 'ms')].to_numpy() - nwb_dataset.data.target_pos.loc[start_times - pd.Timedelta(1, 'ms')].to_numpy()\n",
    "reach_angle = np.arctan2(reach_dist[:, 1], reach_dist[:, 0]) / np.pi * 180\n",
    "# Create trial info\n",
    "nwb_dataset.trial_info = pd.DataFrame({\n",
    "    'trial_id': np.arange(len(start_times)),\n",
    "    'start_time': start_times,\n",
    "    'end_time': end_times,\n",
    "    'duration': (end_times - start_times).total_seconds(),\n",
    "    'start_pos': start_pos,\n",
    "    'target_pos': target_pos,\n",
    "    'reach_dist_x': reach_dist[:, 0],\n",
    "    'reach_dist_y': reach_dist[:, 1],\n",
    "    'reach_angle': reach_angle,\n",
    "})\n",
    "nwb_dataset.resample(5)\n",
    "nwb_dataset.trial_info.to_csv('/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_trialized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17bca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Saved 'neural_input' with shape (378, 764, 130) and dtype int8\n",
      "  - Saved 'behavior_input' with shape (378, 764, 2) and dtype float64\n",
      "  - Saved 'mask' with shape (378, 764) and dtype int8\n",
      "  - Saved 'dataset_group_idx' with shape (378,) and dtype int8\n",
      "Successfully saved all data from 'batch' to /cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_trialized_train.h5\n",
      "  - Saved 'neural_input' with shape (163, 764, 130) and dtype int8\n",
      "  - Saved 'behavior_input' with shape (163, 764, 2) and dtype float64\n",
      "  - Saved 'mask' with shape (163, 764) and dtype int8\n",
      "  - Saved 'dataset_group_idx' with shape (163,) and dtype int8\n",
      "Successfully saved all data from 'batch' to /cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_trialized_val.h5\n",
      "  - Saved 'neural_input' with shape (541, 764, 130) and dtype int8\n",
      "  - Saved 'behavior_input' with shape (541, 764, 2) and dtype float64\n",
      "  - Saved 'mask' with shape (541, 764) and dtype int8\n",
      "  - Saved 'dataset_group_idx' with shape (541,) and dtype int8\n",
      "Successfully saved all data from 'batch' to /cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_trialized.h5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys \n",
    "\n",
    "DTYPE_FLOAT = np.float32 \n",
    "def pad_collate(batch, fixed_seq_len=None):\n",
    "    # Assume batch is a list of dicts with keys: 'neural_input', 'behavior_input', etc.\n",
    "    # Each 'neural_input' is a tensor of shape (timesteps, units)\n",
    "    neural_inputs = [item['neural_input'] for item in batch if item is not None]  # (timesteps, units)\n",
    "    behavioral_inputs = [item['behavior_input'] for item in batch if item is not None]\n",
    "    \n",
    "    # Determine the fixed sequence length\n",
    "    if fixed_seq_len is None:\n",
    "        max_len = max(x.shape[0] for x in neural_inputs)\n",
    "    else:\n",
    "        max_len = fixed_seq_len\n",
    "\n",
    "    # Pad or truncate each sequence to fixed length\n",
    "    def pad_or_truncate(tensor, max_len):\n",
    "        seq_len = tensor.shape[0]\n",
    "        if seq_len == max_len:\n",
    "            return tensor\n",
    "        elif seq_len > max_len:\n",
    "            return tensor[:max_len]\n",
    "        else:\n",
    "            pad_shape = (max_len - seq_len,) + tensor.shape[1:]\n",
    "            pad_tensor = torch.zeros(pad_shape, dtype=tensor.dtype, device=tensor.device)\n",
    "            return torch.cat([tensor, pad_tensor], dim=0)\n",
    "\n",
    "    padded_neural = torch.stack([pad_or_truncate(x, max_len) for x in neural_inputs if x is not None])  # (batch, max_len, units)\n",
    "    padded_behavior = torch.stack([pad_or_truncate(x, max_len) for x in behavioral_inputs if x is not None])\n",
    "\n",
    "    # Create mask: 1 for real data, 0 for padding\n",
    "    lengths = [x.shape[0] for x in neural_inputs]\n",
    "    mask = torch.zeros((len(batch), max_len), dtype=torch.bool)\n",
    "    for i, l in enumerate(lengths):\n",
    "        mask[i, :min(l, max_len)] = 1\n",
    "\n",
    "    # Stack other fields (e.g., dataset_group_idx)\n",
    "    dataset_group_idx = torch.stack([item['dataset_group_idx'] for item in batch])\n",
    "    \n",
    "    return {\n",
    "        'neural_input': padded_neural,\n",
    "        'behavior_input': padded_behavior,\n",
    "        'mask': mask,\n",
    "        'dataset_group_idx': dataset_group_idx,\n",
    "        # add other fields as needed\n",
    "    }\n",
    "    \n",
    "batch = []\n",
    "max_len = 0\n",
    "prepend_duration = 279  # ms to prepend to each trial\n",
    "for i, row in nwb_dataset.trial_info.iterrows():\n",
    "    start = row['start_time'] - pd.Timedelta(prepend_duration, 'ms')\n",
    "    end = row['end_time']\n",
    "    # Load data slices. This is where memory efficiency of nwb_dataset is key.\n",
    "    behavior_data = nwb_dataset.data.finger_vel[start:end].to_numpy()\n",
    "    neural_data = nwb_dataset.data.spikes[start:end].to_numpy(dtype=np.int8)\n",
    "    cursor_pos = nwb_dataset.data.cursor_pos[start:end].to_numpy()\n",
    "\n",
    "    # Convert to torch tensors with desired dtype immediately.\n",
    "    batch.append({\n",
    "        'behavior_input': torch.from_numpy(behavior_data),\n",
    "        'neural_input': torch.from_numpy(neural_data),\n",
    "        'cursor_pos': torch.from_numpy(cursor_pos),\n",
    "        'dataset_group_idx': torch.tensor(9, dtype=torch.int8) # Ensure it's a torch.Tensor\n",
    "    })\n",
    "    if max_len < behavior_data.shape[0]:\n",
    "        max_len = behavior_data.shape[0]\n",
    "    \n",
    "batch = pad_collate(batch)\n",
    "train_proportion = 0.7\n",
    "train_data = {k: v[:int(len(v) * train_proportion)] for k, v in batch.items()}\n",
    "val_data = {k: v[int(len(v) * train_proportion):] for k, v in batch.items()}\n",
    "data_dir = '/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb'\n",
    "train_h5_file = os.path.join(data_dir, 'mc_rtt_trialized_train.h5')\n",
    "val_h5_file = os.path.join(data_dir, 'mc_rtt_trialized_val.h5')\n",
    "h5_file = os.path.join(data_dir, 'mc_rtt_trialized.h5')\n",
    "dict_to_h5(train_data, train_h5_file)\n",
    "dict_to_h5(val_data, val_h5_file)\n",
    "dict_to_h5(batch, h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_h5(batch, h5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3668124",
   "metadata": {},
   "source": [
    "# Original Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6819eb0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m nwb_dataset.resample(bin_width)\n\u001b[32m     11\u001b[39m suffix = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (bin_width == \u001b[32m5\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(bin_width))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m train_dataset_dict = make_train_input_tensors(nwb_dataset, dataset_name=dataset_name, trial_split=\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m, save_file=\u001b[38;5;28;01mTrue\u001b[39;00m, save_path=\u001b[43mprocessed_data_path\u001b[49m, include_forward_pred=\u001b[38;5;28;01mTrue\u001b[39;00m, include_behavior=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     14\u001b[39m val_dataset_dict = make_train_input_tensors(nwb_dataset, dataset_name=dataset_name, trial_split=\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m, save_file=\u001b[38;5;28;01mTrue\u001b[39;00m, save_path=processed_data_path, include_forward_pred=\u001b[38;5;28;01mTrue\u001b[39;00m, include_behavior=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     16\u001b[39m train_dataset_dict[\u001b[33m'\u001b[39m\u001b[33mneural_input\u001b[39m\u001b[33m'\u001b[39m] = np.concatenate([train_dataset_dict[\u001b[33m'\u001b[39m\u001b[33mtrain_spikes_heldin\u001b[39m\u001b[33m'\u001b[39m], train_dataset_dict[\u001b[33m'\u001b[39m\u001b[33mtrain_spikes_heldout\u001b[39m\u001b[33m'\u001b[39m]], axis=\u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'processed_data_path' is not defined"
     ]
    }
   ],
   "source": [
    "d = datasets[1]\n",
    "dataset_name = d['name']\n",
    "dataset_subpath = d['subpath']\n",
    "train_trial_split = ['train', 'val']\n",
    "\n",
    "raw_data_path = os.path.join(dataset_folder, 'raw', 'dandi', dataset_subpath) \n",
    "\n",
    "nwb_dataset = NWBDataset(raw_data_path)\n",
    "bin_width = 5\n",
    "nwb_dataset.resample(bin_width)\n",
    "suffix = '' if (bin_width == 5) else f'_{int(round(bin_width))}'\n",
    "\n",
    "train_dataset_dict = make_train_input_tensors(nwb_dataset, dataset_name=dataset_name, trial_split='train', save_file=True, save_path=processed_data_path, include_forward_pred=True, include_behavior=True)\n",
    "val_dataset_dict = make_train_input_tensors(nwb_dataset, dataset_name=dataset_name, trial_split='val', save_file=True, save_path=processed_data_path, include_forward_pred=True, include_behavior=True)\n",
    "\n",
    "train_dataset_dict['neural_input'] = np.concatenate([train_dataset_dict['train_spikes_heldin'], train_dataset_dict['train_spikes_heldout']], axis=2)\n",
    "train_dataset_dict['behavior_input'] = train_dataset_dict['train_behavior']\n",
    "train_dataset_dict['mask'] = np.ones(train_dataset_dict['neural_input'].shape[:2])\n",
    "\n",
    "val_dataset_dict['neural_input'] = np.concatenate([val_dataset_dict['train_spikes_heldin'], val_dataset_dict['train_spikes_heldout']], axis=2)\n",
    "val_dataset_dict['behavior_input'] = val_dataset_dict['train_behavior']\n",
    "val_dataset_dict['mask'] = np.ones(val_dataset_dict['neural_input'].shape[:2])\n",
    "\n",
    "dict_to_h5(train_dataset_dict, \n",
    "           '/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_not_trialized_train.h5')\n",
    "dict_to_h5(val_dataset_dict, \n",
    "           '/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_not_trialized_val.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13552d04",
   "metadata": {},
   "source": [
    "# Prepended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b62d188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Saved 'neural_input' with shape (810, 176, 130) and dtype int8\n",
      "  - Saved 'behavior_input' with shape (810, 176, 2) and dtype float64\n",
      "  - Saved 'mask' with shape (810, 176) and dtype int8\n",
      "  - Saved 'dataset_group_idx' with shape (810,) and dtype int8\n",
      "Successfully saved all data from 'batch' to /cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_prepend_train.h5\n",
      "  - Saved 'neural_input' with shape (270, 176, 130) and dtype int8\n",
      "  - Saved 'behavior_input' with shape (270, 176, 2) and dtype float64\n",
      "  - Saved 'mask' with shape (270, 176) and dtype int8\n",
      "  - Saved 'dataset_group_idx' with shape (270,) and dtype int8\n",
      "Successfully saved all data from 'batch' to /cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_prepend_val.h5\n"
     ]
    }
   ],
   "source": [
    "d = datasets[1]\n",
    "dataset_name = d['name']\n",
    "dataset_subpath = d['subpath']\n",
    "train_trial_split = ['train', 'val']\n",
    "\n",
    "raw_data_path = os.path.join(dataset_folder, 'raw', 'dandi', dataset_subpath) \n",
    "\n",
    "nwb_dataset = NWBDataset(raw_data_path, split_heldout=False)\n",
    "bin_width = 5\n",
    "nwb_dataset.resample(bin_width)\n",
    "suffix = '' if (bin_width == 5) else f'_{int(round(bin_width))}'\n",
    "train_batch = []\n",
    "\n",
    "prepend_duration = 279  # ms to prepend to each trial\n",
    "for i, row in nwb_dataset.trial_info.iterrows():\n",
    "    trial_idx = row['trial_id']\n",
    "    if row['split']== 'train':\n",
    "        start = row['start_time'] - pd.Timedelta(prepend_duration, 'ms')  # Adjust start time to include the last ms before the trial\n",
    "        end = row['end_time']\n",
    "        # Load data slices. This is where memory efficiency of nwb_dataset is key.\n",
    "        behavior_data = nwb_dataset.data.finger_vel[start:end].to_numpy()\n",
    "        neural_data = nwb_dataset.data.spikes[start:end].to_numpy(dtype=np.int8)\n",
    "        cursor_pos = nwb_dataset.data.cursor_pos[start:end].to_numpy()\n",
    "\n",
    "        # Convert to torch tensors with desired dtype immediately.\n",
    "        train_batch.append({\n",
    "            'behavior_input': torch.from_numpy(behavior_data),\n",
    "            'neural_input': torch.from_numpy(neural_data),\n",
    "            # 'cursor_pos': torch.from_numpy(cursor_pos),\n",
    "            'dataset_group_idx': torch.tensor(9, dtype=torch.int8), # Ensure it's a torch.Tensor\n",
    "            'trial_idx': torch.tensor(trial_idx, dtype=torch.int32)  # Add trial index for reference\n",
    "        })\n",
    "\n",
    "val_batch = []        \n",
    "for i, row in nwb_dataset.trial_info.iterrows():\n",
    "    if row['split']== 'val':\n",
    "        start = row['start_time'] - pd.Timedelta(prepend_duration, 'ms')  # Adjust start time to include the last ms before the trial\n",
    "        end = row['end_time']\n",
    "        # Load data slices. This is where memory efficiency of nwb_dataset is key.\n",
    "        behavior_data = nwb_dataset.data.finger_vel[start:end].to_numpy()\n",
    "        neural_data = nwb_dataset.data.spikes[start:end].to_numpy(dtype=np.int8)\n",
    "        cursor_pos = nwb_dataset.data.cursor_pos[start:end].to_numpy()\n",
    "\n",
    "        # Convert to torch tensors with desired dtype immediately.\n",
    "        val_batch.append({\n",
    "            'behavior_input': torch.from_numpy(behavior_data),\n",
    "            'neural_input': torch.from_numpy(neural_data),\n",
    "            # 'cursor_pos': torch.from_numpy(cursor_pos),\n",
    "            'dataset_group_idx': torch.tensor(9, dtype=torch.int8), # Ensure it's a torch.Tensor\n",
    "            'trial_idx': torch.tensor(trial_idx, dtype=torch.int32)  # Add trial index for reference\n",
    "        })\n",
    "    \n",
    "\n",
    "train_batch = pad_collate(train_batch, fixed_seq_len=None)\n",
    "val_batch = pad_collate(val_batch, fixed_seq_len=None)\n",
    "\n",
    "\n",
    "# # Option 1: Using expand\n",
    "# replacement_value = train_batch['neural_input'][:, prepend_duration // bin_width + 1:prepend_duration // bin_width + 2, :]\n",
    "# train_batch['neural_input'][:, :prepend_duration // bin_width + 1, :] = replacement_value.expand(-1, prepend_duration // bin_width + 1, -1)\n",
    "# replacement_value = val_batch['neural_input'][:, prepend_duration // bin_width + 1:prepend_duration // bin_width + 2, :]\n",
    "# val_batch['neural_input'][:, :prepend_duration // bin_width + 1, :] = replacement_value.expand(-1, prepend_duration // bin_width + 1, -1)\n",
    "\n",
    "train_batch['behavior_input'][:, :prepend_duration // bin_width + 1, :] = 0\n",
    "val_batch['behavior_input'][:, :prepend_duration // bin_width + 1, :] = 0  # Remove the prepended duration\n",
    "\n",
    "\n",
    "dict_to_h5(train_batch, \n",
    "           '/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_prepend_train.h5')\n",
    "dict_to_h5(val_batch, \n",
    "           '/cs/student/projects1/ml/2024/mlaimon/data/foundational_ssm/processed/nlb/mc_rtt_prepend_val.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe17ed54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  1,  2,  2,  3,  1,  2,  1,  2,  1,  2,  1,\n",
       "         2,  4,  0,  1,  4,  1,  1,  2,  2,  2,  4,  2,  0,  1,  1,  3,  3,  0,\n",
       "         0,  2,  2,  0,  3,  1,  5,  0,  1,  1,  2,  1,  0,  1,  1,  2,  2,  1,\n",
       "         1,  3,  1,  4,  1,  3,  0,  2,  1,  4,  4,  1,  1,  1,  0,  3,  3,  0,\n",
       "         0,  3,  0,  1,  3,  0,  0,  4,  1,  7,  8,  2,  0,  2,  1,  3,  2,  3,\n",
       "         1,  0,  1,  5,  5,  3,  0,  0,  3,  1,  3,  2,  1,  2,  2,  9,  2,  1,\n",
       "         4,  4,  4,  4,  6,  6,  2, 10,  7,  3,  3,  6,  7,  7,  8, 10,  4,  7])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch['neural_input'].sum(axis=2)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842601be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
