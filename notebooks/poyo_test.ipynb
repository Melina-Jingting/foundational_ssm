{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95df258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foundational_ssm.data_utils.dataset import TorchBrainDataset\n",
    "from foundational_ssm.data_utils.samplers import GroupedRandomFixedWindowSampler\n",
    "from foundational_ssm.data_utils.loaders import get_dataset_config\n",
    "from torch.utils.data import DataLoader\n",
    "from foundational_ssm.constants import DATA_ROOT\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64ec81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from line_profiler import LineProfiler\n",
    "from foundational_ssm.data_utils.dataset import TorchBrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332d34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/configs/pretrain.yaml\"\n",
    "cfg = OmegaConf.load(config_path) \n",
    "train_dataset = TorchBrainDataset(\n",
    "    root=\"../\"+DATA_ROOT,\n",
    "    config=get_dataset_config(\n",
    "        **cfg.train_dataset\n",
    "    ),\n",
    "    lazy=cfg.dataloader.lazy,\n",
    "    keep_files_open=cfg.dataloader.keep_files_open,\n",
    "    \n",
    ")\n",
    "train_sampling_intervals = train_dataset.get_sampling_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d3a6d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: CUDA driver initialization failed, you might not have a CUDA gpu. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from torch_brain.models import POYO\n",
    "from torch_brain.registry import MODALITY_REGISTRY\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Any, Dict\n",
    "\n",
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "poyo_model = POYO(\n",
    "    sequence_length=1.0,\n",
    "    readout_spec=MODALITY_REGISTRY['cursor_velocity_2d'],\n",
    "    latent_step=1.0 / 8,\n",
    "    num_latents_per_step=16,\n",
    "    dim=64,\n",
    "    depth=6,\n",
    "    dim_head=64,\n",
    "    cross_heads=2,\n",
    "    self_heads=8,\n",
    ").to(device)\n",
    "poyo_model.unit_emb.initialize_vocab(train_dataset.get_unit_ids())\n",
    "poyo_model.session_emb.initialize_vocab(train_dataset.get_session_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3016c09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [00:32,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per batch: 0.23600583327443977 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch_brain.data import Dataset, collate, chain\n",
    "from torch_brain.data.sampler import RandomFixedWindowSampler\n",
    "\n",
    "from foundational_ssm.constants import DATA_ROOT\n",
    "from foundational_ssm.data_utils.dataset import TorchBrainDataset\n",
    "from foundational_ssm.data_utils.loaders import get_dataset_config\n",
    "from torch_brain.models import POYO\n",
    "from torch_brain.registry import MODALITY_REGISTRY\n",
    "\n",
    "train_sampler = RandomFixedWindowSampler(\n",
    "    sampling_intervals=train_sampling_intervals,\n",
    "    window_length=1.0,\n",
    "    # batch_size=256,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    "    batch_size=1024,\n",
    ")\n",
    "train_dataset.transform = poyo_model.tokenize\n",
    "\n",
    "poyo_tokenize_time = np.zeros(1000)\n",
    "start_time = time.time()\n",
    "for i, batch in tqdm(enumerate(train_loader)):\n",
    "    poyo_tokenize_time[i] = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "poyo_tokenize_time = poyo_tokenize_time[poyo_tokenize_time != 0]\n",
    "#print the average time per batch\n",
    "print(f\"Average time per batch: {np.mean(poyo_tokenize_time)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "993d55e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to synchronously get dataspace (identifier is not of specified type)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_recording_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mperich_miller_population_2018/c_20131003_center_out_reaching\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmovement_phases\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2885\u001b[39m, in \u001b[36mData.slice\u001b[39m\u001b[34m(self, start, end, reset_origin)\u001b[39m\n\u001b[32m   2882\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = copy.copy(value)\n\u001b[32m   2884\u001b[39m \u001b[38;5;66;03m# update domain\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2885\u001b[39m out._domain = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_domain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mInterval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_origin:\n\u001b[32m   2887\u001b[39m     out._domain.start -= start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2251\u001b[39m, in \u001b[36mInterval.__and__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   2246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__and__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m   2247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Intersection of two intervals.\u001b[39;00m\n\u001b[32m   2248\u001b[39m \u001b[33;03m    Only start/end times are considered for the intersection,\u001b[39;00m\n\u001b[32m   2249\u001b[39m \u001b[33;03m    and only start/end times are returned in the resulting Interval\u001b[39;00m\n\u001b[32m   2250\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_disjoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2252\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mleft Interval object must be disjoint.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2253\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other.is_disjoint():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:1737\u001b[39m, in \u001b[36mInterval.is_disjoint\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1735\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tmp_copy.is_disjoint()\n\u001b[32m-> \u001b[39m\u001b[32m1737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(np.all(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m[:-\u001b[32m1\u001b[39m] <= \u001b[38;5;28mself\u001b[39m.start[\u001b[32m1\u001b[39m:]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2403\u001b[39m, in \u001b[36mLazyInterval.__getattribute__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2401\u001b[39m     out = out[\u001b[38;5;28mself\u001b[39m._lazy_ops[\u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m   2402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._lazy_ops) == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2403\u001b[39m     out = \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   2405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._unicode_keys:\n\u001b[32m   2406\u001b[39m     \u001b[38;5;66;03m# convert back to unicode\u001b[39;00m\n\u001b[32m   2407\u001b[39m     out = out.astype(\u001b[33m\"\u001b[39m\u001b[33mU\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:818\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, args, new_dtype)\u001b[39m\n\u001b[32m    806\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Read a slice from the HDF5 dataset.\u001b[39;00m\n\u001b[32m    807\u001b[39m \n\u001b[32m    808\u001b[39m \u001b[33;03mTakes slices and recarray-style field names (more than one is\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    814\u001b[39m \u001b[33;03m* Boolean \"mask\" array indexing\u001b[39;00m\n\u001b[32m    815\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    816\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (args,)\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fast_read_ok\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    820\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_reader.read(args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:800\u001b[39m, in \u001b[36mDataset._fast_read_ok\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    796\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fast_read_ok\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is this dataset suitable for simple reading\"\"\"\u001b[39;00m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extent_type\u001b[49m == h5s.SIMPLE\n\u001b[32m    801\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.id.get_type(), (h5t.TypeIntegerID, h5t.TypeFloatID))\n\u001b[32m    802\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:679\u001b[39m, in \u001b[36mDataset._extent_type\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    675\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    676\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_extent_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    678\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get extent type for this dataset - SIMPLE, SCALAR or NULL\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get_simple_extent_type()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5d.pyx:374\u001b[39m, in \u001b[36mh5py.h5d.DatasetID.get_space\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to synchronously get dataspace (identifier is not of specified type)"
     ]
    }
   ],
   "source": [
    "train_dataset.get_recording_data('perich_miller_population_2018/c_20131003_center_out_reaching').movement_phases.slice(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9229fdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(\n",
       "  start=[1],\n",
       "  end=[1]\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from temporaldata import Interval\n",
    "copy.copy(train_dataset.get_recording_data('perich_miller_population_2018/c_20131003_center_out_reaching')._domain & Interval(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1febdc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to synchronously get dataspace (identifier is not of specified type)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py:493\u001b[39m, in \u001b[36mTorchBrainDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n",
      "\u001b[32m    492\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: DatasetIndex):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecording_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# apply transform\u001b[39;00m\n",
      "\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py:326\u001b[39m, in \u001b[36mTorchBrainDataset.get\u001b[39m\u001b[34m(self, recording_id, start, end)\u001b[39m\n",
      "\u001b[32m    315\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"This is the main method to extract a slice from a recording. It returns a\u001b[39;00m\n",
      "\u001b[32m    316\u001b[39m \u001b[33;03mData object that contains all data for recording :obj:`recording_id` between\u001b[39;00m\n",
      "\u001b[32m    317\u001b[39m \u001b[33;03mtimes :obj:`start` and :obj:`end`.\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m \u001b[33;03m    end: The end time of the slice.\u001b[39;00m\n",
      "\u001b[32m    324\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    325\u001b[39m data = \u001b[38;5;28mself\u001b[39m._get_data_object(recording_id)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m sample = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_for_data_leakage_flag \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.split \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    329\u001b[39m     sample._check_for_data_leakage(\u001b[38;5;28mself\u001b[39m.split)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2880\u001b[39m, in \u001b[36mData.slice\u001b[39m\u001b[34m(self, start, end, reset_origin)\u001b[39m\n",
      "\u001b[32m   2874\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m.items():\n",
      "\u001b[32m   2875\u001b[39m     \u001b[38;5;66;03m# todo update domain\u001b[39;00m\n",
      "\u001b[32m   2876\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_domain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n",
      "\u001b[32m   2877\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(value, (IrregularTimeSeries, RegularTimeSeries, Interval))\n",
      "\u001b[32m   2878\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, Data) \u001b[38;5;129;01mand\u001b[39;00m value.domain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m   2879\u001b[39m     ):\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2880\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_origin\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2881\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   2882\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = copy.copy(value)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2885\u001b[39m, in \u001b[36mData.slice\u001b[39m\u001b[34m(self, start, end, reset_origin)\u001b[39m\n",
      "\u001b[32m   2882\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = copy.copy(value)\n",
      "\u001b[32m   2884\u001b[39m \u001b[38;5;66;03m# update domain\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2885\u001b[39m out._domain = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_domain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mInterval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_origin:\n",
      "\u001b[32m   2887\u001b[39m     out._domain.start -= start\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2251\u001b[39m, in \u001b[36mInterval.__and__\u001b[39m\u001b[34m(self, other)\u001b[39m\n",
      "\u001b[32m   2246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__and__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n",
      "\u001b[32m   2247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Intersection of two intervals.\u001b[39;00m\n",
      "\u001b[32m   2248\u001b[39m \u001b[33;03m    Only start/end times are considered for the intersection,\u001b[39;00m\n",
      "\u001b[32m   2249\u001b[39m \u001b[33;03m    and only start/end times are returned in the resulting Interval\u001b[39;00m\n",
      "\u001b[32m   2250\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_disjoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n",
      "\u001b[32m   2252\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mleft Interval object must be disjoint.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   2253\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other.is_disjoint():\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:1737\u001b[39m, in \u001b[36mInterval.is_disjoint\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m   1735\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[32m   1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tmp_copy.is_disjoint()\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(np.all(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m[:-\u001b[32m1\u001b[39m] <= \u001b[38;5;28mself\u001b[39m.start[\u001b[32m1\u001b[39m:]))\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2403\u001b[39m, in \u001b[36mLazyInterval.__getattribute__\u001b[39m\u001b[34m(self, name)\u001b[39m\n",
      "\u001b[32m   2401\u001b[39m     out = out[\u001b[38;5;28mself\u001b[39m._lazy_ops[\u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[32m   2402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._lazy_ops) == \u001b[32m0\u001b[39m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2403\u001b[39m     out = \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m   2405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._unicode_keys:\n",
      "\u001b[32m   2406\u001b[39m     \u001b[38;5;66;03m# convert back to unicode\u001b[39;00m\n",
      "\u001b[32m   2407\u001b[39m     out = out.astype(\u001b[33m\"\u001b[39m\u001b[33mU\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:818\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, args, new_dtype)\u001b[39m\n",
      "\u001b[32m    806\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Read a slice from the HDF5 dataset.\u001b[39;00m\n",
      "\u001b[32m    807\u001b[39m \n",
      "\u001b[32m    808\u001b[39m \u001b[33;03mTakes slices and recarray-style field names (more than one is\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    814\u001b[39m \u001b[33;03m* Boolean \"mask\" array indexing\u001b[39;00m\n",
      "\u001b[32m    815\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    816\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (args,)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fast_read_ok\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m    820\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_reader.read(args)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n",
      "\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:800\u001b[39m, in \u001b[36mDataset._fast_read_ok\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    796\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n",
      "\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fast_read_ok\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is this dataset suitable for simple reading\"\"\"\u001b[39;00m\n",
      "\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n",
      "\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extent_type\u001b[49m == h5s.SIMPLE\n",
      "\u001b[32m    801\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.id.get_type(), (h5t.TypeIntegerID, h5t.TypeFloatID))\n",
      "\u001b[32m    802\u001b[39m     )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n",
      "\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:679\u001b[39m, in \u001b[36mDataset._extent_type\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    675\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n",
      "\u001b[32m    676\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n",
      "\u001b[32m    677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_extent_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    678\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get extent type for this dataset - SIMPLE, SCALAR or NULL\"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get_simple_extent_type()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5d.pyx:374\u001b[39m, in \u001b[36mh5py.h5d.DatasetID.get_space\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to synchronously get dataspace (identifier is not of specified type)"
     ]
    }
   ],
   "source": [
    "train_dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441539b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to synchronously get dataspace (identifier is not of specified type)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py:493\u001b[39m, in \u001b[36mTorchBrainDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n",
      "\u001b[32m    492\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: DatasetIndex):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecording_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# apply transform\u001b[39;00m\n",
      "\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py:326\u001b[39m, in \u001b[36mTorchBrainDataset.get\u001b[39m\u001b[34m(self, recording_id, start, end)\u001b[39m\n",
      "\u001b[32m    315\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"This is the main method to extract a slice from a recording. It returns a\u001b[39;00m\n",
      "\u001b[32m    316\u001b[39m \u001b[33;03mData object that contains all data for recording :obj:`recording_id` between\u001b[39;00m\n",
      "\u001b[32m    317\u001b[39m \u001b[33;03mtimes :obj:`start` and :obj:`end`.\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m \u001b[33;03m    end: The end time of the slice.\u001b[39;00m\n",
      "\u001b[32m    324\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    325\u001b[39m data = \u001b[38;5;28mself\u001b[39m._get_data_object(recording_id)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m sample = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_for_data_leakage_flag \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.split \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    329\u001b[39m     sample._check_for_data_leakage(\u001b[38;5;28mself\u001b[39m.split)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2880\u001b[39m, in \u001b[36mData.slice\u001b[39m\u001b[34m(self, start, end, reset_origin)\u001b[39m\n",
      "\u001b[32m   2874\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m.items():\n",
      "\u001b[32m   2875\u001b[39m     \u001b[38;5;66;03m# todo update domain\u001b[39;00m\n",
      "\u001b[32m   2876\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_domain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n",
      "\u001b[32m   2877\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(value, (IrregularTimeSeries, RegularTimeSeries, Interval))\n",
      "\u001b[32m   2878\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, Data) \u001b[38;5;129;01mand\u001b[39;00m value.domain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m   2879\u001b[39m     ):\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2880\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_origin\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2881\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   2882\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = copy.copy(value)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2885\u001b[39m, in \u001b[36mData.slice\u001b[39m\u001b[34m(self, start, end, reset_origin)\u001b[39m\n",
      "\u001b[32m   2882\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = copy.copy(value)\n",
      "\u001b[32m   2884\u001b[39m \u001b[38;5;66;03m# update domain\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2885\u001b[39m out._domain = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_domain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mInterval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_origin:\n",
      "\u001b[32m   2887\u001b[39m     out._domain.start -= start\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2251\u001b[39m, in \u001b[36mInterval.__and__\u001b[39m\u001b[34m(self, other)\u001b[39m\n",
      "\u001b[32m   2246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__and__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n",
      "\u001b[32m   2247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Intersection of two intervals.\u001b[39;00m\n",
      "\u001b[32m   2248\u001b[39m \u001b[33;03m    Only start/end times are considered for the intersection,\u001b[39;00m\n",
      "\u001b[32m   2249\u001b[39m \u001b[33;03m    and only start/end times are returned in the resulting Interval\u001b[39;00m\n",
      "\u001b[32m   2250\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_disjoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n",
      "\u001b[32m   2252\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mleft Interval object must be disjoint.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   2253\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other.is_disjoint():\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:1737\u001b[39m, in \u001b[36mInterval.is_disjoint\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m   1735\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[32m   1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tmp_copy.is_disjoint()\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(np.all(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m[:-\u001b[32m1\u001b[39m] <= \u001b[38;5;28mself\u001b[39m.start[\u001b[32m1\u001b[39m:]))\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2403\u001b[39m, in \u001b[36mLazyInterval.__getattribute__\u001b[39m\u001b[34m(self, name)\u001b[39m\n",
      "\u001b[32m   2401\u001b[39m     out = out[\u001b[38;5;28mself\u001b[39m._lazy_ops[\u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[32m   2402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._lazy_ops) == \u001b[32m0\u001b[39m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2403\u001b[39m     out = \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m   2405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._unicode_keys:\n",
      "\u001b[32m   2406\u001b[39m     \u001b[38;5;66;03m# convert back to unicode\u001b[39;00m\n",
      "\u001b[32m   2407\u001b[39m     out = out.astype(\u001b[33m\"\u001b[39m\u001b[33mU\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:818\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, args, new_dtype)\u001b[39m\n",
      "\u001b[32m    806\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Read a slice from the HDF5 dataset.\u001b[39;00m\n",
      "\u001b[32m    807\u001b[39m \n",
      "\u001b[32m    808\u001b[39m \u001b[33;03mTakes slices and recarray-style field names (more than one is\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    814\u001b[39m \u001b[33;03m* Boolean \"mask\" array indexing\u001b[39;00m\n",
      "\u001b[32m    815\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    816\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (args,)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fast_read_ok\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m    820\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_reader.read(args)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n",
      "\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:800\u001b[39m, in \u001b[36mDataset._fast_read_ok\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    796\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n",
      "\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fast_read_ok\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is this dataset suitable for simple reading\"\"\"\u001b[39;00m\n",
      "\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n",
      "\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extent_type\u001b[49m == h5s.SIMPLE\n",
      "\u001b[32m    801\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.id.get_type(), (h5t.TypeIntegerID, h5t.TypeFloatID))\n",
      "\u001b[32m    802\u001b[39m     )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n",
      "\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:679\u001b[39m, in \u001b[36mDataset._extent_type\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    675\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n",
      "\u001b[32m    676\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n",
      "\u001b[32m    677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_extent_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    678\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get extent type for this dataset - SIMPLE, SCALAR or NULL\"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get_simple_extent_type()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5d.pyx:374\u001b[39m, in \u001b[36mh5py.h5d.DatasetID.get_space\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to synchronously get dataspace (identifier is not of specified type)"
     ]
    }
   ],
   "source": [
    "train_dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c46dba",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to synchronously get dataspace (identifier is not of specified type)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py:493\u001b[39m, in \u001b[36mTorchBrainDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n",
      "\u001b[32m    492\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: DatasetIndex):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecording_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# apply transform\u001b[39;00m\n",
      "\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py:326\u001b[39m, in \u001b[36mTorchBrainDataset.get\u001b[39m\u001b[34m(self, recording_id, start, end)\u001b[39m\n",
      "\u001b[32m    315\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"This is the main method to extract a slice from a recording. It returns a\u001b[39;00m\n",
      "\u001b[32m    316\u001b[39m \u001b[33;03mData object that contains all data for recording :obj:`recording_id` between\u001b[39;00m\n",
      "\u001b[32m    317\u001b[39m \u001b[33;03mtimes :obj:`start` and :obj:`end`.\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m \u001b[33;03m    end: The end time of the slice.\u001b[39;00m\n",
      "\u001b[32m    324\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    325\u001b[39m data = \u001b[38;5;28mself\u001b[39m._get_data_object(recording_id)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m sample = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_for_data_leakage_flag \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.split \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    329\u001b[39m     sample._check_for_data_leakage(\u001b[38;5;28mself\u001b[39m.split)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2880\u001b[39m, in \u001b[36mData.slice\u001b[39m\u001b[34m(self, start, end, reset_origin)\u001b[39m\n",
      "\u001b[32m   2874\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m.items():\n",
      "\u001b[32m   2875\u001b[39m     \u001b[38;5;66;03m# todo update domain\u001b[39;00m\n",
      "\u001b[32m   2876\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_domain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n",
      "\u001b[32m   2877\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(value, (IrregularTimeSeries, RegularTimeSeries, Interval))\n",
      "\u001b[32m   2878\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, Data) \u001b[38;5;129;01mand\u001b[39;00m value.domain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m   2879\u001b[39m     ):\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2880\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_origin\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2881\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   2882\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = copy.copy(value)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2885\u001b[39m, in \u001b[36mData.slice\u001b[39m\u001b[34m(self, start, end, reset_origin)\u001b[39m\n",
      "\u001b[32m   2882\u001b[39m         out.\u001b[34m__dict__\u001b[39m[key] = copy.copy(value)\n",
      "\u001b[32m   2884\u001b[39m \u001b[38;5;66;03m# update domain\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2885\u001b[39m out._domain = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_domain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m&\u001b[49m\u001b[43m \u001b[49m\u001b[43mInterval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   2886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_origin:\n",
      "\u001b[32m   2887\u001b[39m     out._domain.start -= start\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2251\u001b[39m, in \u001b[36mInterval.__and__\u001b[39m\u001b[34m(self, other)\u001b[39m\n",
      "\u001b[32m   2246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__and__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n",
      "\u001b[32m   2247\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Intersection of two intervals.\u001b[39;00m\n",
      "\u001b[32m   2248\u001b[39m \u001b[33;03m    Only start/end times are considered for the intersection,\u001b[39;00m\n",
      "\u001b[32m   2249\u001b[39m \u001b[33;03m    and only start/end times are returned in the resulting Interval\u001b[39;00m\n",
      "\u001b[32m   2250\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2251\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mis_disjoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n",
      "\u001b[32m   2252\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mleft Interval object must be disjoint.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   2253\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other.is_disjoint():\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:1737\u001b[39m, in \u001b[36mInterval.is_disjoint\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m   1735\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[32m   1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tmp_copy.is_disjoint()\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1737\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(np.all(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m[:-\u001b[32m1\u001b[39m] <= \u001b[38;5;28mself\u001b[39m.start[\u001b[32m1\u001b[39m:]))\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/temporaldata/temporaldata/temporaldata.py:2403\u001b[39m, in \u001b[36mLazyInterval.__getattribute__\u001b[39m\u001b[34m(self, name)\u001b[39m\n",
      "\u001b[32m   2401\u001b[39m     out = out[\u001b[38;5;28mself\u001b[39m._lazy_ops[\u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[32m   2402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._lazy_ops) == \u001b[32m0\u001b[39m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m2403\u001b[39m     out = \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[32m   2405\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._unicode_keys:\n",
      "\u001b[32m   2406\u001b[39m     \u001b[38;5;66;03m# convert back to unicode\u001b[39;00m\n",
      "\u001b[32m   2407\u001b[39m     out = out.astype(\u001b[33m\"\u001b[39m\u001b[33mU\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:818\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, args, new_dtype)\u001b[39m\n",
      "\u001b[32m    806\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Read a slice from the HDF5 dataset.\u001b[39;00m\n",
      "\u001b[32m    807\u001b[39m \n",
      "\u001b[32m    808\u001b[39m \u001b[33;03mTakes slices and recarray-style field names (more than one is\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    814\u001b[39m \u001b[33;03m* Boolean \"mask\" array indexing\u001b[39;00m\n",
      "\u001b[32m    815\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    816\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (args,)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fast_read_ok\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m    820\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_reader.read(args)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n",
      "\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:800\u001b[39m, in \u001b[36mDataset._fast_read_ok\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    796\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n",
      "\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fast_read_ok\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is this dataset suitable for simple reading\"\"\"\u001b[39;00m\n",
      "\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n",
      "\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extent_type\u001b[49m == h5s.SIMPLE\n",
      "\u001b[32m    801\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.id.get_type(), (h5t.TypeIntegerID, h5t.TypeFloatID))\n",
      "\u001b[32m    802\u001b[39m     )\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/base.py:535\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n",
      "\u001b[32m    532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    536\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/h5py/_hl/dataset.py:679\u001b[39m, in \u001b[36mDataset._extent_type\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m    675\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n",
      "\u001b[32m    676\u001b[39m \u001b[38;5;129m@with_phil\u001b[39m\n",
      "\u001b[32m    677\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_extent_type\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[32m    678\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get extent type for this dataset - SIMPLE, SCALAR or NULL\"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.get_simple_extent_type()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5d.pyx:374\u001b[39m, in \u001b[36mh5py.h5d.DatasetID.get_space\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mRuntimeError\u001b[39m: Unable to synchronously get dataspace (identifier is not of specified type)"
     ]
    }
   ],
   "source": [
    "train_dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9033ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.0191875 s\n",
      "File: /cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py\n",
      "Function: get at line 315\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   315                                               def get(self, recording_id: str, start: float, end: float):\n",
      "   316                                                   r\"\"\"This is the main method to extract a slice from a recording. It returns a\n",
      "   317                                                   Data object that contains all data for recording :obj:`recording_id` between\n",
      "   318                                                   times :obj:`start` and :obj:`end`.\n",
      "   319                                           \n",
      "   320                                                   Args:\n",
      "   321                                                       recording_id: The recording id of the slice. This is usually\n",
      "   322                                                           <brainset_id>/<session_id>\n",
      "   323                                                       start: The start time of the slice.\n",
      "   324                                                       end: The end time of the slice.\n",
      "   325                                                   \"\"\"\n",
      "   326        10     719619.0  71961.9      3.8          data = self._get_data_object(recording_id)\n",
      "   327        10   17821543.0    2e+06     92.9          sample = data.slice(start, end)\n",
      "   328                                           \n",
      "   329        10      10712.0   1071.2      0.1          if self._check_for_data_leakage_flag and self.split is not None:\n",
      "   330                                                       sample._check_for_data_leakage(self.split)\n",
      "   331                                           \n",
      "   332        10     609784.0  60978.4      3.2          self._update_data_with_prefixed_ids(sample)\n",
      "   333        10      23238.0   2323.8      0.1          sample.config = self.recording_dict[recording_id][\"config\"]\n",
      "   334                                           \n",
      "   335        10       2631.0    263.1      0.0          return sample\n",
      "\n",
      "Total time: 0.000688532 s\n",
      "File: /cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py\n",
      "Function: _get_data_object at line 337\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   337                                               def _get_data_object(self, recording_id: str):\n",
      "   338        10       6824.0    682.4      1.0          if self.keep_files_open or self.lazy==False:\n",
      "   339        10     681708.0  68170.8     99.0              return copy.copy(self._data_objects[recording_id])\n",
      "   340                                                   else:\n",
      "   341                                                       file = h5py.File(self.recording_dict[recording_id][\"filename\"], \"r\")\n",
      "   342                                                       return Data.from_hdf5(file, lazy=self.lazy)\n",
      "\n",
      "Total time: 0.000553523 s\n",
      "File: /cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/data_utils/dataset.py\n",
      "Function: _update_data_with_prefixed_ids at line 436\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   436                                               def _update_data_with_prefixed_ids(self, data: Data):\n",
      "   437                                                   r\"\"\"Inplace add prefixes to unit ids, session id, and subect id\"\"\"\n",
      "   438        10      10399.0   1039.9      1.9          if hasattr(data, \"units\"):\n",
      "   439        10     457191.0  45719.1     82.6              data.units.id = self._get_unit_ids_with_prefix(data)\n",
      "   440                                           \n",
      "   441        10       4759.0    475.9      0.9          if hasattr(data, \"session\"):\n",
      "   442        10      43318.0   4331.8      7.8              data.session.id = self._get_session_id_with_prefix(data)\n",
      "   443                                           \n",
      "   444        10       4364.0    436.4      0.8          if hasattr(data, \"subject\"):\n",
      "   445        10      33492.0   3349.2      6.1              data.subject.id = self._get_subject_id_with_prefix(data)\n",
      "\n",
      "Total time: 0 s\n",
      "File: /cs/student/projects1/ml/2024/mlaimon/torch_brain/torch_brain/models/poyo.py\n",
      "Function: tokenize at line 260\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   260                                               def tokenize(self, data: Data) -> Dict:\n",
      "   261                                                   r\"\"\"Tokenizer used to tokenize Data for the POYO model.\n",
      "   262                                           \n",
      "   263                                                   This tokenizer can be called as a transform. If you are applying multiple\n",
      "   264                                                   transforms, make sure to apply this one last.\n",
      "   265                                           \n",
      "   266                                                   This code runs on CPU. Do not access GPU tensors inside this function.\n",
      "   267                                                   \"\"\"\n",
      "   268                                           \n",
      "   269                                                   # context window\n",
      "   270                                                   start, end = 0, self.sequence_length\n",
      "   271                                           \n",
      "   272                                                   ### prepare input\n",
      "   273                                                   unit_ids = data.units.id\n",
      "   274                                                   spike_unit_index = data.spikes.unit_index\n",
      "   275                                                   spike_timestamps = data.spikes.timestamps\n",
      "   276                                           \n",
      "   277                                                   # create start and end tokens for each unit\n",
      "   278                                                   (\n",
      "   279                                                       se_token_type_index,\n",
      "   280                                                       se_unit_index,\n",
      "   281                                                       se_timestamps,\n",
      "   282                                                   ) = create_start_end_unit_tokens(unit_ids, start, end)\n",
      "   283                                           \n",
      "   284                                                   # append start and end tokens to the spike sequence\n",
      "   285                                                   spike_token_type_index = np.concatenate(\n",
      "   286                                                       [se_token_type_index, np.zeros_like(spike_unit_index)]\n",
      "   287                                                   )\n",
      "   288                                                   spike_unit_index = np.concatenate([se_unit_index, spike_unit_index])\n",
      "   289                                                   spike_timestamps = np.concatenate([se_timestamps, spike_timestamps])\n",
      "   290                                           \n",
      "   291                                                   # unit_index is relative to the recording, so we want it to map it to\n",
      "   292                                                   # the global unit index\n",
      "   293                                                   local_to_global_map = np.array(self.unit_emb.tokenizer(unit_ids))\n",
      "   294                                                   spike_unit_index = local_to_global_map[spike_unit_index]\n",
      "   295                                           \n",
      "   296                                                   ### prepare latents\n",
      "   297                                                   latent_index, latent_timestamps = create_linspace_latent_tokens(\n",
      "   298                                                       start,\n",
      "   299                                                       end,\n",
      "   300                                                       step=self.latent_step,\n",
      "   301                                                       num_latents_per_step=self.num_latents_per_step,\n",
      "   302                                                   )\n",
      "   303                                           \n",
      "   304                                                   output_timestamps, output_values, output_weights, eval_mask = (\n",
      "   305                                                       prepare_for_readout(data, self.readout_spec)\n",
      "   306                                                   )\n",
      "   307                                           \n",
      "   308                                                   # create session index for output\n",
      "   309                                                   output_session_index = self.session_emb.tokenizer(data.session.id)\n",
      "   310                                                   output_session_index = np.repeat(output_session_index, len(output_timestamps))\n",
      "   311                                           \n",
      "   312                                                   data_dict = {\n",
      "   313                                                       \"model_inputs\": {\n",
      "   314                                                           # input sequence (keys/values for the encoder)\n",
      "   315                                                           \"input_unit_index\": pad8(spike_unit_index),\n",
      "   316                                                           \"input_timestamps\": pad8(spike_timestamps),\n",
      "   317                                                           \"input_token_type\": pad8(spike_token_type_index),\n",
      "   318                                                           \"input_mask\": track_mask8(spike_unit_index),\n",
      "   319                                                           # latent sequence\n",
      "   320                                                           \"latent_index\": latent_index,\n",
      "   321                                                           \"latent_timestamps\": latent_timestamps,\n",
      "   322                                                           # output query sequence (queries for the decoder)\n",
      "   323                                                           \"output_session_index\": pad8(output_session_index),\n",
      "   324                                                           \"output_timestamps\": pad8(output_timestamps),\n",
      "   325                                                           \"output_mask\": track_mask8(output_session_index),\n",
      "   326                                                       },\n",
      "   327                                                       # ground truth targets\n",
      "   328                                                       \"target_values\": pad8(output_values),\n",
      "   329                                                       \"target_weights\": pad8(output_weights),\n",
      "   330                                                       # extra data needed for evaluation\n",
      "   331                                                       \"session_id\": data.session.id,\n",
      "   332                                                       \"absolute_start\": data.absolute_start,\n",
      "   333                                                       \"eval_mask\": pad8(eval_mask),\n",
      "   334                                                   }\n",
      "   335                                           \n",
      "   336                                                   return data_dict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Profile the get method\n",
    "profiler = LineProfiler()\n",
    "profiler.add_function(train_dataset.get)\n",
    "profiler.add_function(train_dataset._get_data_object)\n",
    "profiler.add_function(train_dataset._update_data_with_prefixed_ids)\n",
    "profiler.add_function(train_dataset.transform)\n",
    "\n",
    "# Run profiling\n",
    "profiler.enable_by_count()\n",
    "for i in range(10):  # Profile first 10 calls\n",
    "    sample = train_dataset.get(\"perich_miller_population_2018/c_20131003_center_out_reaching\", 0.0, 1.0)\n",
    "profiler.disable_by_count()\n",
    "\n",
    "# Print results\n",
    "profiler.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95dd276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [00:28,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per batch: 0.21331487831316495 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from foundational_ssm.data_utils.loaders import transform_brainsets_to_fixed_dim_samples_with_binning_and_smoothing, transform_brainsets_to_fixed_dim_samples\n",
    "\n",
    "\n",
    "train_sampler = RandomFixedWindowSampler(\n",
    "    sampling_intervals=train_sampling_intervals,\n",
    "    window_length=1.0,\n",
    "    # batch_size=256,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    "    batch_size=1024,\n",
    ")\n",
    "train_dataset.transform = transform_brainsets_to_fixed_dim_samples\n",
    "\n",
    "poyo_tokenize_time = np.zeros(1000)\n",
    "start_time = time.time()\n",
    "for i, batch in tqdm(enumerate(train_loader)):\n",
    "    poyo_tokenize_time[i] = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "poyo_tokenize_time = poyo_tokenize_time[poyo_tokenize_time != 0]\n",
    "#print the average time per batch\n",
    "print(f\"Average time per batch: {np.mean(poyo_tokenize_time)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf55bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Skipping 107.37806666666742 seconds of data due to short intervals. Remaining: 107778.0 seconds.\n",
      "106it [00:42,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from foundational_ssm.data_utils.loaders import transform_brainsets_to_fixed_dim_samples_with_binning_and_smoothing, transform_brainsets_to_fixed_dim_samples\n",
    "\n",
    "\n",
    "train_sampler = RandomFixedWindowSampler(\n",
    "    sampling_intervals=train_sampling_intervals,\n",
    "    window_length=1.0,\n",
    "    # batch_size=256,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    "    batch_size=1024,\n",
    ")\n",
    "train_dataset.transform = transform_brainsets_to_fixed_dim_samples_with_binning_and_smoothing\n",
    "\n",
    "poyo_tokenize_time = np.zeros(1000)\n",
    "start_time = time.time()\n",
    "for i, batch in tqdm(enumerate(train_loader)):\n",
    "    poyo_tokenize_time[i] = time.time() - start_time\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3697faca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [00:53,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "from foundational_ssm.data_utils.loaders import transform_brainsets_to_fixed_dim_samples_with_binning_and_smoothing, transform_brainsets_to_fixed_dim_samples\n",
    "\n",
    "\n",
    "train_sampler = RandomFixedWindowSampler(\n",
    "    sampling_intervals=train_sampling_intervals,\n",
    "    window_length=1.0,\n",
    "    # batch_size=256,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate,\n",
    "    num_workers=12,\n",
    "    pin_memory=True,\n",
    "    batch_size=1024,\n",
    ")\n",
    "train_dataset.transform = transform_brainsets_to_fixed_dim_samples_with_binning_and_smoothing\n",
    "\n",
    "poyo_tokenize_time = np.zeros(1000)\n",
    "start_time = time.time()\n",
    "for i, batch in tqdm(enumerate(train_loader)):\n",
    "    poyo_tokenize_time[i] = time.time() - start_time\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279001c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
