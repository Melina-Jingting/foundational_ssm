{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95df258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_brain.data import Dataset, collate, chain\n",
    "from foundational_ssm.data_utils import get_dataset_config\n",
    "from torch_brain.data.sampler import RandomFixedWindowSampler, SequentialFixedWindowSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from foundational_ssm.constants import DATA_ROOT\n",
    "from foundational_ssm.data_utils.samplers import GroupedRandomFixedWindowSampler\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Data leakage check is disabled. Please be absolutely sure that there is no leakage between train and other splits.\n"
     ]
    }
   ],
   "source": [
    "config_path = \"/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/configs/pretrain.yaml\"\n",
    "cfg = OmegaConf.load(config_path) \n",
    "train_dataset = Dataset(\n",
    "    root=DATA_ROOT,\n",
    "    config=get_dataset_config(\n",
    "        cfg.train_dataset.name,\n",
    "        subjects=cfg.train_dataset.subjects\n",
    "    ),\n",
    "    split=\"train\",\n",
    ")\n",
    "train_sampling_intervals = train_dataset.get_sampling_intervals()\n",
    "train_dataset.disable_data_leakage_check()\n",
    "\n",
    "from torch_brain.models import POYO\n",
    "from torch_brain.registry import MODALITY_REGISTRY\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Any, Dict\n",
    "\n",
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "poyo_model = POYO(\n",
    "    sequence_length=1.0,\n",
    "    readout_spec=MODALITY_REGISTRY['cursor_velocity_2d'],\n",
    "    latent_step=1.0 / 8,\n",
    "    num_latents_per_step=16,\n",
    "    dim=64,\n",
    "    depth=6,\n",
    "    dim_head=64,\n",
    "    cross_heads=2,\n",
    "    self_heads=8,\n",
    ").to(device)\n",
    "poyo_model.unit_emb.initialize_vocab(train_dataset.get_unit_ids())\n",
    "poyo_model.session_emb.initialize_vocab(train_dataset.get_session_ids())\n",
    "\n",
    "\n",
    "def transform_brainsets_to_fixed_dim_samples(\n",
    "    data: Any,\n",
    "    sampling_rate: int = 100,\n",
    "    sampling_window_ms: int = 1000\n",
    ") -> Dict[str, torch.Tensor | str]:\n",
    "    \"\"\"Convert a *temporaldata* sample to a dictionary of Torch tensors.\n",
    "\n",
    "    The function takes care of binning & smoothing spikes, cropping/padding neural\n",
    "    and behavioural features to a globally consistent dimensionality that depends\n",
    "    on the *(dataset, subject, task)* triple.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: temporaldata.Data\n",
    "        Sample returned by **torch-brain**/**temporaldata**.\n",
    "    sampling_rate: int, default=100\n",
    "        Target sampling rate *Hz* used for binning.\n",
    "    sampling_window_ms: int, default=1000   \n",
    "        Length of the temporal window after binning.\n",
    "    kern_sd_ms: int, default=20\n",
    "        Standard deviation of the Gaussian kernel (in ms) for smoothing spikes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, torch.Tensor]\n",
    "        Dictionary with keys ``neural_input``, ``behavior_input``, ``session_id``\n",
    "        and ``subject_id``.\n",
    "    \"\"\"\n",
    "    def _ensure_dim(arr: np.ndarray, target_dim: int, pad_value: float = 0.0, *, axis: int = 1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Crop or pad `arr` along `axis` to match `target_dim`, right-aligning the original data.\n",
    "        Pads with `pad_value` if needed.\n",
    "        \"\"\"\n",
    "        current_dim = arr.shape[axis]\n",
    "        \n",
    "        # Pad if too small\n",
    "        shape = list(arr.shape)\n",
    "        shape[axis] = target_dim\n",
    "        result = np.full(shape, pad_value, dtype=arr.dtype)\n",
    "        \n",
    "        # Right-align: place arr at the end along the axis\n",
    "        idx = [slice(None)] * arr.ndim\n",
    "        idx[axis] = slice(-current_dim, None)\n",
    "        result[tuple(idx)] = arr\n",
    "        return result\n",
    "    \n",
    "    num_timesteps = int(sampling_rate * sampling_window_ms / 1000)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. Bin + smooth spikes\n",
    "    # ------------------------------------------------------------------\n",
    "    smoothed_spikes = data.smoothed_spikes.smoothed_spikes\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. Prepare behaviour signal (cursor velocity)\n",
    "    # ------------------------------------------------------------------\n",
    "    behavior_input = data.cursor.vel  # np.ndarray, (timesteps?, features)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. Align channel dimensions based on (dataset, subject, task)\n",
    "    # ------------------------------------------------------------------\n",
    "    smoothed_spikes = _ensure_dim(smoothed_spikes, 353, axis=1)\n",
    "    behavior_input = _ensure_dim(behavior_input, 2, axis=1)\n",
    "    smoothed_spikes = _ensure_dim(smoothed_spikes, num_timesteps, axis=0)\n",
    "    behavior_input = _ensure_dim(behavior_input, num_timesteps, axis=0)\n",
    "    # smoothed_spikes = smoothed_spikes[:80, :10]\n",
    "    # behavior_input = behavior_input[:80, :2]\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4. Pack into torch tensors\n",
    "    # ------------------------------------------------------------------\n",
    "    # dataset, subject, task = parse_session_id(data.session.id)\n",
    "    # group_tuple = (dataset, subject, task)\n",
    "    # group_idx = DATASET_GROUP_TO_IDX[group_tuple]\n",
    "\n",
    "    return {\n",
    "        \"neural_input\": torch.as_tensor(smoothed_spikes, dtype=torch.float32),\n",
    "        \"behavior_input\": torch.as_tensor(behavior_input, dtype=torch.float32),\n",
    "        # \"dataset_group_idx\": torch.as_tensor(group_idx, dtype=torch.int32),\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016c09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Skipping 107.37806666666742 seconds of data due to short intervals. Remaining: 107778.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.5574705600738525 seconds\n",
      "Time taken: 0.40118980407714844 seconds\n",
      "Time taken: 0.0017473697662353516 seconds\n",
      "Time taken: 0.0007100105285644531 seconds\n",
      "Time taken: 2.014241933822632 seconds\n",
      "Time taken: 0.13263964653015137 seconds\n",
      "Time taken: 0.0009927749633789062 seconds\n",
      "Time taken: 0.0015914440155029297 seconds\n",
      "Time taken: 1.6969027519226074 seconds\n",
      "Time taken: 0.19640517234802246 seconds\n",
      "Time taken: 0.001524209976196289 seconds\n",
      "Time taken: 0.0007107257843017578 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "train_sampler = RandomFixedWindowSampler(\n",
    "    sampling_intervals=train_sampling_intervals,\n",
    "    window_length=1.0,\n",
    "    # batch_size=256,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    batch_size=256,\n",
    ")\n",
    "train_dataset.transform = poyo_model.tokenize\n",
    "\n",
    "prev_start_time = time.time()\n",
    "for i, batch in enumerate(train_loader):\n",
    "    start_time = time.time()\n",
    "    print(f\"Time taken: {start_time - prev_start_time} seconds\")\n",
    "    prev_start_time = start_time\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95dd276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Skipping 107.37806666666742 seconds of data due to short intervals. Remaining: 107778.0 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 4.721935272216797 seconds\n",
      "Time taken: 1.561842441558838 seconds\n",
      "Time taken: 0.001127481460571289 seconds\n",
      "Time taken: 5.91278076171875e-05 seconds\n",
      "Time taken: 2.118638038635254 seconds\n",
      "Time taken: 0.0010046958923339844 seconds\n",
      "Time taken: 0.7510652542114258 seconds\n",
      "Time taken: 0.0008804798126220703 seconds\n",
      "Time taken: 2.420652151107788 seconds\n",
      "Time taken: 0.0010461807250976562 seconds\n",
      "Time taken: 0.6492063999176025 seconds\n",
      "Time taken: 0.0013842582702636719 seconds\n",
      "Time taken: 3.3137524127960205 seconds\n",
      "Time taken: 0.0006413459777832031 seconds\n",
      "Time taken: 6.723403930664062e-05 seconds\n",
      "Time taken: 0.6956057548522949 seconds\n",
      "Time taken: 2.3636980056762695 seconds\n",
      "Time taken: 0.0008573532104492188 seconds\n",
      "Time taken: 0.6097381114959717 seconds\n",
      "Time taken: 1.0648438930511475 seconds\n",
      "Time taken: 2.3183610439300537 seconds\n",
      "Time taken: 0.0002963542938232422 seconds\n",
      "Time taken: 0.4427821636199951 seconds\n",
      "Time taken: 0.9433753490447998 seconds\n",
      "Time taken: 1.2553966045379639 seconds\n",
      "Time taken: 0.0008227825164794922 seconds\n",
      "Time taken: 1.2898879051208496 seconds\n",
      "Time taken: 0.22584247589111328 seconds\n",
      "Time taken: 2.4208948612213135 seconds\n",
      "Time taken: 0.0015172958374023438 seconds\n",
      "Time taken: 0.36599183082580566 seconds\n",
      "Time taken: 0.7807586193084717 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m train_dataset.transform = transform_brainsets_to_fixed_dim_samples\n\u001b[32m     15\u001b[39m prev_start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTime taken: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart_time\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43m-\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mprev_start_time\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m seconds\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_sampler = GroupedRandomFixedWindowSampler(\n",
    "    sampling_intervals=train_sampling_intervals,\n",
    "    window_length=1.0,\n",
    "    batch_size=256,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_sampler=train_sampler,\n",
    "    collate_fn=collate,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "train_dataset.transform = transform_brainsets_to_fixed_dim_samples\n",
    "\n",
    "prev_start_time = time.time()\n",
    "for i, batch in enumerate(train_loader):\n",
    "    start_time = time.time()\n",
    "    print(f\"Time taken: {start_time - prev_start_time} seconds\")\n",
    "    prev_start_time = start_time\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55bc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
