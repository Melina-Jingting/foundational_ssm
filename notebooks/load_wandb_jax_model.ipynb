{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5564e9a3",
   "metadata": {},
   "source": [
    "# Load trained models and generated trajectories from Wandb\n",
    "You will need to: \n",
    "1. Enroll in Wandb project `foundational_ssm_nlb`\n",
    "2. Check runs in the project for all trained models. \n",
    "3. Download the original dataset from huggingface `https://huggingface.co/datasets/MelinaLaimon/nlb_processed/tree/main`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd5793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb \n",
    "from foundational_ssm.models import SSMFoundational\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from foundational_ssm.utils import load_model_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b1cec",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5f31f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "wandb_account = \"melinajingting-ucl\"\n",
    "project = \"foundational_ssm_pretrain_decoding\"\n",
    "run_name = \"perich_miller_population_2018_l3_d64\" # Change this to the desired run name\n",
    "version = \"v3\"\n",
    "\n",
    "model_artifact_full_name = f\"{wandb_account}/{project}/{run_name}_best_model:{version}\"\n",
    "model_artifact = api.artifact(model_artifact_full_name, type=\"model\")\n",
    "model_artifact_dir = model_artifact.download()\n",
    "\n",
    "model_filename = os.path.join(model_artifact_dir, 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2606a97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'foundational_ssm.models.s4d'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfoundational_ssm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SSMFoundational\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mequinox\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01meqx\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/models/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfoundational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SSMFoundational, S4DNeuroModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01ms4d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S4D, S4DKernel \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01ms5\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S5\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/models/foundational.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Dict\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Import model components\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01ms4d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S4D\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Import data processing utilities\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfoundational_ssm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bin_spikes, map_binned_features_to_global\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'foundational_ssm.models.s4d'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from foundational_ssm.models import SSMFoundational\n",
    "import equinox as eqx\n",
    "import jax.random as jr\n",
    "\n",
    "with open(model_filename, \"rb\") as f:\n",
    "    hyperparams = json.loads(f.readline().decode())\n",
    "    model = SSMFoundational(**hyperparams, key=jr.PRNGKey(0))\n",
    "    model = eqx.tree_deserialise_leaves(f, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da77c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "from foundational_ssm.utils.training import load_model_and_state\n",
    "from foundational_ssm.utils.training import get_filter_spec\n",
    "import equinox as eqx\n",
    "\n",
    "model, state = load_model_and_state(wandb_pretrained_model_id=\"melinajingting-ucl/foundational_ssm_pretrain_decoding/train_batch-1024_sub-cmtj_l1_d128_best_model:v3\")\n",
    "opt = optax.adamw(learning_rate=0.001, weight_decay=0.001)\n",
    "filter_spec = get_filter_spec(\n",
    "        model,\n",
    "        freeze_ssm=True,\n",
    "        freeze_mlp=True\n",
    "    )\n",
    "opt_state = opt.init(eqx.filter(model, filter_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def save_checkpoint_wandb(model, state, opt_state, epoch, step, run_name):\n",
    "    \"\"\"Save model, optimizer state, epoch, and step to a checkpoint file.\"\"\"\n",
    "    with open('checkpoint.ckpt', 'wb') as f:\n",
    "        # Write metadata as JSON in the first line\n",
    "        meta = json.dumps({'epoch': epoch, 'step': step})\n",
    "        f.write((meta + '\\n').encode())\n",
    "        eqx.tree_serialise_leaves(f, model)\n",
    "        eqx.tree_serialise_leaves(f, state)\n",
    "        eqx.tree_serialise_leaves(f, opt_state)\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f'{run_name}_checkpoint',  # Name for the artifact\n",
    "        type=\"checkpoint\",                # Artifact type (can be \"model\", \"checkpoint\", etc.)\n",
    "        description=f\"Checkpoint at epoch {epoch}\",\n",
    "    )\n",
    "    wandb.log_artifact(artifact)\n",
    "    \n",
    "\n",
    "def load_checkpoint_wandb(model_template, state_template, opt_state_template, wandb_run_name, wandb_project, wandb_entity):\n",
    "    \"\"\"Load model, optimizer state, epoch, and step from a checkpoint file.\"\"\"\n",
    "    api = wandb.Api()\n",
    "    artifact_full_name = f\"{wandb_entity}/{wandb_project}/{wandb_run_name}_checkpoint:latest\"\n",
    "    artifact = api.artifact(artifact_full_name, type=\"checkpoint\")\n",
    "    dir = artifact.download()\n",
    "    path = os.path.join(dir, 'checkpoint.ckpt')\n",
    "    with open(path, 'rb') as f:\n",
    "        meta = json.loads(f.readline().decode())\n",
    "        model = eqx.tree_deserialise_leaves(f, model_template)\n",
    "        state = eqx.tree_deserialise_leaves(f, state_template)\n",
    "        opt_state = eqx.tree_deserialise_leaves(f, opt_state_template)\n",
    "    return model, state, opt_state, meta['epoch'], meta['step']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06567148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>67</td></tr><tr><td>system/cpu_percent</td><td>0</td></tr><tr><td>system/memory_rss_mb</td><td>52669.14099</td></tr><tr><td>timing/batch_process_sec</td><td>1.43222</td></tr><tr><td>timing/batches_per_minute</td><td>38</td></tr><tr><td>timing/data_load_sec</td><td>0.00027</td></tr><tr><td>train/epoch_loss</td><td>5155.03662</td></tr><tr><td>train/learning_rate</td><td>0.001</td></tr><tr><td>train/loss</td><td>39.16758</td></tr><tr><td>val/epoch_time_sec</td><td>26.22102</td></tr><tr><td>val/memory_rss_mb</td><td>49017.22931</td></tr><tr><td>val/r2_pm_c_co</td><td>0.40517</td></tr><tr><td>val/r2_pm_c_rt</td><td>0.42991</td></tr><tr><td>val/r2_pm_j_co</td><td>0.31942</td></tr><tr><td>val/r2_pm_m_co</td><td>0.46819</td></tr><tr><td>val/r2_pm_m_rt</td><td>0.60547</td></tr><tr><td>val/r2_pm_t_co</td><td>0.2172</td></tr><tr><td>val/r2_pm_t_rt</td><td>0.2456</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train_batch-1024_sub-cmtj_l1_d128</strong> at: <a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding/runs/cr6zuzfw' target=\"_blank\">https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding/runs/cr6zuzfw</a><br> View project at: <a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding' target=\"_blank\">https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250707_164246-cr6zuzfw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/notebooks/wandb/run-20250707_164406-cr6zuzfw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding/runs/cr6zuzfw' target=\"_blank\">train_batch-1024_sub-cmtj_l1_d128</a></strong> to <a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding' target=\"_blank\">https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding/runs/cr6zuzfw' target=\"_blank\">https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding/runs/cr6zuzfw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>67</td></tr><tr><td>system/cpu_percent</td><td>0</td></tr><tr><td>system/memory_rss_mb</td><td>52669.14099</td></tr><tr><td>timing/batch_process_sec</td><td>1.43222</td></tr><tr><td>timing/batches_per_minute</td><td>38</td></tr><tr><td>timing/data_load_sec</td><td>0.00027</td></tr><tr><td>train/epoch_loss</td><td>5155.03662</td></tr><tr><td>train/learning_rate</td><td>0.001</td></tr><tr><td>train/loss</td><td>39.16758</td></tr><tr><td>val/epoch_time_sec</td><td>26.22102</td></tr><tr><td>val/memory_rss_mb</td><td>49017.22931</td></tr><tr><td>val/r2_pm_c_co</td><td>0.40517</td></tr><tr><td>val/r2_pm_c_rt</td><td>0.42991</td></tr><tr><td>val/r2_pm_j_co</td><td>0.31942</td></tr><tr><td>val/r2_pm_m_co</td><td>0.46819</td></tr><tr><td>val/r2_pm_m_rt</td><td>0.60547</td></tr><tr><td>val/r2_pm_t_co</td><td>0.2172</td></tr><tr><td>val/r2_pm_t_rt</td><td>0.2456</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train_batch-1024_sub-cmtj_l1_d128</strong> at: <a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding/runs/cr6zuzfw' target=\"_blank\">https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding/runs/cr6zuzfw</a><br> View project at: <a href='https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding' target=\"_blank\">https://wandb.ai/melinajingting-ucl/foundational_ssm_pretrain_decoding</a><br>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250707_164406-cr6zuzfw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Set your entity, project, and run ID\n",
    "entity = \"melinajingting-ucl\"\n",
    "project = \"foundational_ssm_pretrain_decoding\"\n",
    "run_id = \"cr6zuzfw\"  # The run you want to attach the artifact to\n",
    "run_name = 'train_batch-1024_sub-cmtj_l1_d128'\n",
    "epoch = 60\n",
    "step = 19124\n",
    "\n",
    "# Path to your checkpoint file\n",
    "ckpt_path = \"checkpoint.ckpt\"  # or \"best_model\" if that's your file\n",
    "\n",
    "# Initialize existing run to upload checkpoint\n",
    "api = wandb.Api()\n",
    "run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "wandb.init(entity=entity, project=project, id=run_id, resume=\"allow\")\n",
    "save_checkpoint_wandb(model, state, opt_state, epoch, step, run_name)\n",
    "wandb.finish()\n",
    "\n",
    "model, state, opt_state, epoch, step = load_checkpoint_wandb(model, state, opt_state, wandb_run_name=run_name, wandb_project='foundational_ssm_pretrain_decoding', wandb_entity='melinajingting-ucl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612528cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
