{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5564e9a3",
   "metadata": {},
   "source": [
    "# Load trained models and generated trajectories from Wandb\n",
    "You will need to: \n",
    "1. Enroll in Wandb project `foundational_ssm_nlb`\n",
    "2. Check runs in the project for all trained models. \n",
    "3. Download the original dataset from huggingface `https://huggingface.co/datasets/MelinaLaimon/nlb_processed/tree/main`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd5793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb \n",
    "from foundational_ssm.models import SSMFoundational\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from foundational_ssm.utils import load_model_wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b1cec",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5f31f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "wandb_account = \"melinajingting-ucl\"\n",
    "project = \"foundational_ssm_pretrain_decoding\"\n",
    "run_name = \"perich_miller_population_2018_l3_d64\" # Change this to the desired run name\n",
    "version = \"v3\"\n",
    "\n",
    "model_artifact_full_name = f\"{wandb_account}/{project}/{run_name}_best_model:{version}\"\n",
    "model_artifact = api.artifact(model_artifact_full_name, type=\"model\")\n",
    "model_artifact_dir = model_artifact.download()\n",
    "\n",
    "model_filename = os.path.join(model_artifact_dir, 'best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2606a97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'foundational_ssm.models.s4d'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfoundational_ssm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SSMFoundational\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mequinox\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01meqx\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjax\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrandom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/models/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfoundational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SSMFoundational, S4DNeuroModel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01ms4d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S4D, S4DKernel \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01ms5\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S5\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cs/student/projects1/ml/2024/mlaimon/foundational_ssm/src/foundational_ssm/models/foundational.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Dict\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Import model components\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01ms4d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m S4D\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Import data processing utilities\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfoundational_ssm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bin_spikes, map_binned_features_to_global\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'foundational_ssm.models.s4d'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from foundational_ssm.models import SSMFoundational\n",
    "import equinox as eqx\n",
    "import jax.random as jr\n",
    "\n",
    "with open(model_filename, \"rb\") as f:\n",
    "    hyperparams = json.loads(f.readline().decode())\n",
    "    model = SSMFoundational(**hyperparams, key=jr.PRNGKey(0))\n",
    "    model = eqx.tree_deserialise_leaves(f, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da77c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "from foundational_ssm.utils.wandb_utils_jax import load_model_and_state_wandb\n",
    "from foundational_ssm.utils.training import get_filter_spec\n",
    "import equinox as eqx\n",
    "\n",
    "model, state = load_model_and_state_wandb(wandb_pretrained_model_id=\"melinajingting-ucl/foundational_ssm_pretrain_decoding/train_batch-1024_sub-cmtj_l1_d128_best_model:v3\")\n",
    "opt = optax.adamw(learning_rate=0.001, weight_decay=0.001)\n",
    "filter_spec = get_filter_spec(\n",
    "        model,\n",
    "        freeze_ssm=False,\n",
    "        freeze_mlp=False\n",
    "    )\n",
    "opt_state = opt.init(eqx.filter(model, filter_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def save_checkpoint_wandb(model, state, opt_state, epoch, step, run_name):\n",
    "    \"\"\"Save model, optimizer state, epoch, and step to a checkpoint file.\"\"\"\n",
    "    with open('checkpoint.ckpt', 'wb') as f:\n",
    "        # Write metadata as JSON in the first line\n",
    "        meta = json.dumps({'epoch': epoch, 'step': step})\n",
    "        f.write((meta + '\\n').encode())\n",
    "        eqx.tree_serialise_leaves(f, model)\n",
    "        eqx.tree_serialise_leaves(f, state)\n",
    "        eqx.tree_serialise_leaves(f, opt_state)\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f'{run_name}_checkpoint',  # Name for the artifact\n",
    "        type=\"checkpoint\",                # Artifact type (can be \"model\", \"checkpoint\", etc.)\n",
    "        description=f\"Checkpoint at epoch {epoch}\",\n",
    "    )\n",
    "    wandb.log_artifact(artifact)\n",
    "    \n",
    "\n",
    "def load_checkpoint_wandb(path, model_template, state_template, opt_state_template, wandb_run_name, wandb_project, wandb_entity):\n",
    "    \"\"\"Load model, optimizer state, epoch, and step from a checkpoint file.\"\"\"\n",
    "    api = wandb.Api()\n",
    "    artifact_full_name = f\"{wandb_entity}/{wandb_project}/{wandb_run_name}_checkpoint:latest\"\n",
    "    artifact_save_path = f\"{wandb_run_name}\"\n",
    "    artifact = api.artifact(artifact_full_name, type=\"checkpoint\")\n",
    "    dir = artifact.download(artifact_save_path)\n",
    "    path = os.path.join(dir, 'checkpoint.ckpt')\n",
    "    with open(path, 'rb') as f:\n",
    "        meta = json.loads(f.readline().decode())\n",
    "        model = eqx.tree_deserialise_leaves(f, model_template)\n",
    "        state = eqx.tree_deserialise_leaves(f, state_template)\n",
    "        opt_state = eqx.tree_deserialise_leaves(f, opt_state_template)\n",
    "    return model, state, opt_state, meta['epoch'], meta['step'], meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06567148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Deserialised leaf at path (GetAttrKey(name='encoders'), SequenceKey(idx=0), GetAttrKey(name='weight')) has changed shape from (120, 353) in `like` to (56, 353) on disk.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     12\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# or \"best_model\" if that's your file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize existing run to upload checkpoint\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# api = wandb.Api()\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# run = api.run(f\"{entity}/{project}/{run_id}\")\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# wandb.init(entity=entity, project=project, id=run_id, resume=\"allow\")\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# save_checkpoint_wandb(model, state, opt_state, epoch, step, run_name)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# wandb.finish()\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m model, state, opt_state, epoch, step, meta \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint_wandb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_run_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_project\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfoundational_ssm_pretrain_decoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmelinajingting-ucl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m, in \u001b[0;36mload_checkpoint_wandb\u001b[0;34m(path, model_template, state_template, opt_state_template, wandb_run_name, wandb_project, wandb_entity)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m     meta \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(f\u001b[38;5;241m.\u001b[39mreadline()\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m---> 31\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_deserialise_leaves\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     state \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mtree_deserialise_leaves(f, state_template)\n\u001b[1;32m     33\u001b[0m     opt_state \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mtree_deserialise_leaves(f, opt_state_template)\n",
      "File \u001b[0;32m~/anaconda3/envs/foundational_ssm/lib/python3.11/site-packages/equinox/_serialisation.py:333\u001b[0m, in \u001b[0;36mtree_deserialise_leaves\u001b[0;34m(path_or_file, like, filter_spec, is_leaf)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/foundational_ssm/lib/python3.11/site-packages/jax/_src/tree_util.py:1166\u001b[0m, in \u001b[0;36mtree_map_with_path\u001b[0;34m(f, tree, is_leaf, is_leaf_takes_path, *rest)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/foundational_ssm/lib/python3.11/site-packages/jax/_src/tree_util.py:1166\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/foundational_ssm/lib/python3.11/site-packages/equinox/_serialisation.py:178\u001b[0m, in \u001b[0;36m_assert_same_impl\u001b[0;34m(path, new, old)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Deserialised leaf at path (GetAttrKey(name='encoders'), SequenceKey(idx=0), GetAttrKey(name='weight')) has changed shape from (120, 353) in `like` to (56, 353) on disk."
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Set your entity, project, and run ID\n",
    "entity = \"melinajingting-ucl\"\n",
    "project = \"foundational_ssm_pretrain_decoding\"\n",
    "run_id = \"cr6zuzfw\"  # The run you want to attach the artifact to\n",
    "run_name = 'train_batch-1024_sub-cmtj_l4_d64'\n",
    "epoch = 60\n",
    "step = 19124\n",
    "\n",
    "# Path to your checkpoint file\n",
    "ckpt_path = \"checkpoint.ckpt\"  # or \"best_model\" if that's your file\n",
    "\n",
    "# Initialize existing run to upload checkpoint\n",
    "# api = wandb.Api()\n",
    "# run = api.run(f\"{entity}/{project}/{run_id}\")\n",
    "# wandb.init(entity=entity, project=project, id=run_id, resume=\"allow\")\n",
    "# save_checkpoint_wandb(model, state, opt_state, epoch, step, run_name)\n",
    "# wandb.finish()\n",
    "\n",
    "model, state, opt_state, epoch, step, meta = load_checkpoint_wandb(path=ckpt_path, model_template=model, state_template=state, opt_state_template=opt_state, wandb_run_name=run_name, wandb_project='foundational_ssm_pretrain_decoding', wandb_entity='melinajingting-ucl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612528cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
