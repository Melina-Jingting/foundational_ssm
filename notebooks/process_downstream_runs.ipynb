{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "655b00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import t as student_t\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "# Build bootstrap samples DataFrame for single-recording tasks\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import math\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random as jr\n",
    "\n",
    "from foundational_ssm.utils.wandb_utils_jax import load_model_and_state_from_checkpoint_wandb\n",
    "from foundational_ssm.utils.downstream_utils import validate_one_epoch, get_nlb_datasets\n",
    "from foundational_ssm.models import SSMDownstreamDecoder\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Build agg_df with sample lists and patch with bootstrap samples for single-recording tasks\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def downstream_checkpoint_artifact(run_name: str, alias: str) -> str:\n",
    "    # Note: downstream sweep project name; run_name is exact W&B run display name\n",
    "    return f\"melinajingting-ucl/foundational_ssm_downstream_sweep/{run_name}_checkpoint:{alias}\"\n",
    "\n",
    "def load_eval_split(dataset_name: str, phase: str = \"test\", batch_size: int = 64, rng_seed: int = 0):\n",
    "    # Build a minimal dataset cfg for get_nlb_datasets\n",
    "    ds_cfg = OmegaConf.create({\n",
    "        \"name\": dataset_name,\n",
    "        \"phase\": phase,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"skip_timesteps\": 60,\n",
    "    })\n",
    "    key = jr.PRNGKey(rng_seed)\n",
    "    try:\n",
    "        train_data, val_data = get_nlb_datasets(ds_cfg, key, return_full=False)\n",
    "        # When phase=='test', get_nlb_datasets should return (train, test) or (None, test)\n",
    "        eval_data = val_data\n",
    "    except Exception:\n",
    "        # Fallback: set phase explicitly and re-try\n",
    "        ds_cfg.phase = phase\n",
    "        train_data, eval_data = get_nlb_datasets(ds_cfg, key, return_full=False)\n",
    "    return eval_data, ds_cfg\n",
    "\n",
    "def eval_model_once(eval_batch: Dict[str,np.ndarray], model, state, skip_timesteps: int = 60) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Run a single full-batch eval to get predictions and targets, respecting mask.\n",
    "    Returns (preds, targets, mask) as numpy arrays with skip_timesteps cropped.\"\"\"\n",
    "    batch = {k: jax.device_put(np.array(v)) for k, v in eval_batch.items()}\n",
    "    inputs = batch[\"neural_input\"]\n",
    "    targets = batch[\"behavior_input\"]\n",
    "    mask = batch[\"mask\"]\n",
    "    mask = mask[..., None]\n",
    "    inf_model = eqx.nn.inference_mode(model)\n",
    "    preds, _state = jax.vmap(inf_model, axis_name=\"batch\", in_axes=(0, None, None), out_axes=(0, None))(inputs, state, jr.PRNGKey(0))\n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    mask = np.array(mask)\n",
    "    if skip_timesteps > 0:\n",
    "        preds = preds[:, skip_timesteps:, :]\n",
    "        targets = targets[:, skip_timesteps:, :]\n",
    "        mask = mask[:, skip_timesteps:, :]\n",
    "    preds = np.where(mask, preds, 0)\n",
    "    targets = np.where(mask, targets, 0)\n",
    "    return preds, targets, mask\n",
    "\n",
    "\n",
    "def bootstrap_r2_from_trials(\n",
    "    preds: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    P: float = 1/6,\n",
    "    B: int = 1000,\n",
    "    rng: Optional[np.random.Generator] = None,\n",
    "    replace: bool = False,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Draw B subsamples of trials of size ~= P*N and compute R² for each.\n",
    "\n",
    "    Args:\n",
    "        preds: array (trials, timesteps, 2)\n",
    "        targets: array (trials, timesteps, 2)\n",
    "        P: proportion of trials per subsample (0 < P <= 1)\n",
    "        B: number of resamples\n",
    "        rng: optional NumPy Generator\n",
    "        replace: if True, sample with replacement (bootstrap-style). If False, without replacement.\n",
    "\n",
    "    Returns:\n",
    "        r2_samples: shape (B,) of R² values.\n",
    "    \"\"\"\n",
    "    N = int(preds.shape[0])\n",
    "    m = max(1, min(N, int(round(P * N))))\n",
    "    r2_samples = np.zeros((B,), dtype=float)\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "\n",
    "    for i in range(B):\n",
    "        idx = rng.choice(N, size=m, replace=replace)\n",
    "        preds_b = preds[idx].reshape(-1, 2)\n",
    "        targets_b = targets[idx].reshape(-1, 2)\n",
    "        r2_samples[i] = r2_score(targets_b, preds_b)\n",
    "    return r2_samples\n",
    "\n",
    "@dataclass\n",
    "class BootstrapRequest:\n",
    "    task: str\n",
    "    opt_mode: str\n",
    "    checkpoint_short: str\n",
    "    train_mode: str\n",
    "    run_name: str  # W&B display name\n",
    "\n",
    "\n",
    "def bootstrap_samples_for_request(req: BootstrapRequest, B: int = 500) -> Optional[pd.DataFrame]:\n",
    "    art = downstream_checkpoint_artifact(req.run_name, 'latest')\n",
    "    model, state, _ = load_model_and_state_from_checkpoint_wandb(art, model_cls=SSMDownstreamDecoder)\n",
    "    skip_timesteps = 60\n",
    "    batch_size = 64\n",
    "    eval_data, _ = load_eval_split(req.task, phase=\"test\", batch_size=batch_size)\n",
    "    preds, targets, mask = eval_model_once(eval_data, model, state, skip_timesteps=skip_timesteps)\n",
    "    \n",
    "    r2 = bootstrap_r2_from_trials(preds, targets, B=B)\n",
    "    # print(f\"overall R2 for {req.run_name}\",r2_score(targets.reshape(-1,2), preds.reshape(-1,2), sample_weight=mask.reshape(-1)))\n",
    "    # print(r2)\n",
    "    df = pd.DataFrame({\n",
    "        'task': req.task,\n",
    "        'opt_mode': req.opt_mode,\n",
    "        'checkpoint_short': req.checkpoint_short,\n",
    "        'train_mode': req.train_mode,\n",
    "        'run_name': req.run_name,\n",
    "        'sample': np.arange(len(r2)),\n",
    "        'r2': r2,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def pm_task_from_dataset(ds: str) -> str:\n",
    "    # Handle multiple naming styles:\n",
    "    # - pm_* suffixes: *_co -> center_out, *_rt -> random_target\n",
    "    # - recording ids like t_YYYYMMDD_center_out_reaching / random_target_reaching\n",
    "    if not isinstance(ds, str):\n",
    "        return \"unknown\"\n",
    "    if ds.endswith(\"_co\") or \"center_out_reaching\" in ds:\n",
    "        return \"pm_center_out\"\n",
    "    if ds.endswith(\"_rt\") or \"random_target_reaching\" in ds:\n",
    "        return \"pm_random_target\"\n",
    "    return ds  # fallback to original label\n",
    "\n",
    "def build_bootstrap_samples_df(raw_df: pd.DataFrame, tasks=(\"mc_rtt_prepend\",\"mc_area2bump_prepend\"), B: int = 500) -> pd.DataFrame:\n",
    "    samples = []\n",
    "    for task in tasks:\n",
    "        tdf = raw_df[raw_df['task'] == task] if 'task' in raw_df.columns else raw_df[raw_df['dataset'] == task]\n",
    "        if tdf.empty:\n",
    "            continue\n",
    "        for (om, ck, tm), g in tdf.groupby(['opt_mode','checkpoint_short','train_mode']):\n",
    "            if g.empty or 'run_name' not in g.columns:\n",
    "                continue\n",
    "            run_name = g['run_name'].iloc[0]\n",
    "            req = BootstrapRequest(task=task, opt_mode=str(om), checkpoint_short=ck, train_mode=tm, run_name=run_name)\n",
    "            df = bootstrap_samples_for_request(req, B=B)\n",
    "            if df is not None:\n",
    "                samples.append(df)\n",
    "    if not samples:\n",
    "        bs_df = pd.DataFrame(columns=['task','opt_mode','checkpoint_short','train_mode','run_name','sample','r2'])\n",
    "    else:\n",
    "        bs_df = pd.concat(samples, ignore_index=True)\n",
    "    return bs_df\n",
    "\n",
    "# Patch with bootstrap samples (store samples + overwrite mean/std/n if needed)\n",
    "\n",
    "def patch_agg_df_with_bootstrap_samples(agg_df_in: pd.DataFrame, raw_df: pd.DataFrame, tasks=(\"mc_rtt_prepend\",\"mc_area2bump_prepend\"), B: int = 500) -> pd.DataFrame:\n",
    "    out = agg_df_in.copy()\n",
    "    bs_df_local = build_bootstrap_samples_df(raw_df, tasks=tasks, B=B)\n",
    "    if bs_df_local is None or len(bs_df_local) == 0:\n",
    "        return out\n",
    "    key_cols = [\"task\",\"opt_mode\",\"checkpoint_short\",\"train_mode\"]\n",
    "    for key, g in bs_df_local.groupby(key_cols):\n",
    "        task, opt_mode, ck, tm = key\n",
    "        idx = out[(out[\"task\"] == task) & (out[\"opt_mode\"].astype(str) == str(opt_mode)) & (out[\"checkpoint_short\"] == ck) & (out[\"train_mode\"] == tm)].index\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        samples = g[\"r2\"].astype(float).values\n",
    "        s = float(np.nanstd(samples, ddof=1)) if len(samples) > 1 else 0.0\n",
    "        n = int(len(samples))\n",
    "        out.loc[idx, \"r2_mean\"] = samples.mean()\n",
    "        out.loc[idx, \"r2_std\"] = s\n",
    "        out.loc[idx, \"n\"] = n\n",
    "        out.loc[idx, \"r2_sample_source\"] = \"bootstrap\"\n",
    "        out.loc[idx, \"r2_samples\"] = tuple(samples)\n",
    "    return out\n",
    "\n",
    "def _infer_task_from_dataset(ds: str) -> str:\n",
    "    if not isinstance(ds, str):\n",
    "        return \"unknown\"\n",
    "    if ds.endswith(\"_co\") or \"center_out\" in ds:\n",
    "        return \"pm_center_out\"\n",
    "    if ds.endswith(\"_rt\") or \"random_target\" in ds:\n",
    "        return \"pm_random_target\"\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b0a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNSTREAM_PROJECT = \"melinajingting-ucl/foundational_ssm_downstream_sweep\"\n",
    "api = wandb.Api()\n",
    "runs = api.runs(DOWNSTREAM_PROJECT, filters={\"state\": \"finished\"})\n",
    "\n",
    "records = []\n",
    "for r in runs:\n",
    "    cfg = r.config or {}\n",
    "    # Extract sweep origin if present\n",
    "    sweep_name = r.sweep.name if getattr(r, \"sweep\", None) else None\n",
    "    # Find all final/r2/* in summary\n",
    "    for k, v in r.summary.items():\n",
    "        if isinstance(k, str) and k.startswith(\"final/r2/\"):\n",
    "            dataset = k[len(\"final/r2/\"):]\n",
    "            records.append({\n",
    "                \"run_id\": r.id,\n",
    "                \"run_name\": r.display_name,\n",
    "                \"sweep\": sweep_name,\n",
    "                \"dataset\": dataset,\n",
    "                \"r2\": v,\n",
    "                # Key config axes for comparisons\n",
    "                \"from_scratch\": cfg.get(\"training.from_scratch\"),\n",
    "                \"opt_mode\": cfg.get(\"optimizer.mode\"),  # all vs encoder_only\n",
    "                \"checkpoint\": cfg.get(\"model.checkpoint\"),\n",
    "                \"dataset_name\": cfg.get(\"dataset.name\") or cfg.get(\"dataset_args.recording_id\"),\n",
    "            })\n",
    "\n",
    "downstream_df = pd.DataFrame.from_records(records)\n",
    "downstream_df[\"task\"] = downstream_df[\"dataset\"].apply(_infer_task_from_dataset)\n",
    "downstream_df[\"train_mode\"] = downstream_df[\"from_scratch\"].map({True: \"scratch\", False: \"finetune\"}).fillna(\"unknown\")\n",
    "downstream_df[\"checkpoint_short\"] = downstream_df[\"checkpoint\"].apply(lambda s: s.split(\"/\")[-1].split(\":\")[0] if isinstance(s, str) else s)\n",
    "downstream_df[\"train_mode\"] = downstream_df[\"train_mode\"].astype(str).str.lower()\n",
    "downstream_df[\"is_pm\"] = downstream_df[\"dataset\"].apply(lambda dataset: isinstance(dataset, str) and (dataset.startswith(\"pm_\") or \"perich_miller\" in dataset or dataset.startswith(\"t_\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f3a176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated (mean/std) per (checkpoint, train_mode, opt_mode, task)\n",
    "agg_cols = [\"checkpoint_short\", \"train_mode\", \"opt_mode\", \"task\"]\n",
    "pm_agg = (\n",
    "    downstream_df[downstream_df[\"is_pm\"]]\n",
    "    .groupby(agg_cols)\n",
    "    .agg(r2_mean=(\"r2\", \"mean\"), r2_std=(\"r2\", \"std\"), n=(\"r2\", \"count\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "nlb_agg = (\n",
    "    downstream_df[~downstream_df[\"is_pm\"]]\n",
    "    .groupby(agg_cols)\n",
    "    .agg(r2_mean=(\"r2\", \"mean\"), r2_std=(\"r2\", \"std\"), n=(\"r2\", \"count\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg_df = pd.concat([pm_agg, nlb_agg], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks=(\"mc_rtt_prepend\",\"mc_area2bump_prepend\")\n",
    "B=100\n",
    "out = agg_df.copy()\n",
    "samples = []\n",
    "for task in tasks:\n",
    "    tdf = downstream_df[downstream_df['task'] == task] if 'task' in downstream_df.columns else downstream_df[downstream_df['dataset'] == task]\n",
    "    if tdf.empty:\n",
    "        continue\n",
    "    for (om, ck, tm), g in tdf.groupby(['opt_mode','checkpoint_short','train_mode']):\n",
    "        if g.empty or 'run_name' not in g.columns:\n",
    "            continue\n",
    "        run_name = g['run_name'].iloc[0]\n",
    "        req = BootstrapRequest(task=task, opt_mode=str(om), checkpoint_short=ck, train_mode=tm, run_name=run_name)\n",
    "        df = bootstrap_samples_for_request(req, B=B)\n",
    "        if df is not None:\n",
    "            samples.append(df)\n",
    "bs_df = pd.concat(samples, ignore_index=True)\n",
    "    \n",
    "key_cols = [\"task\",\"opt_mode\",\"checkpoint_short\",\"train_mode\"]\n",
    "for key, g in bs_df.groupby(key_cols):\n",
    "    task, opt_mode, ck, tm = key\n",
    "    idx = out[(out[\"task\"] == task) & (out[\"opt_mode\"].astype(str) == str(opt_mode)) & (out[\"checkpoint_short\"] == ck) & (out[\"train_mode\"] == tm)].index\n",
    "    if len(idx) == 0:\n",
    "        continue\n",
    "    samples = g[\"r2\"].astype(float).values\n",
    "    s = float(np.nanstd(samples, ddof=1)) if len(samples) > 1 else 0.0\n",
    "    n = int(len(samples))\n",
    "    out.loc[idx, \"r2_mean\"] = samples.mean()\n",
    "    out.loc[idx, \"r2_std\"] = s\n",
    "    out.loc[idx, \"n\"] = n\n",
    "    out.loc[idx, \"r2_sample_source\"] = \"bootstrap\"\n",
    "\n",
    "out.to_csv(\"results/main_downstream_performances_with_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cea0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  ndb\u001b[0m: \\ 1 of 3 files downloaded...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "/tmp/ipykernel_378943/639917935.py:163: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  v1 = jnp.asarray(K1, dtype=jnp.float64).reshape(-1)\n",
      "/tmp/ipykernel_378943/639917935.py:164: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  v2 = jnp.asarray(K2, dtype=jnp.float64).reshape(-1)\n",
      "/tmp/ipykernel_378943/639917935.py:181: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  thetas = jnp.asarray(thetas, dtype=jnp.float64)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  4m\u001b[1mwandb\u001b[0m: \\ 1 of 3 files downloaded...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/multiprocessing/popen_fork.py:67: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/cs/student/projects1/ml/2024/mlaimon/anaconda3/envs/foundational_ssm/lib/python3.13/multiprocessing/popen_fork.py:67: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_378943/639917935.py:233: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  x = jax.device_put(np.array(subset[\"neural_input\"]))  # [N,T,D]\n",
      "/tmp/ipykernel_378943/639917935.py:163: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  v1 = jnp.asarray(K1, dtype=jnp.float64).reshape(-1)\n",
      "/tmp/ipykernel_378943/639917935.py:164: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  v2 = jnp.asarray(K2, dtype=jnp.float64).reshape(-1)\n",
      "/tmp/ipykernel_378943/639917935.py:181: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  thetas = jnp.asarray(thetas, dtype=jnp.float64)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  4m\u001b[1mwandb\u001b[0m: \\ 1 of 3 files downloaded...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "/tmp/ipykernel_378943/639917935.py:163: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  v1 = jnp.asarray(K1, dtype=jnp.float64).reshape(-1)\n",
      "/tmp/ipykernel_378943/639917935.py:164: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  v2 = jnp.asarray(K2, dtype=jnp.float64).reshape(-1)\n",
      "/tmp/ipykernel_378943/639917935.py:181: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  thetas = jnp.asarray(thetas, dtype=jnp.float64)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "100%|██████████| 3/3 [01:27<00:00, 29.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Try to load downstream_df from CSV if available, else expect it to exist in the notebook state.\n",
    "try:\n",
    "    downstream_df = pd.read_csv(\"results/raw_downstream_performances.csv\")\n",
    "except Exception:\n",
    "    if 'downstream_df' not in globals():\n",
    "        raise FileNotFoundError(\"results/raw_downstream_performances.csv not found and no in-memory downstream_df. Run the earlier data collection cell or provide the CSV.\")\n",
    "\n",
    "# Helper: resolve best vs epoch_0 artifacts for a run_name\n",
    "\n",
    "def _ckpt_artifact(run_name: str, alias: str) -> str:\n",
    "    return f\"melinajingting-ucl/foundational_ssm_downstream_sweep/{run_name}_checkpoint:{alias}\"\n",
    "\n",
    "# Build a small eval batch for NTK (limit trials to keep NTK feasible)\n",
    "\n",
    "def load_eval_subset(dataset_name: str, max_trials: int = 64, rng_seed: int = 0):\n",
    "    from foundational_ssm.utils.downstream_utils import get_nlb_datasets\n",
    "    from foundational_ssm.loaders import get_brainset_data_loader\n",
    "    from foundational_ssm.constants import DATA_ROOT\n",
    "    if dataset_name.startswith(\"mc_\"):\n",
    "        ds_cfg = OmegaConf.create({\n",
    "            \"name\": dataset_name,\n",
    "            \"phase\": \"test\",\n",
    "            \"batch_size\": 2048,\n",
    "            \"skip_timesteps\": 60,\n",
    "        })\n",
    "        key = jr.PRNGKey(rng_seed)\n",
    "        train_data, val_data = get_nlb_datasets(ds_cfg, key, return_full=False)\n",
    "        subset = {k: v[:max_trials] for k, v in train_data.items()}\n",
    "\n",
    "    else:\n",
    "        dataset, loader, max_neural_input = get_brainset_data_loader(\n",
    "            dataset_args={\n",
    "                'keep_files_open': False,\n",
    "                'lazy': True,\n",
    "                'recording_id': dataset_name\n",
    "            },\n",
    "            dataloader_args={\n",
    "                'batch_size': max_trials,\n",
    "                'num_workers': 2,\n",
    "                'persistent_workers': True,\n",
    "            },\n",
    "            sampler = 'TrialSampler',\n",
    "            sampler_args = {\n",
    "                'max_window_length': 5.0\n",
    "            },\n",
    "            data_root = '../' + DATA_ROOT,\n",
    "            prepend_history = 0.3,\n",
    "            sampling_rate = 200,\n",
    "            split = 'trial' \n",
    "        )\n",
    "        subset = next(iter(loader))\n",
    "\n",
    "    return subset\n",
    "\n",
    "# Wrap model apply as a function f(params, x) -> R^{T*Dout}\n",
    "# We'll flatten time and output dims for NTK shape stability.\n",
    "\n",
    "def make_apply_fn_for_ntk(state):\n",
    "    def f(params, x):\n",
    "        inf_model = eqx.nn.inference_mode(params)\n",
    "        preds, _ = jax.vmap(inf_model, axis_name='batch', in_axes=(0, None, None))(x, state, jr.PRNGKey(0))\n",
    "        y = preds  # [N, T, Dout]\n",
    "        return y.reshape(y.shape[0], -1)  # [N, T*Dout]\n",
    "    return f\n",
    "\n",
    "# Utilities to build random tangent directions over parameter pytrees (float leaves only).\n",
    "\n",
    "def _tangent_random_normal_like(tree, key):\n",
    "    leaves, treedef = jax.tree_util.tree_flatten(tree)\n",
    "    subkeys = jr.split(key, len(leaves))\n",
    "    tang_leaves = []\n",
    "    for leaf, sk in zip(leaves, subkeys):\n",
    "        try:\n",
    "            arr = jnp.asarray(leaf)\n",
    "            if jnp.issubdtype(arr.dtype, jnp.floating):\n",
    "                tang_leaves.append(jr.normal(sk, shape=arr.shape, dtype=arr.dtype))\n",
    "            else:\n",
    "                tang_leaves.append(None)  # non-differentiable leaf\n",
    "        except Exception:\n",
    "            tang_leaves.append(None)\n",
    "    return jax.tree_util.tree_unflatten(treedef, tang_leaves)\n",
    "\n",
    "# Helper: random normals with identical structure to an array-only pytree (e.g., from eqx.partition).\n",
    "\n",
    "def _randn_like_inexact(tree, key):\n",
    "    leaves, treedef = jax.tree_util.tree_flatten(tree)\n",
    "    subkeys = jr.split(key, len(leaves))\n",
    "    tang_leaves = [jr.normal(sk, shape=jnp.asarray(leaf).shape, dtype=jnp.asarray(leaf).dtype) for leaf, sk in zip(leaves, subkeys)]\n",
    "    return jax.tree_util.tree_unflatten(treedef, tang_leaves)\n",
    "\n",
    "# Compute an empirical NTK Gram matrix via random-projection JVPs.\n",
    "# Return both the averaged K and each projection's Gram contribution G_r = v_r v_r^T for jackknife.\n",
    "\n",
    "def empirical_ntk_approx_jvp_components(f, params, x, R: int = 16, key: jax.Array = jr.PRNGKey(0)) -> tuple[jax.Array, jax.Array]:\n",
    "    # Differentiate only w.r.t. array-valued parameters to avoid PyTree mismatches with statics.\n",
    "    p_arr, p_static = eqx.partition(params, eqx.is_inexact_array)\n",
    "    def f_arr(p_arr_):\n",
    "        m = eqx.combine(p_arr_, p_static)\n",
    "        return f(m, x)  # [N, D]\n",
    "    keys = jr.split(key, R)\n",
    "    G_list = []\n",
    "    for k in keys:\n",
    "        z_arr = _randn_like_inexact(p_arr, k)\n",
    "        _, tang = jax.jvp(f_arr, (p_arr,), (z_arr,))  # tang: [N, D]\n",
    "        G = tang @ tang.T  # [N, N]\n",
    "        G_list.append(G)\n",
    "    Gs = jnp.stack(G_list, axis=0)  # [R, N, N]\n",
    "    K = jnp.mean(Gs, axis=0)\n",
    "    return K, Gs\n",
    "\n",
    "# Keep legacy API for callers that only need K.\n",
    "\n",
    "def empirical_ntk_approx_jvp(f, params, x, R: int = 16, key: jax.Array = jr.PRNGKey(0)) -> jax.Array:\n",
    "    K, _Gs = empirical_ntk_approx_jvp_components(f, params, x, R=R, key=key)\n",
    "    return K\n",
    "\n",
    "# Exact NTK via explicit Jacobians wrt parameters.\n",
    "# Build Jacobian for each example, flatten (output dims + param dims) per leaf, concatenate leaves -> J in R^{N x M}. Then K = J J^T.\n",
    "\n",
    "def empirical_ntk_exact_jacobian(f, params, x) -> jax.Array:\n",
    "    # Split Equinox model into array-valued parameters and static (non-array) fields.\n",
    "    params_arr, params_static = eqx.partition(params, eqx.is_inexact_array)\n",
    "    # Define single-example function over only array params; rebuild the full model internally.\n",
    "    def f_single(p_arr, xi):\n",
    "        m = eqx.combine(p_arr, params_static)\n",
    "        y = f(m, xi[None, ...])  # [1, D]\n",
    "        return y[0]\n",
    "    # Batched Jacobian over examples: returns pytree leaves shaped [N, D, *param_leaf_shape]\n",
    "    jac_fun = jax.jit(jax.vmap(jax.jacrev(f_single), in_axes=(None, 0)))\n",
    "    jac_tree = jac_fun(params_arr, x)\n",
    "    # Ravel to J in R^{N x M}\n",
    "    leaves = []\n",
    "    for leaf in jax.tree_util.tree_leaves(jac_tree):\n",
    "        if leaf is None:\n",
    "            continue\n",
    "        if not jnp.issubdtype(leaf.dtype, jnp.floating):\n",
    "            continue\n",
    "        leaves.append(leaf.reshape(leaf.shape[0], -1))  # (N, D * prod(param_shape))\n",
    "    J = jnp.concatenate(leaves, axis=1) if leaves else jnp.zeros((x.shape[0], 0), dtype=x.dtype)\n",
    "    return J @ J.T\n",
    "\n",
    "# Parameter-space utilities: L2 norms over array-valued leaves\n",
    "\n",
    "def _tree_l2_norm(tree) -> float:\n",
    "    \"\"\"Compute sqrt(sum_i ||leaf_i||^2) over float leaves of a pytree.\"\"\"\n",
    "    leaves = [jnp.asarray(leaf) for leaf in jax.tree_util.tree_leaves(tree) if leaf is not None]\n",
    "    if not leaves:\n",
    "        return 0.0\n",
    "    # Filter to floating types only (eqx.partition usually ensures this already)\n",
    "    leaves = [leaf for leaf in leaves if jnp.issubdtype(leaf.dtype, jnp.floating)]\n",
    "    if not leaves:\n",
    "        return 0.0\n",
    "    total = jnp.sum(jnp.stack([jnp.sum(leaf * leaf) for leaf in leaves]))\n",
    "    return float(jnp.sqrt(total))\n",
    "\n",
    "# Similarity between two NTK matrices\n",
    "\n",
    "def kernel_cosine(K1: jnp.ndarray, K2: jnp.ndarray) -> float:\n",
    "    v1 = jnp.asarray(K1, dtype=jnp.float64).reshape(-1)\n",
    "    v2 = jnp.asarray(K2, dtype=jnp.float64).reshape(-1)\n",
    "    num = jnp.vdot(v1, v2).real\n",
    "    den = jnp.linalg.norm(v1) * jnp.linalg.norm(v2)\n",
    "    return float(num / (den + 1e-12))\n",
    "\n",
    "def _jackknife_variance_cosine(G0s: jnp.ndarray, GBs: jnp.ndarray) -> float:\n",
    "    # G0s, GBs: [R, N, N] projection contributions\n",
    "    R = int(G0s.shape[0])\n",
    "    if R <= 1:\n",
    "        return 0.0\n",
    "    K0 = jnp.mean(G0s, axis=0)\n",
    "    KB = jnp.mean(GBs, axis=0)\n",
    "    thetas = []\n",
    "    for r in range(R):\n",
    "        K0_mr = (R * K0 - G0s[r]) / (R - 1)\n",
    "        KB_mr = (R * KB - GBs[r]) / (R - 1)\n",
    "        thetas.append(kernel_cosine(K0_mr, KB_mr))\n",
    "    thetas = jnp.asarray(thetas, dtype=jnp.float64)\n",
    "    theta_bar = jnp.mean(thetas)\n",
    "    var = (R - 1) / R * jnp.sum((thetas - theta_bar) ** 2)\n",
    "    return float(var)\n",
    "\n",
    "def _bootstrap_variance_cosine(K0: jnp.ndarray, KB: jnp.ndarray, B: int = 200, seed: int = 0) -> float:\n",
    "    if B <= 1:\n",
    "        return 0.0\n",
    "    N = int(K0.shape[0])\n",
    "    rng = np.random.default_rng(seed)\n",
    "    thetas = np.zeros(B, dtype=float)\n",
    "    for b in range(B):\n",
    "        idx = rng.choice(N, size=N, replace=True)\n",
    "        K0b = np.asarray(K0)[idx][:, idx]\n",
    "        KBb = np.asarray(KB)[idx][:, idx]\n",
    "        thetas[b] = kernel_cosine(K0b, KBb)\n",
    "    return float(np.var(thetas, ddof=1))\n",
    "\n",
    "# Iterate runs and compute similarity with uncertainty\n",
    "\n",
    "def compute_ntk_similarity_for_runs(df: pd.DataFrame, tasks: Iterable[str], max_trials: int = 16, R: int = 16, seed: int = 0, method: str = \"jvp\", bootstrap_B: int = 200, bootstrap_seed: int = 0):\n",
    "    rows = []\n",
    "    for task in tqdm(tasks):\n",
    "        tdf = df[df[\"dataset_name\"] == task]\n",
    "        if tdf.empty:\n",
    "            continue\n",
    "        for (ck_short, tm, om), g in tdf.groupby([\"checkpoint_short\", \"train_mode\", \"opt_mode\"]):\n",
    "            if g.empty or 'run_name' not in g.columns:\n",
    "                continue\n",
    "            run_name = g['run_name'].iloc[0]\n",
    "            # Load models\n",
    "            art_epoch0 = _ckpt_artifact(run_name, 'epoch_0')\n",
    "            art_best = _ckpt_artifact(run_name, 'best')\n",
    "            try:\n",
    "                model0, state0, _ = load_model_and_state_from_checkpoint_wandb(art_epoch0, model_cls=SSMDownstreamDecoder)\n",
    "                modelB, stateB, _ = load_model_and_state_from_checkpoint_wandb(art_best, model_cls=SSMDownstreamDecoder)\n",
    "            except Exception as e:\n",
    "                print(f\"skip {run_name} ({task}) due to load error: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Parameter-space distances\n",
    "            p0_arr, _ = eqx.partition(model0, eqx.is_inexact_array)\n",
    "            pB_arr, _ = eqx.partition(modelB, eqx.is_inexact_array)\n",
    "            diff_arr = jax.tree_util.tree_map(lambda b, a: b - a, pB_arr, p0_arr)\n",
    "            norm_init = _tree_l2_norm(p0_arr)\n",
    "            norm_final = _tree_l2_norm(pB_arr)\n",
    "            norm_diff = _tree_l2_norm(diff_arr)\n",
    "            param_rel_l2 = float(norm_diff / (norm_init + 1e-12))\n",
    "            param_abs_l2 = float(norm_diff)\n",
    "\n",
    "            # Eval subset\n",
    "            subset = load_eval_subset(task, max_trials=max_trials)\n",
    "            x = jax.device_put(np.array(subset[\"neural_input\"]))  # [N,T,D]\n",
    "            # Build apply fns\n",
    "            f0 = make_apply_fn_for_ntk(state0)\n",
    "            fB = make_apply_fn_for_ntk(stateB)\n",
    "            # Compute NTKs and components\n",
    "            if method == \"jacobian\":\n",
    "                K0 = empirical_ntk_exact_jacobian(f0, model0, x)\n",
    "                KB = empirical_ntk_exact_jacobian(fB, modelB, x)\n",
    "                proj = 0\n",
    "                G0s = None\n",
    "                GBs = None\n",
    "            else:\n",
    "                k1 = jr.PRNGKey(seed)\n",
    "                k2 = jr.PRNGKey(seed + 1)\n",
    "                K0, G0s = empirical_ntk_approx_jvp_components(f0, model0, x, R=R, key=k1)\n",
    "                KB, GBs = empirical_ntk_approx_jvp_components(fB, modelB, x, R=R, key=k2)\n",
    "                proj = int(R)\n",
    "            # Ensure symmetry and numeric stability\n",
    "            K0 = 0.5 * (K0 + K0.T)\n",
    "            KB = 0.5 * (KB + KB.T)\n",
    "            # Point estimate\n",
    "            theta = kernel_cosine(K0, KB)\n",
    "            # Uncertainty components\n",
    "            var_proj = _jackknife_variance_cosine(G0s, GBs) if (G0s is not None and GBs is not None) else 0.0\n",
    "            var_boot = _bootstrap_variance_cosine(K0, KB, B=bootstrap_B, seed=bootstrap_seed) if x.shape[0] > 1 else 0.0\n",
    "            std_proj = float(np.sqrt(max(var_proj, 0.0)))\n",
    "            std_boot = float(np.sqrt(max(var_boot, 0.0)))\n",
    "            std_total = float(np.sqrt(std_proj**2 + std_boot**2))\n",
    "            rows.append({\n",
    "                'task': task,\n",
    "                'train_mode': tm,\n",
    "                'opt_mode': om,\n",
    "                'checkpoint_short': ck_short,\n",
    "                'run_name': run_name,\n",
    "                'ntk_cosine_init_vs_best': theta,\n",
    "                'ntk_cosine_mean': theta,\n",
    "                'ntk_cosine_std': std_total,\n",
    "                'ntk_std_proj': std_proj,\n",
    "                'ntk_std_boot': std_boot,\n",
    "                'n_trials': int(x.shape[0]),\n",
    "                'ntk_method': method,\n",
    "                'ntk_projections': proj,\n",
    "                'ntk_bootstrap_B': int(bootstrap_B),\n",
    "                # Parameter distances\n",
    "                'param_norm_init': norm_init,\n",
    "                'param_norm_final': norm_final,\n",
    "                'param_norm_diff': norm_diff,\n",
    "                'param_rel_l2': param_rel_l2,\n",
    "                'param_abs_l2': param_abs_l2,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Run and plot (use exact Jacobians if model/dataset are small enough)\n",
    "selected_for_ntk_sim = downstream_df[downstream_df[\"checkpoint_short\"].isin([\"l2_reaching_checkpoint\"]) & downstream_df[\"opt_mode\"].isin([\"all\"])]\n",
    "# selected_for_ntk_sim[\"task\"] = selected_for_ntk_sim[\"\"]\n",
    "ntk_df = compute_ntk_similarity_for_runs(\n",
    "    selected_for_ntk_sim, tasks=(\"mc_rtt_prepend\",\"perich_miller_population_2018/t_20130903_center_out_reaching\",\"mc_area2bump_prepend\"), R=32, seed=0, bootstrap_B=50, bootstrap_seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cfbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0, state0, _ = load_model_and_state_from_checkpoint_wandb(art_epoch0, model_cls=SSMDownstreamDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "008c0340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1140x520 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2x3 grid: top NTK cosine mean±std, bottom relative parameter L2 across tasks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_ntk_and_paramrel_grid(\n",
    "    ntk_df_in,\n",
    "    tasks=(\n",
    "        \"mc_rtt_prepend\",\n",
    "        \"perich_miller_population_2018/t_20130903_center_out_reaching\",\n",
    "        \"mc_area2bump_prepend\",\n",
    "    ),\n",
    "    order=(\"scratch\", \"finetune\"),\n",
    "    opt_modes=None,\n",
    "):\n",
    "    \"\"\"Draw a 2xN figure per opt_mode: top row NTK cosine (mean±std), bottom row relative param L2.\n",
    "\n",
    "    Args:\n",
    "        ntk_df_in: DataFrame with columns ['task','train_mode','opt_mode','ntk_cosine_mean','ntk_cosine_std','param_rel_l2'].\n",
    "        tasks: task names to plot as columns.\n",
    "        order: x-axis order for train_mode categories.\n",
    "        opt_modes: list of opt_mode values to plot. If None, inferred from data.\n",
    "    \"\"\"\n",
    "    if ntk_df_in is None or len(ntk_df_in) == 0:\n",
    "        print(\"ntk_df is empty; compute it first.\")\n",
    "        return\n",
    "\n",
    "    df = ntk_df_in.copy()\n",
    "    # Ensure required columns exist/types\n",
    "    df[\"train_mode\"] = df[\"train_mode\"].astype(str).str.lower()\n",
    "    df[\"opt_mode\"] = df[\"opt_mode\"].astype(str)\n",
    "    if \"ntk_cosine_mean\" not in df.columns and \"ntk_cosine_init_vs_best\" in df.columns:\n",
    "        df[\"ntk_cosine_mean\"] = df[\"ntk_cosine_init_vs_best\"].astype(float)\n",
    "    if \"ntk_cosine_std\" not in df.columns:\n",
    "        df[\"ntk_cosine_std\"] = 0.0\n",
    "\n",
    "    task_titles = {\n",
    "        \"mc_rtt_prepend\": \"RTT\",\n",
    "        \"mc_area2bump_prepend\": \"Area2Bump\",\n",
    "        \"perich_miller_population_2018/t_20130903_center_out_reaching\": \"T, CO\",\n",
    "    }\n",
    "    palette = {\"scratch\": \"tab:orange\", \"finetune\": \"tab:blue\", \"unknown\": \"gray\"}\n",
    "\n",
    "    if opt_modes is None:\n",
    "        opt_modes = sorted(df[\"opt_mode\"].unique())\n",
    "\n",
    "    ncols = max(1, len(tasks))\n",
    "\n",
    "    for om in opt_modes:\n",
    "        sub = df[df[\"opt_mode\"] == om]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        fig, axes = plt.subplots(\n",
    "            2,\n",
    "            ncols,\n",
    "            figsize=(3.8 * ncols, 5.2),\n",
    "            sharey=\"row\",\n",
    "            constrained_layout=True,\n",
    "        )\n",
    "        # Ensure axes is 2D array even if ncols==1\n",
    "        if ncols == 1:\n",
    "            axes = np.array(axes).reshape(2, 1)\n",
    "\n",
    "        for j, task in enumerate(tasks):\n",
    "            if j >= ncols:\n",
    "                break\n",
    "            g = sub[sub[\"task\"] == task].copy()\n",
    "            ax_top = axes[0, j]\n",
    "            ax_bot = axes[1, j]\n",
    "\n",
    "            # Column title\n",
    "            ax_top.set_title(task_titles.get(task, task))\n",
    "\n",
    "            # TOP: NTK cosine mean ± std\n",
    "            ax_top.set_ylim(0, 1)\n",
    "            ax_top.grid(True, axis=\"y\", alpha=0.15, zorder=0)\n",
    "            if not g.empty:\n",
    "                means = g[\"ntk_cosine_mean\"].astype(float).clip(-1, 1).values\n",
    "                stds = g[\"ntk_cosine_std\"].astype(float).values\n",
    "                tms = g[\"train_mode\"].astype(str).values\n",
    "                x_map = {tm: i for i, tm in enumerate(order)}\n",
    "                rng = np.random.default_rng(0)\n",
    "                xs_center = np.array([x_map.get(tm, len(order)) for tm in tms], dtype=float)\n",
    "                xs = xs_center + rng.normal(0, 0.05, size=xs_center.shape)\n",
    "                colors = [palette.get(tm, \"gray\") for tm in tms]\n",
    "                ax_top.errorbar(\n",
    "                    xs,\n",
    "                    means,\n",
    "                    yerr=stds,\n",
    "                    fmt=\"o\",\n",
    "                    ms=4,\n",
    "                    lw=1,\n",
    "                    ecolor=\"k\",\n",
    "                    elinewidth=0.8,\n",
    "                    capsize=2,\n",
    "                    color=\"k\",\n",
    "                    alpha=0.85,\n",
    "                    zorder=2,\n",
    "                )\n",
    "                ax_top.scatter(xs_center, means, c=colors, s=28, alpha=0.9, zorder=3)\n",
    "            ax_top.set_xticks(range(len(order)))\n",
    "            ax_top.set_xticklabels(order)\n",
    "            if j == 0:\n",
    "                ax_top.set_ylabel(\"NTK cosine mean ± std\")\n",
    "            else:\n",
    "                ax_top.set_ylabel(\"\")\n",
    "                ax_top.tick_params(labelleft=False)\n",
    "\n",
    "            # BOTTOM: relative parameter L2 (||ΔW||/||W0||)\n",
    "            ax_bot.grid(True, axis=\"y\", alpha=0.15, zorder=0)\n",
    "            if not g.empty:\n",
    "                vals = g[\"param_rel_l2\"].astype(float).values\n",
    "                tms = g[\"train_mode\"].astype(str).values\n",
    "                x_map = {tm: i for i, tm in enumerate(order)}\n",
    "                rng = np.random.default_rng(1)\n",
    "                xs_center = np.array([x_map.get(tm, len(order)) for tm in tms], dtype=float)\n",
    "                xs = xs_center + rng.normal(0, 0.05, size=xs_center.shape)\n",
    "                colors = [palette.get(tm, \"gray\") for tm in tms]\n",
    "                ax_bot.scatter(\n",
    "                    xs,\n",
    "                    vals,\n",
    "                    c=colors,\n",
    "                    s=28,\n",
    "                    alpha=0.9,\n",
    "                    zorder=2,\n",
    "                    edgecolor=\"k\",\n",
    "                    linewidth=0.3,\n",
    "                )\n",
    "                # Optional: overlay group means at category centers\n",
    "                try:\n",
    "                    import pandas as pd\n",
    "\n",
    "                    g2 = g.groupby(\"train_mode\", as_index=False)[\"param_rel_l2\"].mean()\n",
    "                    for _, row in g2.iterrows():\n",
    "                        xi = x_map.get(str(row[\"train_mode\"]))\n",
    "                        if xi is not None:\n",
    "                            ax_bot.scatter(\n",
    "                                [xi],\n",
    "                                [float(row[\"param_rel_l2\"])],\n",
    "                                c=[palette.get(str(row[\"train_mode\"]), \"gray\")],\n",
    "                                s=64,\n",
    "                                marker=\"D\",\n",
    "                                zorder=3,\n",
    "                                edgecolor=\"k\",\n",
    "                                linewidth=0.5,\n",
    "                            )\n",
    "                except Exception:\n",
    "                    pass\n",
    "            ax_bot.set_xticks(range(len(order)))\n",
    "            ax_bot.set_xticklabels(order)\n",
    "            ax_bot.set_xlabel(\"Train Mode\")\n",
    "            if j == 0:\n",
    "                ax_bot.set_ylabel(\"Relative param L2 (||ΔW||/||W0||)\")\n",
    "            else:\n",
    "                ax_bot.set_ylabel(\"\")\n",
    "                ax_bot.tick_params(labelleft=False)\n",
    "\n",
    "        fig.suptitle(\n",
    "            f\"NTK (top) and Parameter Movement (bottom) — {'All Params' if om == 'all' else 'Encoder Only'}\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Run the plot for current ntk_df\n",
    "plot_ntk_and_paramrel_grid(ntk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a98ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>train_mode</th>\n",
       "      <th>param_abs_l2</th>\n",
       "      <th>param_rel_l2</th>\n",
       "      <th>param_norm_init</th>\n",
       "      <th>param_norm_final</th>\n",
       "      <th>param_norm_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mc_rtt_prepend</td>\n",
       "      <td>finetune</td>\n",
       "      <td>38.668682</td>\n",
       "      <td>0.038415</td>\n",
       "      <td>1006.603210</td>\n",
       "      <td>1007.093933</td>\n",
       "      <td>38.668682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mc_rtt_prepend</td>\n",
       "      <td>scratch</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1006.013611</td>\n",
       "      <td>1006.013611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perich_miller_population_2018/t_20130903_cente...</td>\n",
       "      <td>finetune</td>\n",
       "      <td>34.336571</td>\n",
       "      <td>0.034129</td>\n",
       "      <td>1006.078064</td>\n",
       "      <td>1006.026001</td>\n",
       "      <td>34.336571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perich_miller_population_2018/t_20130903_cente...</td>\n",
       "      <td>scratch</td>\n",
       "      <td>28.259167</td>\n",
       "      <td>0.028103</td>\n",
       "      <td>1005.562134</td>\n",
       "      <td>1006.041809</td>\n",
       "      <td>28.259167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mc_area2bump_prepend</td>\n",
       "      <td>finetune</td>\n",
       "      <td>34.313702</td>\n",
       "      <td>0.034111</td>\n",
       "      <td>1005.933899</td>\n",
       "      <td>1005.131348</td>\n",
       "      <td>34.313702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mc_area2bump_prepend</td>\n",
       "      <td>scratch</td>\n",
       "      <td>16.079241</td>\n",
       "      <td>0.015992</td>\n",
       "      <td>1005.464905</td>\n",
       "      <td>1005.516235</td>\n",
       "      <td>16.079241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                task train_mode  param_abs_l2  \\\n",
       "0                                     mc_rtt_prepend   finetune     38.668682   \n",
       "1                                     mc_rtt_prepend    scratch      0.000000   \n",
       "2  perich_miller_population_2018/t_20130903_cente...   finetune     34.336571   \n",
       "3  perich_miller_population_2018/t_20130903_cente...    scratch     28.259167   \n",
       "4                               mc_area2bump_prepend   finetune     34.313702   \n",
       "5                               mc_area2bump_prepend    scratch     16.079241   \n",
       "\n",
       "   param_rel_l2  param_norm_init  param_norm_final  param_norm_diff  \n",
       "0      0.038415      1006.603210       1007.093933        38.668682  \n",
       "1      0.000000      1006.013611       1006.013611         0.000000  \n",
       "2      0.034129      1006.078064       1006.026001        34.336571  \n",
       "3      0.028103      1005.562134       1006.041809        28.259167  \n",
       "4      0.034111      1005.933899       1005.131348        34.313702  \n",
       "5      0.015992      1005.464905       1005.516235        16.079241  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntk_df[['task','train_mode','param_abs_l2','param_rel_l2','param_norm_init','param_norm_final','param_norm_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d77580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03d29ac0",
   "metadata": {},
   "source": [
    "## NTK similarity and parameter distance definitions\n",
    "\n",
    "- NTK cosine similarity between two Gram matrices K0 and KB:\n",
    "  \n",
    "  $\\displaystyle \\cos(\\Theta_{\\text{NTK}}) \\,=\\, \\frac{\\langle \\mathrm{vec}(K_0),\\, \\mathrm{vec}(K_B)\\rangle}{\\|\\mathrm{vec}(K_0)\\|_2\\,\\|\\mathrm{vec}(K_B)\\|_2 + \\varepsilon}$\n",
    "  \n",
    "  where $K_0, K_B \\in \\mathbb{R}^{N\\times N}$, $\\mathrm{vec}(\\cdot)$ flattens the matrix, and we use a tiny $\\varepsilon$ for numerical stability.\n",
    "\n",
    "- Absolute parameter distance (L2 over all float leaves):\n",
    "  \n",
    "  $\\displaystyle \\|\\Delta W\\|_2 \\,=\\, \\Big\\|W_{\\text{final}} - W_{\\text{init}}\\Big\\|_2$\n",
    "\n",
    "- Relative parameter distance:\n",
    "  \n",
    "  $\\displaystyle \\frac{\\|\\Delta W\\|_2}{\\|W_{\\text{init}}\\|_2 + \\varepsilon}$\n",
    "\n",
    "These correspond to the columns `ntk_cosine_mean`, `param_abs_l2`, and `param_rel_l2` in `ntk_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60562a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAAF5CAYAAABgAFIuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYN1JREFUeJzt3XlcFeX7//H3AWSXTQV3MTUz9yWJNJXSLNPclyz3NLPUMistN6xES4tcK01p0bTUj9bHckPJck3Nsm9p4p67IqIoIpz5/eGP8+kEKAcGjujr+XjwyLnPzNzXHE5zcZ255x6LYRiGAAAAAACAKVycHQAAAAAAALcTCm0AAAAAAExEoQ0AAAAAgIkotAEAAAAAMBGFNgAAAAAAJqLQBgAAAADARBTaAAAAAACYiEIbAAAAAAATUWgDAAAAAGAiCm0AyIbFYlGzZs2cHUau9e7dWxaLRYcOHcqX/cfFxclisWjcuHF27c2aNZPFYsmXPm/Wd2Ewbtw4WSwWxcXFOTuUW5JZ709BfA4LQlbnIT5DAHDro9AGbkOHDh2SxWKRxWJRy5Yts1xny5Ytslgs6t27t6T//eGW05+MAiejmNuyZUumPo4fP66aNWvKYrHotddey3H858+f11tvvaXw8HAVK1ZMRYoUUYkSJdS8eXNNmzZNly5dcvg9uR2kpaVp+vTpCg8Pl7+/v9zd3VWqVCmFhYXppZde0i+//OLsEJ0uNDRUoaGhzg6j0Mvt+QA5YxiGKleuLIvFoscffzzf+8v40iHjx8XFRYGBgXrwwQcVExMjwzDyPYZbXUxMjCwWi2JiYpwdCoDbhJuzAwCQv1avXq1169bpoYceuuF6WV253bVrl5YvX66mTZtmev1mV3r379+vFi1a6ODBg3rnnXf0yiuv5Cje2NhYdenSRQkJCapWrZo6d+6sYsWK6dy5c9qwYYOGDBmi6Oho7d+/P0f7y4s///xT3t7e+d5PTqSnp+uxxx7T2rVrVbp0aXXu3FkhISFKTEzUzp07NXXqVPn4+Khu3bq2baKiojRixAiVKVMmX2Jq2LCh/vzzTxUvXjxf9n+r9n0nMPt84IgXXnhB3bp1U/ny5fO0n88++0yXL182KSpzxcXFaf/+/bJYLFq1apWOHz+u0qVL53u/L7/8snx9fZWenq4DBw5o6dKl+umnn7Rjxw5NmzYt3/sHgDsJhTZwGwsNDdWRI0f02muvadu2bTccRtmsWbNMfyzHxMRo+fLlatasmUNXrH777Te1bNlSZ86c0Zw5c9SvX78cbffrr7+qTZs2kqQvvvhCTz31VKZ14uLiNHLkyBzHkhf33HNPgfSTEwsWLNDatWv16KOP6ptvvlGRIkXsXj958qSOHz9u11aqVCmVKlUq32Ly9vZ22nvkzL7vBGaeDxxVvHhxU75AyWuhnp8++eQTSdcL38mTJysmJkavv/56vvc7fPhwlSxZ0ra8e/duhYWFacaMGRo2bJgqVqyY7zEAwJ2CoePAbaxq1arq0aOHtm/frq+++qpA+ty4caOaNm2q8+fP6+uvv85xkS1JQ4YM0ZUrVzRt2rQsi2zpegGQ1X2J8+bNU1hYmHx9feXr66uwsLBshwAuWbJETZs2VXBwsDw9PVW6dGk1b95cS5YssVsvq3sjM4bKHzx4UFOnTtU999wjDw8PVahQQZGRkbJarVn2uXz5cj388MMKDAyUp6enatSoocmTJys9Pf2m74skbd68WZL07LPPZiqyJalkyZKqV69elrH+8x7tf97bvGnTJkVERKho0aIqUaKEBg0apCtXrkiSVqxYofDwcPn4+CgkJESvvvqq0tLS7PbvyH3SFy5c0KRJk9S0aVOVLl1a7u7uKl26tHr27Jnl6IR/3oMaExOjevXqydvb2/b7+HffGbdLHD58WIcPH840rHnt2rWyWCwaNGhQlvHt379fLi4u2d5qkWH58uWyWCyaPHmyXXt0dLQsFovKli1r156SkiJPT09FRERkub8FCxaoTp068vLyUqlSpTR06FDb7+DfNmzYoDZt2qh48eLy8PBQlSpVNGrUqExXbf/53mzfvl0tWrRQ0aJF5e/vr/bt25t+z37G5+zAgQOaMmWK7r33Xnl4eNhuSzl+/LjGjh2r+++/X8HBwfLw8FBoaKgGDRqk06dPZ9pfVvcfZ/x+e/furfj4eLVv316BgYHy8fFR8+bN9euvv2baT1b3aP9zePDq1av1wAMPyNvbW8WKFVOvXr107ty5LI/xo48+UvXq1eXp6aly5crp1VdfVUpKSq7mcUhMTNSSJUtUo0YNjR8/XkWLFtXcuXOdMny7Zs2aatq0qQzD0Pbt2yVJc+fOVdu2bRUaGipPT08FBQWpZcuWWr9+fabt/30+eeSRRxQQEGD3vudlf3k5P2XIybm3d+/e6tOnjySpT58+duePf7p48aLGjh2r6tWry8vLSwEBAWrZsqV++umnTP1mfP5SUlI0atQoVapUSUWKFLGdsy5cuKAxY8bo3nvvla+vr/z8/FS5cmX16tVLhw8fvtGvDUAhQaEN3ObGjx8vDw8PjRo1SteuXcvXvr7//nu1aNFCaWlp+u6779S+ffscbxsfH68NGzaoXLlytj94suPh4WG3PGTIEPXt21fHjh1Tv3791K9fPx07dkx9+vTR0KFD7dadNWuWOnXqpH379ql9+/YaNmyYHn30UZ08eVL/+c9/chzvK6+8ojfffFPh4eEaOHCgpOsFwujRozOtO3LkSLVr10579+5Vhw4dNGjQIHl5eemVV15Rt27dctRfsWLFJEl//fVXjmO8ka1bt+rhhx+Wv7+/nn32WZUvX16zZs1S//79tWjRInXq1EkVKlTQs88+q4CAAL377ruaMGFCrvv7888/NWbMGHl5eal9+/Z68cUX1aBBAy1YsEANGzbM9g/Ld999V4MGDVLVqlU1ZMgQNWrUKMv1AgICNHbsWPn7+8vf319jx461/TRr1kwPP/ywKlWqpAULFmQ5nHjOnDkyDEP9+/e/4XE0adJELi4umYqEjOVjx45p3759tvbNmzfr6tWrWRba06dP14ABA1S9enU999xzCgwM1NSpU/XMM89kWnfWrFlq1qyZNm7cqMcff1xDhgxR2bJl9fbbb6tFixZKTU3NtM3PP/+sJk2ayN3dXc8++6waNGigZcuWqXnz5kpJSbnhcebG4MGDNWHCBDVo0EAvvviiatasKen6FwRTpkxRSEiInnzySQ0ePFiVKlXSrFmzFB4ergsXLuS4j0OHDun+++9XQkKC+vbtqxYtWig2NlYRERE6depUjvfzzTffqE2bNipdurQGDRqkSpUq6bPPPlPbtm0zrTtmzBgNHDhQ586dU//+/dW5c2d99dVX6tKlS477+6cFCxYoJSVFPXv2lJeXlzp16qT9+/frhx9+yNX+zJJRVD7//PM6deqUmjdvrpdeekmtW7fW5s2b1bx5cy1fvjzLbTdt2mQrLAcMGKCuXbvaXsvN/sw6P+X03NuuXTvb775t27Z2548MCQkJCg8P1/jx4xUYGKiBAweqY8eO2rFjhyIiIrRs2bIsj6Vjx46KiYlRRESEhg4dqooVK8owDLVs2VJvvvmmgoKCNGDAAA0YMEB169bVN998Y3cOAVCIGQBuOwcPHjQkGS1btjQMwzCGDx9uSDKmTZtmW2fz5s2GJKNXr17Z7mfevHmGJGPs2LHZrtOrVy9DkvHiiy8aRYoUMYoVK2Zs27bN4ZhjYmIMScbTTz/t0HY//PCDIcmoVq2akZiYaGtPSEgw7r77bkOSsWHDBlt7vXr1DHd3d+PUqVOZ9nX27Fm7ZUlG06ZN7doyjrdixYrG8ePHbe1nzpwxAgICjKJFixpXr161ta9evdr2u7h06ZKt3Wq1GgMHDjQkGYsXL77pce7YscNwc3Mz3N3djWeffdb45ptv7PrPSkasBw8etLWtX7/ekGRIMpYtW2ZrT01NNWrVqmVYLBajePHidr/DpKQkIzg42AgKCjJSU1Mz7evfn4+mTZsa/04viYmJxrlz5zLFuG7dOsPFxcV45pln7NrHjh1rSDJ8fHyM3377LdN22fVdoUIFo0KFClm+H5MmTTIkGTExMXbt165dM0qVKmUEBwfbHV926tWrZxQtWtS4du2aYRiGkZ6ebgQEBBgPP/ywIcn46KOPbOuOHj0602cw49j8/f2NPXv22NovX75s3H333YaLi4tx7NgxW/v//d//GW5ubkbt2rUzfUajoqIMScbkyZMzvTeSjIULF9qt36NHD0OS8eWXX970OP8tu/NBxuesbNmyxuHDhzNtd+rUKePixYuZ2j/99FNDkvHWW2/ZtWe8P+vXr7e1ZZzTJBkTJ060W3/UqFGGJCMqKsquPavPYcYxuLm5GT/99JOtPS0tzWjWrJkhydi8ebOtfe/evYarq6tRpkwZu3NGUlKSce+992Z5jriZevXq2f2O161bd8NzX1Z9ZPUe3UjGe3HixAm79t9//93w8vIyLBaL7Txx4MCBTNsfP37cKF26tFGlShW79n9+1ubOnZtl37ndX17PT46eezM+G/PmzcvyOLp3725IMmbPnm3XfurUKaNcuXJGiRIljCtXrtjaM97zOnXqZDr3/fbbb4Yko127dpn6SUlJyfL/FwCFD1e0gTvA66+/roCAAL355pv5NmN3dHS0rl27pvnz5+u+++5zePuTJ09KUqahtzfz6aefSrp+Ndnf39/WHhgYaLsa8e8h5EWKFMly+HXGVeOcGD16tN39z8WLF1fbtm118eJF7d2719Y+ffp0SdLHH38sHx8fW7vFYtHEiRNlsVj05Zdf3rS/evXq6dNPP5Wfn58++ugjPfHEEypdurRtBMCOHTtyHLskRURE2F29K1KkiDp16iTDMNSmTRu732HRokXVunVrJSQk6O+//3aonwz+/v4KCgrKMo7q1atr7dq1WW43YMAA25XRvOrTp4/c3d01Z84cu/YVK1boxIkT6tWrV5afi6xivnjxom2o7S+//KLExEQ988wzKl++vNatW2dbd/369fLy8lJYWFim/QwdOlRVq1a1LXt5eenJJ5+U1Wq1+31+9NFHSktL07Rp0zJ9Rl999VWVKFEiy89QkyZN7K4sSlLfvn0lXb/abbZXXnkly/uig4OD5evrm6m9R48e8vPzy/Z3n5WKFStmmlgx4/YUR46pe/fudqMjXF1d1atXr0z7+fLLL5Wenq6XX35ZwcHBtvaiRYtq1KhROe4vw65du7Rz5049/PDDtsnPmjVrpvLly2vJkiUOXd3PjcmTJ9tG3jz99NO67777dOXKFQ0ePNg2W39W92mXKlVKHTt21L59+7IcfVKvXr1sRyLlZn9mnJ/MOvdK0tmzZ7Vo0SI99NBDmUacBAcH65VXXtGZM2ey/CxHRkZmee6Trv8//28eHh5Z/v8CoPBhMjTgDhAYGKgRI0ZoxIgRtj+0zNaiRQutWbNGzz33nNavX68KFSqY3kdWMh5pldV9khnDdXft2mVr69atm1599VXVqFFD3bt3V0REhBo3biw/Pz+H+q1fv36mtowvCRITE21tW7ZskY+Pj+bOnZvlfry8vLRnz54c9dm9e3d16NBBa9assc0UvGnTJsXExOizzz7TjBkzbMPYb6ZOnTqZ2jK+OLjRa8ePH8/1hElxcXGKjo7W1q1bdfbsWbt7Kt3d3bPcpmHDhrnqKyslSpRQhw4dtHDhQu3Zs8c2mVpG4Z3VkO2sREREaMqUKVq/fr3uv/9+27Dxhx56SBEREVq5cqUk6fLly9q2bZsefPDBLI/Pkc+QJK1atUqxsbGZtilSpEiWn6Gc7t8sN/pdLV26VB999JF27typ8+fP290f++9J/G6kTp06cnGxv0aQm2PK6XuTce9348aNM62f3W0MN5LxWevZs6etzWKx6Omnn9aECRO0YMECPffccw7vN6emTJli69PPz08NGjRQv3797OI5cOCAoqKitG7dOh07dkxXr16128fx48cznd9v9OVqbvZnxvnJzHPvzz//rPT0dF29ejXL/Jkx1HvPnj1q3bq13WtZ/X9RrVo11apVS19++aX+/vtvtWvXTs2aNcvy8w2g8KLQBu4QQ4YM0fTp0zVlypRsJ4TKi/Hjx6t+/fqaOHGimjZtqvXr1ztUkGXMhHvs2DGH+k1KSpKLi4tKlCiR6bWQkBBZLBYlJSXZ2oYPH65ixYpp1qxZmjJliiZPniw3Nzc9/vjjev/993Mcc1aFuZvb9VPqP4uIhIQEpaWlKTIyMtt9JScn56hPSfL09FSbNm1ss7OnpKRo8uTJGj16tIYOHap27drZzSqcm/hv9Fpu7/P/+uuv1bVrV/n6+qply5YKDQ2Vt7e3bWKq7O7RDgkJyVV/2Xn22We1cOFCzZkzR5MnT9bx48f1/fffq2nTprr77rtztI8HH3xQrq6uWr9+vUaOHKn169erevXqCg4OVkREhD799FP98ccfOnbsmFJTU7OdCM2Rz5Akvf322w4da073b5bsfldTpkzR8OHDVaJECT3yyCMqW7as7UpedHR0psLrRsw6ppzuJ+Pc8c+r2Rkc/WympKRo/vz58vX1VYcOHexe69mzpyZMmKC5c+fma6F94sSJG54f4uPj1bBhQyUlJSkiIkJt2rSRn5+fXFxcFBcXpx9++CHL31d270Vu92fG+cnMc2/G/4MbN27Uxo0bHdpfVu+Nm5ub1q1bp3HjxmnJkiV6+eWXJV3/MvCFF17QG2+8IVdX1xzFBuDWRaEN3CG8vLwUGRmpfv36KTIyUj169DC9j6ioKLm6uurtt99Ws2bNtH79et1111052jbj6lBcXJysVmuOv9X38/OT1WrVmTNnMv0xfPr0aRmGYfeHmcViUd++fdW3b1+dO3dOP/74o7788kt99dVX2rdvn3777TdT/8Dx8/OTxWLR2bNnTdvnP3l6emrUqFFas2aNNmzYoI0bN6pjx4750ldejBs3Tp6entqxY4eqVKli99rChQuz3e5Gj6TLjWbNmumee+7RZ599pgkTJmjevHlKT0+/6SRo/+Tn56f69etr48aNunLlin766SfbFcGMonr9+vW2K7XZFdqO9CddL/qKFi2ap33lp6x+V2lpaXrzzTdVqlQp7dq1y+7/UcMw9M477xRkiA7LeO9Pnz6d6aqrI5OvSdev6mdcLf/nUOZ/2r59u3777TfVqlXL8WBN8P777+v8+fP6/PPP9fTTT9u9NnDgwGwnbMvu/9Pc7s8MZp57Mz4HGY9jc0R2702xYsU0bdo0TZ06VXv27NG6des0bdo0jR07VkWKFCmwx1gCyD+MTwHuIL169VL16tU1e/ZsxcfH50sfb731lsaMGaMjR46oadOmOe6ncuXKatKkiY4ePWq77zo7/7wCUrduXUnK8pFfGW1ZDTWUrv+h065dO9u9d3/88Yfp70tYWJjOnTuX77PI3ur39O3fv1/VqlXLVGSfOHFCBw4cMK0fV1fXm17ZHDBggM6cOaNly5Zp7ty5CgwMdPjLiYiICF2+fFkzZ85UUlKSHnroIUnXn91cqVIlrVu3TuvXr5ePj0+u5iz4p4z7uzOGkBcmZ8+e1YULFxQeHp7pi7Dt27dn+yizW0Xt2rUlKcurmJs2bXJoXxnPzu7cubPt6Qj//Ml4tFzGes6Q8ai9f8++bhjGDa/kFtT+HOHouTfjC9aszh/33XefLBaL7TGLZrJYLKpWrZqef/55rVmzRtL1WfEBFH4U2sAdxNXVVRMmTNC1a9fy5T7tDJGRkYqMjNTff/+tpk2b5viRVB988IG8vLz0wgsvaNGiRVmu8+OPP9qKGkm2CYwiIyPthohfuHDBNmQwYx3pevFt/Ot5tdeuXbMNDfT09MxRrDk1ZMgQSbJdQf+3kydP6s8//7zpfhYuXKh169Zl+azdLVu2aP369XJzc9P999+f96DzQYUKFRQfH293FTAlJUXPPfecqY+dCwoK0tmzZ2/4+KpevXrJ09NTL730kg4cOKAePXo4/HvPuEo9adIkubi42M0REBERoXXr1unnn39Wo0aNcjTB2o0MGjRIbm5uGjx4sI4cOZLp9cTERNtcBbea4OBgeXl5aefOnXaPVTt//rwGDx7sxMhyplu3bnJxcdGUKVPsrowmJyc7NJT/4MGDWr9+vUJDQ7Vo0SLNmTMn08+iRYvk5eWlL774wqHh9GbKuGr/7+dCT5w4Ub///rvT9+cIR8+9GROWHT16NNO6JUuWVJcuXbRp0ya9++67WZ6Ht27dmuWjA7Ny6NChLJ9nn3F+NDsPAXAOho4Dd5gnnnhCjRs3zvSHj9nGjBkjNzc3vfHGG7Zh5P+cYTkrderU0bfffqsuXbqoW7duGj9+vJo0aaKgoCAlJCRo48aN2r17typXrmzbpkmTJho8eLCmTZumGjVqqGPHjjIMQ0uWLNHff/+tIUOGqEmTJrb127VrJz8/P91///2qUKGCrl27pjVr1uiPP/6wPZvVTI8++qhGjx6tN998U5UrV9ajjz6qChUq6Ny5c4qPj9ePP/6ot956S9WqVbvhfrZs2aIPPvhAZcqUUZMmTVS+fHmlpqbqzz//1OrVq2W1WjVx4kSVKVPG1PjNMnjwYA0ePFh169ZVp06dlJaWpjVr1sgwDNWuXds26VRePfTQQ9q+fbsee+wx2yRkTZo0sfsMBAUFqXPnzvr8888lyaFh4xkaN26sIkWK6MyZM6pbt64CAwNtr0VERNgmvcrrsHFJqlGjhmbOnKnnnntOVatWVatWrVSpUiVdvHhRBw4c0A8//KDevXvrww8/zHNfZnNxcdGgQYM0ZcoU1a5dW23atFFSUpK+//57VahQwTbz9q2qatWqGjFihCZMmKCaNWuqS5cucnNz09KlS1WzZk39/vvvObrNZe7cuTIMQ7169cp2KLG/v7/at2+vBQsWaNmyZZlmjC8IAwcO1Lx589SxY0d16dJFxYoV05YtW7Rz5049/vjjWrFihVP35whHz73h4eHy8vJSdHS0zp8/b5v3I2N2+ZkzZ2rv3r169dVX9fnnnys8PFwBAQE6evSotm/frn379unEiRPy9va+aWy7du1Shw4d1LBhQ917770qWbKkjh07pmXLlsnFxUUvvfRSvr0vAAoOhTZwB5o0aVKuZsx11Ouvvy43Nze99tpratasmdatW3fTgvLhhx/Wvn37NHPmTK1YsUKLFi3SxYsX5e/vr5o1a2rq1Km2RxRlmDp1qurWratZs2bp448/liRVr15d48ePz/TImaioKK1cuVLbtm3Tt99+Kx8fH1WqVEmzZs2yPSbIbBlfGEydOlWxsbFKTExUsWLFVLFiRY0bN05PPfXUTffx8ssvq3Llylq9erV+/vlnffPNN7p27ZpKliypjh07auDAgXZX+m81zz//vIoUKaJp06Zp9uzZCggI0OOPP66oqCh17tzZtH5Gjx6t8+fP67///a9+/PFHpaena+zYsXaFtnT9qvbnn3+u+++/XzVq1HC4n4wh4Zs2bcr0vv+zuM5qNvzc6N+/v+rUqaP33ntPGzZs0Lfffit/f3+VL19eL730kt2ojVtNVFSUgoKCFBMTo5kzZyokJERPPvmkxo0bl6v3vqC9/fbbKlu2rKZNm6YPP/xQwcHB6tatm4YOHapvv/32pk8ssFqtiomJkcViuenvqU+fPlqwYIE++eQTpxTadevW1erVqzVq1CgtXbpUrq6ueuCBB7Rx40Z98803DhfGZu/PUY6ce4OCgrR48WKNGzdOs2fPtt3WkFFoBwUFadOmTZo+fboWLVqk+fPny2q1qmTJkqpdu7ZGjx6t4sWL5yiuBg0a6LXXXlNcXJxWrFihxMRElSxZUs2bN9crr7xyy45MAuAYi5HV+BcAAG5jkydP1iuvvKJPPvkk0xc3QE6sXbtWLVq00KuvvqpJkyY5OxwAwC2GQhsAcEdJSUnRPffco6SkJP399985GuqJO9eZM2cUFBRk9zSCxMREtWjRQtu3b9emTZsUHh7uxAgBALciho4DAO4IP/30k3744QetWrVKhw8fVlRUFEU2bmr+/PmaPHmyHnroIZUuXVonTpzQypUrdfr0afXu3ZsiGwCQJQptAMAdYe3atYqMjFTx4sX10ksvafjw4c4OCYXAAw88oPr162vt2rVKSEiQq6urqlWrptGjR2vQoEHODg8AcIti6DgAAAAAACbiOdoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYCIKbQAAAAAATEShDQAAAACAiSi0AQAAAAAwEYU2AAAAAAAmotAGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYCIKbQAAAAAATEShDQAAAACAiSi0AQAAAAAwEYU2AAAAAAAmotAGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYCIKbQAAAAAATEShDQAAAACAiSi0AQAAAAAwEYU2gExiYmJksVhsP25ubipTpox69+6tY8eOqXfv3navZ/fjyHoAADjbzJkzZbFYFBYW5tQ4jh49qsjISDVs2FCBgYEqXry4mjVrprVr12Zad9y4cXY51cXFRaVKlVLr1q21ZcsWJ0QPQJLcnB0AgFvX+PHjVbFiRaWkpGjLli2KiYnRTz/9pM8//1zNmze3rXfw4EGNGTNGAwYM0IMPPmhrr1SpUo7XAwDA2ebPn6/Q0FBt27ZN8fHxqly5slPiWL58uSZNmqR27dqpV69eSktL02effaYWLVpo7ty56tOnT6ZtZs2aJV9fX1mtVh09elSzZ89WkyZNtG3bNtWpU6fgDwK4w1FoA8jWY489pgYNGkiSnnnmGRUvXlyTJk3S0aNH9fTTT9vW2759u8aMGaPw8HC7dkkKDw/P0XoAADjTwYMHtWnTJi1dulTPPvus5s+fr7Fjx95wm7S0NFmtVrm7u5saS0REhI4cOaLixYvb2gYOHKg6depozJgxWRbanTp1slu/Xbt2qlGjhr7++msKbcAJGDoOIMcyrkLv37/fyZEAAGCu+fPnKzAwUI8//rg6deqk+fPn271+6NAhWSwWTZ48WdHR0apUqZI8PDz0xx9/SJL27NmjTp06KSgoSJ6enmrQoIG++eYbu30kJCRo+PDhqlmzpnx9feXn56fHHntMv/76q9161atXtyuaJcnDw0OtWrXS33//rYsXL970eEqWLClJcnP733W1jFvDDh06ZLduXFycLBaL4uLibG3NmjVTjRo19Ntvv6lp06by9vZW5cqVtXjxYknSDz/8oLCwMHl5ealq1aqZhrVnDGnfs2ePunTpIj8/PxUrVkxDhw5VSkrKTeMHCjsKbQA5lpGYAwMDnRsIAAAmmz9/vjp06CB3d3c9+eST2rdvn37++edM682bN0/Tpk3TgAEDNGXKFAUFBen//u//dP/99+vPP//UiBEjNGXKFPn4+Khdu3b6z3/+Y9v2wIEDWrZsmVq3bq333ntPr7zyinbv3q2mTZvq+PHjN43x5MmT8vb2lre3d6bXEhISdPbsWZ0+fVq//PKL+vfvL09PT3Xp0iXX78n58+fVunVrhYWF6Z133pGHh4e6deumRYsWqVu3bmrVqpUmTpyo5ORkderUKcsvALp06aKUlBRFRUWpVatWmjp1qgYMGJDrmIDCgqHjALJ14cIFnT17VikpKdq6dasiIyPl4eGh1q1bOzs0AABMs2PHDu3Zs0fTpk2TJDVu3Fhly5bV/Pnzdd9999mt+/fffys+Pl4lSpSwtTVv3lzly5fXzz//LA8PD0nSoEGD1LhxY7322mtq3769JKlmzZr666+/5OLyv2tdPXr00D333KNPPvlEo0ePzjbG+Ph4LV26VJ07d5arq2um16tWrWq3HBAQoGXLlql69eoOvhv/c/z4cS1YsEBPPvmkJKlFixa655571L17d23atMk2aVy1atXUsmVLLVmyJNMEpxUrVtTy5cslSc8//7z8/Pw0c+ZMDR8+XLVq1cp1bMCtjivaALLVvHlzlShRQuXKlVOnTp3k4+Ojb775RmXLlnV2aAAAmGb+/PkKCQlRRESEJMlisahr165auHCh0tPT7dbt2LGjXZGdkJCgdevWqUuXLrp48aLOnj2rs2fP6ty5c2rZsqX27dunY8eOSbo+/DujyE5PT9e5c+fk6+urqlWraufOndnGd/nyZXXu3FleXl6aOHFilussWbJEa9as0erVqzVv3jzdfffd6tixozZt2pTr98XX11fdunWzLVetWlUBAQGqVq2a3czsGf8+cOBApn08//zzdsuDBw+WJH333Xe5jgsoDLiiDSBbM2bM0N13360LFy5o7ty52rBhg+2begAAbgfp6elauHChIiIidPDgQVt7WFiYpkyZotjYWD3yyCO29ooVK9ptHx8fL8MwNHr06GyvSJ8+fVplypSR1WrVBx98oJkzZ+rgwYN2RXyxYsWyja9bt276448/9P3336t06dJZrtekSRO7+7o7deqkKlWqaPDgwdqxY8fN34gslC1bVhaLxa7N399f5cqVy9QmXR9q/m9VqlSxW65UqZJcXFwy3ScO3G4otAFkq2HDhrZZx9u1a6fGjRure/fu2rt3r3x9fZ0cHQAAebdu3TqdOHFCCxcu1MKFCzO9Pn/+fLtC28vLy+51q9UqSRo+fLhatmyZZR8ZjwmbMGGCRo8erb59++rNN99UUFCQXFxc9OKLL9r282/9+/fXf//7X82fP18PPfRQjo/L19dXYWFhWr58uZKTk+Xj45OpaM7w76v2GbIaon6jdsMwbhpXdjEAtxsKbQA54urqqqioKEVERGj69OkaMWKEs0MCACDP5s+fr+DgYM2YMSPTa0uXLtV//vMfffjhh9luf9ddd0mSihQpoubNm9+wr8WLFysiIkKffPKJXXtiYmKmWcYl6ZVXXtG8efMUHR1tu0/aEWlpaZKkS5cuycfHxzaZaWJiot16hw8fdnjfObVv3z67UQDx8fGyWq0KDQ3Ntz6BWwH3aAPIsWbNmqlhw4aKjo7m0RwAgELvypUrWrp0qVq3bq1OnTpl+nnhhRd08eLFTI/p+qfg4GA1a9ZMH330kU6cOJHp9TNnztj+7erqmumq79dff227h/uf3n33XU2ePFmvv/66hg4d6vCxJSQkaNOmTSpZsqSCg4MlXR+2LUkbNmywrZeenq6PP/7Y4f3n1L+/wMiYcO6xxx7Ltz6BWwFXtAE45JVXXlHnzp0VExOjgQMHOjscAABy7ZtvvtHFixf1xBNPZPn6/fffrxIlSmj+/Pl2k3/924wZM9S4cWPVrFlT/fv311133aVTp05p8+bN+vvvv23PyW7durXGjx+vPn366IEHHtDu3bs1f/5821XxDP/5z3/06quvqkqVKqpWrZq++OILu9dbtGihkJAQu7bFixfL19dXhmHo+PHj+uSTT3T+/Hl9+OGHtuHa1atX1/3336+RI0cqISFBQUFBWrhwoe3Kd344ePCgnnjiCT366KPavHmzvvjiC3Xv3l21a9fOtz6BWwGFNgCHdOjQQZUqVdLkyZPVv3//bO/TAgDgVjd//nx5enqqRYsWWb7u4uKixx9/XPPnz9e5c+ey3c+9996r7du3KzIyUjExMTp37pyCg4NVt25djRkzxrbe66+/ruTkZC1YsECLFi1SvXr1tGLFiky3Y2UU5vv27VOPHj0y9bd+/fpMhfZzzz1n+7ePj49q1aqlt99+W507d850zM8++6wmTpyogIAA9evXTxEREdm+B3m1aNEijRkzRiNGjJCbm5teeOEFvfvuu/nSF3ArsRg5mbUAAAAAAHJo3LhxioyM1JkzZ7K8/xy43XGPNgAAAAAAJqLQBgAAAADARBTaAAAAAACYyKmF9oYNG9SmTRuVLl1aFotFy5Ytu+k2cXFxqlevnjw8PFS5cmXFxMTke5wAAAAAcm7cuHEyDIP7s3HHcmqhnZycrNq1a2d6vl52Dh48qMcff1wRERHatWuXXnzxRT3zzDNatWpVPkcKAAAAAEDO3DKzjlssFv3nP/9Ru3btsl3ntdde04oVK/T777/b2rp166bExEStXLmyAKIEAAAAAODGCtVztDdv3qzmzZvbtbVs2VIvvvhitttcvXpVV69etS1brVYlJCSoWLFislgs+RUqAAB5ZhiGLl68qNKlS8vFpfBMq0LuBQAUVmbl3kJVaJ88eVIhISF2bSEhIUpKStKVK1fk5eWVaZuoqChFRkYWVIgAAJju6NGjKlu2rLPDyLH8zr1NKrgq+lFPVQp0kYtFSrNKm4+m6bkVKTp84ZYYqAcAyAeBD/eXb61HZE29Iv1jYLaliIck6eQXw5V27m9T+spr7i1UhXZujBw5UsOGDbMtX7hwQeXLl9eRI0fk5+fnxMgAALixpKQklS9fXkWLFnV2KA7Jz9z7839jVP//xsvDkqZUuamIp4+83aRHi17T/vBautRlseRRuN4vAMDNXUu3quWMn3X1mlVe7v6SpDNnzigtPU1KS5XF3Uu+9zyoC5sW6u6779bWrVtz1Y9ZubdQFdolS5bUqVOn7NpOnTolPz+/LK9mS5KHh4c8PDwytfv7+1NoAwBuaRnDrAvbcOv8yr1fffWVUpePVZHKViWlWmQY15SSekH+/v7ycveR64XD8v97nVSvZ17CBwDcgs4np+qa1ZCrq8UuL7pYXGSxWGRI8itRWq5BQbp27Zr8/f1z1Y9Zubfw3PAlKTw8XLGxsXZta9asUXh4uJMiAgAABWX8+PFqWiZd6VZDVqtVhnH9vxcvXpRcXCUZ0oE4Z4cJAMgHRT3dFOjtrmvp/xsy7urqareOcemMrl27pkqVKhV0eJk49Yr2pUuXFB8fb1s+ePCgdu3apaCgIJUvX14jR47UsWPH9Nlnn0mSBg4cqOnTp+vVV19V3759tW7dOn311VdasWJFgcd+5swZnT59OlN7cHCwSpQoUeDxAABwu7t06ZJcXFx0/SKDVS4urjIMQ7YHqBiyu2cPAHD7cHN1Udf7ymn6unilplnl7uYiNzc3paamSkU8ZVxL0ckt/5VxJVlVqlRxdrjOLbS3b9+uiIgI23LG/Vy9evVSTEyMTpw4oSNHjther1ixolasWKGXXnpJH3zwgcqWLas5c+aoZcuWBR77woULNX36dBmGoQsXElWvnK8CPAw93GWAnhk6ssDjAQDgdufr66u1B06rY7Xrf75YremSJIvFTbKmSxaLFNrYmSECAPJRv8YVtfvvC9rw1xmlplllcfeWp6u70lOvKH37Qj1Qr4aefvrpGz4yuqDcMs/RLihJSUny9/fXhQsX8nSfWMYVbZe/tyl52cuqU8ZTFlllcfOUy71PSC3GS14B5gUOALjjmJWznM2s4/jqq6/00bjntLB1mrzdpMvXpHRJgX4+8nCR5F9WemaN5Jm7+/IAALe+tHSrfvjrjFb+flIXU9JUtWRRdapfVuWCvE3Zv1k5q1BNhnYrKVGihOJ/XKJ7to+Se2Cakq+kyNPLRx5GurT7aynxiPTU15JrEWeHCgDIR6cvpihu7xmdPX9BJdyuqloJD7sJVLilyDxdunRRQECAPoiJVJ+QP1XKV/Io4ipXNxepZC3piWkU2QBwm3NzddHD1UL0cLWQm6/sRBTaubR69WpdXPK6alVI14WrhiyWdF1JvaiAgAB5uhWR/t4mxcdKVR91dqgAgHxgGIZmxu3XnB8PKCXNqrRr13QtNVWWxKO6vG6W/IsYslgseuGFFzR48GBnh3vbeOSRR/TII49I6dekwxuly+ekoLukUnWkQjY7OwDg9kWhnUszpkXrk3vTlWZYJFnk4uIiq9Wq5ORkeQYFSWkp0n4KbQC4XS36+ahmro+XxSL5uLvKcLPossVQSlAFuTTurxIHl6tXzx5q3769s0O9PbkWke5q5uwoAADIUqF6vNetJH7fPrlark9wmsFikdLS0v7/knH923YAwG0nLd2quRsPypDk7e4mF4tFaWlpunzpotJTU1SkRAXtTZTGjRunX375xdnhAgCAAkahnUsVK1fVrlOSu8v/Sm3DkNzc/v/Mp5JU9j4nRQcAyE8nLqToxIUUubv+L40mJyfLMAy5/P+vYP0q1taVK1c0depUZ4UJAACchEI7l4YMGaK5f3jomlUq6i7JapXFIhX19pCuJUv+5aR72zo7TABAPnB3c5FFkvGPcU1paWn/mATNIhnp8vDw0F9//eWUGAEAgPNQaOfSI488oh5vfqFP/q6kS6mSn5eLihf1uH6Fu0RVqdsCycPX2WECAPJBcFEPVSvlp9Q0QxlPyXRzc7v+bxc3ybDKcvJPXb16VVWrVnVytAAAoKBRaOfSmTNnVKZMGT045CO1/DZAx+uP0Ok6g5X42CzpmXVS8crODhEAkE8sFosGP1RF7m4uunQ1TalpVnl6+8hSxEOGi6uuxG9Twv5f5eXlpSFDhjg7XAAAUMCYdTyXFi5cqOnTp8swDF24cFWPvfrJ/3+MS4AG1+X7CwC43TWuUlwfdKujKav/0sGzybLKRb5eHrIc2qrja2YqrEE99erVS3Xq1HF2qAAAoIBRaOdSt27d9NBDD2VqDw4OdkI0AABnaFY1WE2qlNBfpy/qs/kLtXjuDOnaFQX5F9Xp06c1efJkpaSk8BxtAADuMBTauVSiRAmVKFHC2WEAAJzMxcWie0r66aWe7fXUo40yvc4XsAAA3HkotAEAMAFfwAIAgAzcTAwAAAAAgIkotAEAAAAAMBGFNgAAAAAAJqLQBgAAAADARBTaAAAAAACYiEIbAAAAAAATUWgDAAAAAGAiCm0AAAAAAExEoQ0AAAAAgIkotAEAAAAAMBGFNgAAAAAAJqLQBgAAAADARBTaAAAAAACYiEIbAAAAAAATUWgDAAAAAGAiCm0AAAAAAExEoQ0AAAAAgIkotAEAAAAAMBGFNgAAAAAAJqLQBgAAAADARBTaAAAAAACYiEIbAAAAAAATUWgDAAAAAGAiCm0AAAAAAExEoQ0AAAAAgIkotAEAAAAAMBGFNgAAAAAAJnJ6oT1jxgyFhobK09NTYWFh2rZt2w3Xj46OVtWqVeXl5aVy5crppZdeUkpKSgFFCwAAAADAjbnlZKXAwEBZLJYc7TAhISHHnS9atEjDhg3Thx9+qLCwMEVHR6tly5bau3evgoODM62/YMECjRgxQnPnztUDDzygv/76S71795bFYtF7772X434BAMD/5FeeBwDgTpWjQjs6Otr273Pnzumtt95Sy5YtFR4eLknavHmzVq1apdGjRzvU+Xvvvaf+/furT58+kqQPP/xQK1as0Ny5czVixIhM62/atEmNGjVS9+7dJUmhoaF68skntXXrVof6BQAA/5NfeR4AgDuVxTAMw5ENOnbsqIiICL3wwgt27dOnT9fatWu1bNmyHO0nNTVV3t7eWrx4sdq1a2dr79WrlxITE7V8+fJM2yxYsECDBg3S6tWr1bBhQx04cECPP/64evTooddffz3Lfq5evaqrV6/alpOSklSuXDklJibKz88vR7ECAOAMSUlJCggI0IULFwosZ5mR58m9AIDCyqzcm6Mr2v+0atUqTZo0KVP7o48+muVV6OycPXtW6enpCgkJsWsPCQnRnj17styme/fuOnv2rBo3bizDMJSWlqaBAwdmW2RLUlRUlCIjIzO1Jycny9XVNcfxAgBQ0JKTkwu8TzPyPLkXAFBYmZV7HS60ixUrpuXLl+vll1+2a1++fLmKFStmSlDZiYuL04QJEzRz5kyFhYUpPj5eQ4cO1ZtvvpntcLaRI0dq2LBhtuWMb9V9fHzk4+OTr/ECAJAX6enpBd6nGXme3AsAKKzMyr0OF9qRkZF65plnFBcXp7CwMEnS1q1btXLlSs2ePTvH+ylevLhcXV116tQpu/ZTp06pZMmSWW4zevRo9ejRQ88884wkqWbNmkpOTtaAAQP0xhtvyMUl8yTqHh4e8vDwyNRusVhyPPELAADO4Iw8ZUaeJ/cCAAors/KUw4/36t27tzZu3Cg/Pz8tXbpUS5culZ+fn3766Sf17t07x/txd3dX/fr1FRsba2uzWq2KjY21Tb7yb5cvX85UTGcMQXPwVnMAAJAFs/I8AAB3MoevaEtSWFiY5s+fn+fOhw0bpl69eqlBgwZq2LChoqOjlZycbJuFvGfPnipTpoyioqIkSW3atNF7772nunXr2oaOjx49Wm3atOGeLwAATGJWngcA4E7lcKHt6uqqEydOZHrO9blz5xQcHOzQmPauXbvqzJkzGjNmjE6ePKk6depo5cqVtgnSjhw5YncFe9SoUbJYLBo1apSOHTumEiVKqE2bNnr77bcdPQwAAJAFM/M8AAB3Kocf7+Xi4qKTJ09mSsDHjx9XpUqVdOXKFVMDNFtSUpL8/f0L9FEpAADkhjNyVn7keXIvAKCwMCtn5fiK9tSpUyVdvzl8zpw58vX1tb2Wnp6uDRs26J577sl1IAAAwHnI8wAAmCfHhfb7778v6fqkYx9++KHdPdHu7u4KDQ3Vhx9+aH6EAAAg35HnAQAwT44L7YMHD0qSIiIitHTpUgUGBuZbUAAAoGCR5wEAMI/Dj/dav369XfJNT0/Xrl27dP78eVMDAwAABY88DwBA3jlcaL/44ov65JNPJF1Pvk2aNFG9evVUrlw5xcXFmR0fAAAoQOR5AADyzuFC++uvv1bt2rUlSd9++60OHTqkPXv26KWXXtIbb7xheoAAAKDgkOcBAMg7hwvtc+fOqWTJkpKk7777Tp07d9bdd9+tvn37avfu3aYHCAAACg55HgCAvHO40A4JCdEff/yh9PR0rVy5Ui1atJAkXb582W6GUgAAUPiQ5wEAyLsczzqeoU+fPurSpYtKlSoli8Wi5s2bS5K2bt3K8zUBACjkyPMAAOSdw4X2uHHjVKNGDR09elSdO3eWh4eHJMnV1VUjRowwPUAAAFBwyPMAAOSdxTAMw9lBFKSkpCT5+/vrwoUL8vPzc3Y4AABk63bJWbfLcQAAbn9m5SyH79EGAAAAAADZo9AGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYKJcF9o1a9bU0aNHbctnz57VXXfdZUpQAADAucjzAADkXq4L7UOHDunatWu25fT0dB0+fNiUoAAAgHOR5wEAyD2GjgMAAAAAYCI3R1Y+cuSI7d+GYej48eNyc7u+Cw8PD3MjAwAABYo8DwCAORwqtENDQ2WxWGQYhiSpSZMmkiSLxaLjx4/b2gEAQOFDngcAwBwODR23Wq1KT0+X1WqVj4+P4uPjbW3S9UQMAAAKJ/I8AADm4B5tAAAAAABMRKENAAAAAICJcl1oP/jgg/Ly8rItu7u72+7lAgAAhRt5HgCA3LMYd9jMJklJSfL399eFCxfk5+fn7HAAAMjW7ZKzbpfjAADc/szKWQwdBwAAAADARBTaAAAAAACYiEIbAAAAAAATUWgDAAAAAGAiCm0AAAAAAEzklpuNrFar4uPjdfr0aVmtVrvXePQHAACFG3keAIC8cbjQ3rJli7p3767Dhw/r308Gs1gsSk9PNy04AABQsMjzAADkncOF9sCBA9WgQQOtWLFCpUqVksViyY+4AACAE5DnAQDIO4cL7X379mnx4sWqXLlyfsQDAACciDwPAEDeOTwZWlhYmOLj4/MjFgAA4GTkeQAA8s7hK9qDBw/Wyy+/rJMnT6pmzZoqUqSI3eu1atUyLTgAAFCwyPMAAOSdxfj3TCc34eKS+SK4xWKRYRiFYpKUpKQk+fv768KFC/Lz83N2OAAAZMsZOSs/8jy5FwBQWJiVsxy+on3w4MFcdwYAAG5t5HkAAPLO4UK7QoUKpgYwY8YMvfvuuzp58qRq166tadOmqWHDhtmun5iYqDfeeENLly5VQkKCKlSooOjoaLVq1crUuAAAuBOZnecBALgTOVxoZ/jjjz905MgRpaam2rU/8cQTOd7HokWLNGzYMH344YcKCwtTdHS0WrZsqb179yo4ODjT+qmpqWrRooWCg4O1ePFilSlTRocPH1ZAQEBuDwMAAGTBjDwPAMCdyuFC+8CBA2rfvr12795tu2dLku05m47cu/Xee++pf//+6tOnjyTpww8/1IoVKzR37lyNGDEi0/pz585VQkKCNm3aZJucJTQ01NFDAAAA2TAzzwMAcKdyuNAeOnSoKlasqNjYWFWsWFHbtm3TuXPn9PLLL2vy5Mk53k9qaqp27NihkSNH2tpcXFzUvHlzbd68OcttvvnmG4WHh+v555/X8uXLVaJECXXv3l2vvfaaXF1ds9zm6tWrunr1qm05KSlJkmQYhhycBw4AgALljDxlRp4n9wIACiuz8pTDhfbmzZu1bt06FS9eXC4uLnJxcVHjxo0VFRWlIUOG6JdffsnRfs6ePav09HSFhITYtYeEhGjPnj1ZbnPgwAGtW7dOTz31lL777jvFx8dr0KBBunbtmsaOHZvlNlFRUYqMjMzUnpycnG1xDgDArSA5ObnA+zQjz5N7AQCFlVm51+FCOz09XUWLFpUkFS9eXMePH1fVqlVVoUIF7d2715SgsmO1WhUcHKyPP/5Yrq6uql+/vo4dO6Z3330320J75MiRGjZsmG05KSlJ5cqVk4+Pj3x8fPI1XgAA8sIZw7TNyPPkXgBAYWVW7nW40K5Ro4Z+/fVXVaxYUWFhYXrnnXfk7u6ujz/+WHfddVeO91O8eHG5urrq1KlTdu2nTp1SyZIls9ymVKlSKlKkiN234dWqVdPJkyeVmpoqd3f3TNt4eHjIw8MjU7vFYrHdbwYAwK3IGXnKjDxP7gUAFFZm5SkXRzcYNWqUrFarJGn8+PE6ePCgHnzwQX333XeaOnVqjvfj7u6u+vXrKzY21tZmtVoVGxur8PDwLLdp1KiR4uPjbf1L0l9//aVSpUplWWQDAADHmJXnAQC4k1kME+72TkhIUGBgoMPV/6JFi9SrVy999NFHatiwoaKjo/XVV19pz549CgkJUc+ePVWmTBlFRUVJko4eParq1aurV69eGjx4sPbt26e+fftqyJAheuONN3LUZ1JSkvz9/XXhwgX5+fk5fKwAABSUWyVn5TbPZ7hVjgMAgJsxK2fl+jna8fHx2r9/v5o0aaKgoKBczc7WtWtXnTlzRmPGjNHJkydVp04drVy50jZB2pEjR+Ti8r+L7uXKldOqVav00ksvqVatWipTpoyGDh2q1157LbeHAQAAsmBGngcA4E7l8BXtc+fOqUuXLlq/fr0sFov27dunu+66S3379lVgYKCmTJmSX7Gagm/VAQCFhTNyVn7keXIvAKCwMCtnOXyP9ksvvaQiRYroyJEj8vb2trV37dpVK1euzHUgAADA+cjzAADkncNDx1evXq1Vq1apbNmydu1VqlTR4cOHTQsMAAAUPPI8AAB55/AV7eTkZLtvuDMkJCRk+SgPAABQeJDnAQDIO4cL7QcffFCfffaZbdlischqteqdd95RRESEqcEBAICCRZ4HACDvHB46/s477+jhhx/W9u3blZqaqldffVX/93//p4SEBG3cuDE/YgQAAAWEPA8AQN45fEW7Ro0a+uuvv9S4cWO1bdtWycnJ6tChg3755RdVqlQpP2IEAAAFhDwPAEDeOfx4r8KOR4wAAAqL2yVn3S7HAQC4/ZmVsxweOi5JKSkp+u2333T69GlZrVa715544olcBwMAAJyPPA8AQN44XGivXLlSPXv21NmzZzO9ZrFYlJ6ebkpgAACg4JHnAQDIO4fv0R48eLA6d+6sEydOyGq12v2QfAEAKNzI8wAA5J3DhfapU6c0bNgwhYSE5Ec8AADAicjzAADkncOFdqdOnRQXF5cPoQAAAGcjzwMAkHcOzzp++fJlde7cWSVKlFDNmjVVpEgRu9eHDBliaoBmY+ZTAEBh4YyclR95ntwLACgsnDbr+JdffqnVq1fL09NTcXFxslgsttcsFsstX2gDAIDskecBAMg7hwvtN954Q5GRkRoxYoRcXBweeQ4AAG5h5HkAAPLO4Qyampqqrl27knwBALgNkecBAMg7h7Nor169tGjRovyIBQAAOBl5HgCAvHN46Hh6erreeecdrVq1SrVq1co0Scp7771nWnAAAKBgkecBAMg7hwvt3bt3q27dupKk33//3e61f06YAgAACh/yPAAAeedwob1+/fr8iAMAANwCyPMAAOQdM50AAAAAAGAiCm0AAAAAAExEoQ0AAAAAgIkotAEAAAAAMBGFNgAAAAAAJspVof3555+rUaNGKl26tA4fPixJio6O1vLly00NDgAAFDzyPAAAeeNwoT1r1iwNGzZMrVq1UmJiotLT0yVJAQEBio6ONjs+AABQgMjzAADkncOF9rRp0zR79my98cYbcnV1tbU3aNBAu3fvNjU4AABQsMjzAADkncOF9sGDB1W3bt1M7R4eHkpOTjYlKAAA4BzkeQAA8s7hQrtixYratWtXpvaVK1eqWrVqZsQEAACchDwPAEDeuTm6wbBhw/T8888rJSVFhmFo27Zt+vLLLxUVFaU5c+bkR4wAAKCAkOcBAMg7hwvtZ555Rl5eXho1apQuX76s7t27q3Tp0vrggw/UrVu3/IgRAAAUEPI8AAB5ZzEMw8jtxpcvX9alS5cUHBxsZkz5KikpSf7+/rpw4YL8/PycHQ4AANlyds4yK887+zgAAMgps3KWw1e0/8nb21ve3t552QUAALhFkecBAMgdhydDO3XqlHr06KHSpUvLzc1Nrq6udj8AAKDwIs8DAJB3Dl/R7t27t44cOaLRo0erVKlSslgs+REXAABwAvI8AAB553Ch/dNPP+nHH39UnTp18iEcAADgTOR5AADyzuGh4+XKlVMe5k8DAAC3MPI8AAB553ChHR0drREjRujQoUP5EA4AAHAm8jwAAHnncKHdtWtXxcXFqVKlSipatKiCgoLsfnJjxowZCg0Nlaenp8LCwrRt27Ycbbdw4UJZLBa1a9cuV/0CAAB7+ZHnAQC40zh8j3Z0dLSpASxatEjDhg3Thx9+qLCwMEVHR6tly5bau3fvDZ/beejQIQ0fPlwPPvigqfEAAHAnMzvPAwBwJ7IYTr4RKywsTPfdd5+mT58uSbJarSpXrpwGDx6sESNGZLlNenq6mjRpor59++rHH39UYmKili1blqP+zHoAOQAA+e12yVm3y3EAAG5/ZuWsHF3RTkpKsnWSlJR0w3UdCSY1NVU7duzQyJEjbW0uLi5q3ry5Nm/enO1248ePV3BwsPr166cff/wxx/0BAIDM8ivPAwBwp8pRoR0YGKgTJ04oODhYAQEBWT5T0zAMWSwWpaen57jzs2fPKj09XSEhIXbtISEh2rNnT5bb/PTTT/rkk0+0a9euHPVx9epVXb161bac8QeEYRjMqgoAuKUVVJ4yO8+TewEAhZVZeSpHhfa6detsE6CsX7/elI5z4+LFi+rRo4dmz56t4sWL52ibqKgoRUZGZmpPTk6Wq6ur2SECAGCa5OTkAunH7DxP7gUAFFZm5V6n3qOdmpoqb29vLV682G7m8F69eikxMVHLly+3W3/Xrl2qW7euXZK2Wq2Srg8537t3rypVqmS3TVbfqpcrV06JiYkMfwMA3NKSkpIUEBBQ6O5tJvcCAAors3Kvw7OOr1y5Ur6+vmrcuLGk64/mmj17tu69917NmDFDgYGBOd6Xu7u76tevr9jYWFuhbbVaFRsbqxdeeCHT+vfcc492795t1zZq1ChdvHhRH3zwgcqVK5dpGw8PD3l4eGRqt1gsWQ6NAwDgVuGMPGVGnif3AgAKK7PylMPP0X7llVds91rt3r1bw4YNU6tWrXTw4EENGzbM4QCGDRum2bNn69NPP9Wff/6p5557TsnJyerTp48kqWfPnrbJ0jw9PVWjRg27n4CAABUtWlQ1atSQu7u7w/0DAID/MTvPAwBwJ3L4ivbBgwd17733SpKWLFmiNm3aaMKECdq5c6datWrlcABdu3bVmTNnNGbMGJ08eVJ16tTRypUrbROkHTlyRC4uDn8fAAAAcsHsPA8AwJ3I4ULb3d1dly9fliStXbtWPXv2lCQFBQXd9JEg2XnhhReyHCouSXFxcTfcNiYmJld9AgCAzPIjzwMAcKdxuNBu3Lixhg0bpkaNGmnbtm1atGiRJOmvv/5S2bJlTQ8QAAAUHPI8AAB55/CY7OnTp8vNzU2LFy/WrFmzVKZMGUnS999/r0cffdT0AAEAQMEhzwMAkHdOfbyXMyQlJcnf37/QPSoFAHDnuV1y1u1yHACA259ZOcvhoeOSlJ6ermXLlunPP/+UJFWvXl1PPPGE3fOtAQBA4USeBwAgbxwutOPj49WqVSsdO3ZMVatWlSRFRUWpXLlyWrFihSpVqmR6kAAAoGCQ5wEAyDuH79EeMmSIKlWqpKNHj2rnzp3auXOnjhw5oooVK2rIkCH5ESMAACgg5HkAAPLO4SvaP/zwg7Zs2aKgoCBbW7FixTRx4kQ1atTI1OAAAEDBIs8DAJB3Dl/R9vDw0MWLFzO1X7p0Se7u7qYEBQAAnIM8DwBA3jlcaLdu3VoDBgzQ1q1bZRiGDMPQli1bNHDgQD3xxBP5ESMAACgg5HkAAPLO4UJ76tSpqlSpksLDw+Xp6SlPT081atRIlStX1gcffJAfMQIAgAJCngcAIO8cvkc7ICBAy5cvV3x8vO2xH9WqVVPlypVNDw4AABQs8jwAAHmXq+doS1LlypVJugAA3KbI8wAA5J7DQ8c7duyoSZMmZWp/55131LlzZ1OCAgAAzkGeBwAg7xwutDds2KBWrVplan/ssce0YcMGU4ICAADOQZ4HACDvHC60s3u8R5EiRZSUlGRKUAAAwDnI8wAA5J3DhXbNmjW1aNGiTO0LFy7Uvffea0pQAADAOcjzAADkncOToY0ePVodOnTQ/v379dBDD0mSYmNj9eWXX+rrr782PUAAAFBwyPMAAOSdw4V2mzZttGzZMk2YMEGLFy+Wl5eXatWqpbVr16pp06b5ESMAACgg5HkAAPLOYhiG4ewgClJSUpL8/f114cIF+fn5OTscAACydbvkrNvlOAAAtz+zcpbD92gDAAAAAIDsUWgDAAAAAGAiCm0AAAAAAExkaqGdlpZm5u4AAMAthDwPAEDO5LjQ/uqrr274elpamrp06ZLngAAAQMEjzwMAYJ4cF9o9e/bUmjVrsnwtPT1dXbp00ebNm00LDAAAFBzyPAAA5slxoT1p0iR16NBBW7dutWu3Wq3q0qWLNm7cqLVr15oeIAAAyH/keQAAzOOW0xWHDh2qhIQEtWrVShs2bFD16tWVnp6url276scff9S6detUvXr1/IwVAADkE/I8AADmyXGhLUmRkZFKSEjQI488ovXr12vUqFH64YcfFBsbqxo1auRXjAAAoACQ5wEAMIdDhbYkTZs2TefPn1ft2rXl6+ur2NhY1apVKz9iAwAABYw8DwBA3uW40B42bJjt34GBgTIMQ3Xq1FFMTIzdeu+9955pwQEAgIJBngcAwDw5LrR37twpi8ViWw4PD1daWpp++eUXW9s/XwcAAIUHeR4AAPPkuNCOi4vLxzAAAIAzkecBADBPjh/vddddd+ncuXP5GQsAAHAS8jwAAObJcaF96NAhpaen52csAADAScjzAACYJ8eFNgAAAAAAuDmHHu+1atUq+fv733CdJ554Ik8BAQAA5yDPAwBgDocK7V69et3wdYvFwrAzAAAKKfI8AADmcGjo+MmTJ2W1WrP9IfkCAFB4kecBADBHjgttnp0JAMDtizwPAIB5clxoG4aRn3EAAAAnIs8DAGCeHBfavXr1kpeXV74EMWPGDIWGhsrT01NhYWHatm1btuvOnj1bDz74oAIDAxUYGKjmzZvfcH0AAHBz+ZnnAQC40+S40J43b56KFi1qegCLFi3SsGHDNHbsWO3cuVO1a9dWy5Ytdfr06SzXj4uL05NPPqn169dr8+bNKleunB555BEdO3bM9NgAALhT5FeeBwDgTmQxcjhWzMXF5ab3b1ksFqWlpTkUQFhYmO677z5Nnz5dkmS1WlWuXDkNHjxYI0aMuOn26enpCgwM1PTp09WzZ8+brp+UlCR/f39duHBBfn5+DsUKAEBBKsiclV95XiL3AgAKD7NyVo4f77V06dJsE/DmzZs1depUWa1WhzpPTU3Vjh07NHLkSFubi4uLmjdvrs2bN+doH5cvX9a1a9cUFBSU5etXr17V1atXbctJSUmSrt+Lxv1oAIBbWUHmKTPzPLkXAFBYmZWnclxot2vXLlPb3r17NWLECH377bd66qmnNH78eIc6P3v2rNLT0xUSEmLXHhISoj179uRoH6+99ppKly6t5s2bZ/l6VFSUIiMjM7UnJyfL1dXVoXgBAChIycnJBdaXmXme3AsAKKzMyr05LrT/6fjx4xo7dqw+/fRTtWzZUrt27VKNGjVMCcgREydO1MKFCxUXFydPT88s1xk5cqSGDRtmW05KSlK5cuXk4+MjHx+fggoVAACHOeu51XnN8+ReAEBhZVbudajQvnDhgiZMmKBp06apTp06io2N1YMPPpjrzosXLy5XV1edOnXKrv3UqVMqWbLkDbedPHmyJk6cqLVr16pWrVrZrufh4SEPD49M7RaLhWeGAgBuaQWdp8zK8+ReAEBhZVaeyvGs4++8847uuusu/fe//9WXX36pTZs25anIliR3d3fVr19fsbGxtjar1arY2FiFh4ffMJY333xTK1euVIMGDfIUAwAAyJ88DwDAncqhWce9vLzUvHnzG95ftXTpUocCWLRokXr16qWPPvpIDRs2VHR0tL766ivt2bNHISEh6tmzp8qUKaOoqChJ0qRJkzRmzBgtWLBAjRo1su3H19dXvr6+N+2PmU8BAIVFQc86nh95XiL3AgAKjwKfdbxnz575Mtyra9euOnPmjMaMGaOTJ0+qTp06WrlypW2CtCNHjsjF5X8X3mfNmqXU1FR16tTJbj9jx47VuHHjTI8PAIA7QX7leQAA7kQ5vqJ9u+BbdQBAYXG75Kzb5TgAALc/s3JWju/RBgAAAAAAN0ehDQAAAACAiSi0AQAAAAAwEYU2AAAAAAAmotAGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYCIKbQAAAAAATEShDQAAAACAiSi0AQAAAAAwEYU2AAAAAAAmotAGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYCIKbQAAAAAATEShDQAAAACAiSi0AQAAAAAwEYU2AAAAAAAmotAGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYCIKbQAAAAAATEShDQAAAACAiSi0AQAAAAAwEYU2AAAAAAAmotAGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABNRaAMAAAAAYCIKbQAAAAAATEShDQAAAACAiSi0AQAAAAAwEYU2AAAAAAAmotAGAAAAAMBEFNoAAAAAAJiIQhsAAAAAABPdEoX2jBkzFBoaKk9PT4WFhWnbtm03XP/rr7/WPffcI09PT9WsWVPfffddAUUKAAAAAMCNOb3QXrRokYYNG6axY8dq586dql27tlq2bKnTp09nuf6mTZv05JNPql+/fvrll1/Url07tWvXTr///nsBRw4AAAAAQGYWwzAMZwYQFham++67T9OnT5ckWa1WlStXToMHD9aIESMyrd+1a1clJyfrv//9r63t/vvvV506dfThhx/etL+kpCT5+/vrwoUL8vPzM+9AAAAw2e2Ss26X4wAA3P7MylluJsbksNTUVO3YsUMjR460tbm4uKh58+bavHlzltts3rxZw4YNs2tr2bKlli1bluX6V69e1dWrV23LFy5csP3Xyd8xAABwQ0lJSZJU6PIVuRcAUFiZlXudWmifPXtW6enpCgkJsWsPCQnRnj17stzm5MmTWa5/8uTJLNePiopSZGRkpvby5cvnMmoAAArWxYsX5e/v7+wwcozcCwAo7PKae51aaBeEkSNH2l0Bt1qtSkhIULFixWSxWEzrJykpSeXKldPRo0cZFgcAd5j8ygGGYejixYsqXbq0afssCOReAEB+u9Vzr1ML7eLFi8vV1VWnTp2yaz916pRKliyZ5TYlS5Z0aH0PDw95eHjYtQUEBOQ+6Jvw8/Mj2QPAHSo/ckBhupKdgdwLACgot2rudeqs4+7u7qpfv75iY2NtbVarVbGxsQoPD89ym/DwcLv1JWnNmjXZrg8AAAAAQEFy+tDxYcOGqVevXmrQoIEaNmyo6OhoJScnq0+fPpKknj17qkyZMoqKipIkDR06VE2bNtWUKVP0+OOPa+HChdq+fbs+/vhjZx4GAAAAAACSboFCu2vXrjpz5ozGjBmjkydPqk6dOlq5cqVtwrMjR47IxeV/F94feOABLViwQKNGjdLrr7+uKlWqaNmyZapRo4azDkHS9WFyY8eOzTRUDgBw+yMHOAfvOwDcuW71HOD052gDAAAAAHA7ceo92gAAAAAA3G4otAEAAAAAMBGFNgAAAAAAJqLQvgWNGzdOderUcXYYAFDoGYahAQMGKCgoSBaLRQEBAXrxxRedHRZuQeReADAHufc6p886frvr3bu3EhMTtWzZMmeHAgB3nJUrVyomJkZxcXG666675OLiIi8vL1P74Dx/6+F3AgDOQ+69jkI7l65du6YiRYo4OwwAwA3s379fpUqV0gMPPODsUGACci8A3PrIvdfdcUPHFy9erJo1a8rLy0vFihVT8+bNlZycLEmaO3euqlevLg8PD5UqVUovvPCCbTuLxaJZs2bpiSeekI+Pj95++22lp6erX79+qlixory8vFS1alV98MEHtm3GjRunTz/9VMuXL5fFYpHFYlFcXJwk6e+//9aTTz6poKAg+fj4qEGDBtq6datdrJ9//rlCQ0Pl7++vbt266eLFi/n/BgHAbaJ3794aPHiwjhw5IovFotDQUDVr1sxu+FpoaKgmTJigvn37qmjRoipfvrw+/vhju/0cPXpUXbp0UUBAgIKCgtS2bVsdOnRIUvbn+bi4OFksFiUmJtr2s2vXLlksFtu2MTExCggI0KpVq1StWjX5+vrq0Ucf1YkTJ+z6nzNnjqpVqyZPT0/dc889mjlzZn68XfmK3AsAdwZy7z8Yd5Djx48bbm5uxnvvvWccPHjQ+O2334wZM2YYFy9eNGbOnGl4enoa0dHRxt69e41t27YZ77//vm1bSUZwcLAxd+5cY//+/cbhw4eN1NRUY8yYMcbPP/9sHDhwwPjiiy8Mb29vY9GiRYZhGMbFixeNLl26GI8++qhx4sQJ48SJE8bVq1eNixcvGnfddZfx4IMPGj/++KOxb98+Y9GiRcamTZsMwzCMsWPHGr6+vkaHDh2M3bt3Gxs2bDBKlixpvP7668542wCgUEpMTDTGjx9vlC1b1jhx4oRx+vRpo2nTpsbQoUNt61SoUMEICgoyZsyYYezbt8+IiooyXFxcjD179hiGYRipqalGtWrVjL59+xq//fab8ccffxjdu3c3qlatajufZ3WeX79+vSHJOH/+vK2vX375xZBkHDx40DAMw5g3b55RpEgRo3nz5sbPP/9s7Nixw6hWrZrRvXt32zZffPGFUapUKWPJkiXGgQMHjCVLlhhBQUFGTExMQbyFpiD3AsCdg9z7P3dUob1jxw5DknHo0KFMr5UuXdp44403st1WkvHiiy/etI/nn3/e6Nixo225V69eRtu2be3W+eijj4yiRYsa586dy3IfY8eONby9vY2kpCRb2yuvvGKEhYXdtH8AwP+8//77RoUKFWzLWSX7p59+2rZstVqN4OBgY9asWYZhGMbnn39uVK1a1bBarbZ1rl69anh5eRmrVq0yDCPr83xOk70kIz4+3rbOjBkzjJCQENtypUqVjAULFtjt+8033zTCw8Mdeh+cidwLAHcWcu91d9Q92rVr19bDDz+smjVrqmXLlnrkkUfUqVMnXbt2TcePH9fDDz98w+0bNGiQqW3GjBmaO3eujhw5oitXrig1NfWms5bu2rVLdevWVVBQULbrhIaGqmjRorblUqVK6fTp0zc+QACAw2rVqmX7t8ViUcmSJW3n219//VXx8fF252NJSklJ0f79+/Pct7e3typVqmRb/ue5Pjk5Wfv371e/fv3Uv39/2zppaWny9/fPc98FhdwLAPi3OyH33lGFtqurq9asWaNNmzZp9erVmjZtmt544w3FxsbmaHsfHx+75YULF2r48OGaMmWKwsPDVbRoUb377ruZ7vf6t5zMuvfvyV4sFousVmuO4gQA5NyNzreXLl1S/fr1NX/+/EzblShRItt9urhcnwLFMAxb27Vr13LUd8Y2ly5dkiTNnj1bYWFhduu5urpm2/ethtwLAPi3OyH33lGFtnT9jWzUqJEaNWqkMWPGqEKFClqzZo1CQ0MVGxuriIiIHO9r48aNeuCBBzRo0CBb27+/ZXF3d1d6erpdW61atTRnzhwlJCTc8Jt1AIBz1atXT4sWLVJwcLD8/PyyXCer83zGHwInTpxQYGCgpOtXVB0REhKi0qVL68CBA3rqqaccD/4WQu4FAOTU7ZJ776hZx7du3aoJEyZo+/btOnLkiJYuXaozZ86oWrVqGjdunKZMmaKpU6dq37592rlzp6ZNm3bD/VWpUkXbt2/XqlWr9Ndff2n06NH6+eef7dYJDQ3Vb7/9pr179+rs2bO6du2annzySZUsWVLt2rXTxo0bdeDAAS1ZskSbN2/Oz8MHADjoqaeeUvHixdW2bVv9+OOPOnjwoOLi4jRkyBD9/fffkrI+z1euXFnlypXTuHHjtG/fPq1YsUJTpkxxuP/IyEhFRUVp6tSp+uuvv7R7927NmzdP7733ntmHmm/IvQAAR9wuufeOKrT9/Py0YcMGtWrVSnfffbdGjRqlKVOm6LHHHlOvXr0UHR2tmTNnqnr16mrdurX27dt3w/09++yz6tChg7p27aqwsDCdO3fO7ht2Serfv7+qVq2qBg0aqESJEtq4caPc3d21evVqBQcHq1WrVqpZs6YmTpxYqIYCAsCdwNvbWxs2bFD58uXVoUMHVatWTf369VNKSortW/aszvNFihTRl19+qT179qhWrVqaNGmS3nrrLYf7f+aZZzRnzhzNmzdPNWvWVNOmTRUTE6OKFSuafaj5htwLAHDE7ZJ7LcY/B7EDAAAAAIA8uaOuaAMAAAAAkN8otAEAAAAAMBGFNgAAAAAAJqLQBgAAAADARBTaAAAAAACYiEIbAAAAAAATUWgDAAAAAGAiCm0ANqGhoYqOjnZ2GDcVExOjgIAAZ4cBAECekXuB2xOFNlAIWSyWG/6MGzcuV/v9+eefNWDAgDzF1qxZM1ksFk2cODHTa48//nie4gMAwFnIvQAcQaENFEInTpyw/URHR8vPz8+ubfjw4bZ1DcNQWlpajvZbokQJeXt75zm+cuXKKSYmxq7t2LFjio2NValSpfK8fwAAChq5F4AjKLSBQqhkyZK2H39/f1ksFtvynj17VLRoUX3//feqX7++PDw89NNPP2n//v1q27atQkJC5Ovrq/vuu09r16612++/h69ZLBbNmTNH7du3l7e3t6pUqaJvvvnmpvG1bt1aZ8+e1caNG21tn376qR555BEFBwfbrXv+/Hn17NlTgYGB8vb21mOPPaZ9+/bZrRMTE6Py5cvL29tb7du317lz5zL1uXz5ctWrV0+enp666667FBkZmeM/cgAAuBlyL7kXcASFNnCbGjFihCZOnKg///xTtWrV0qVLl9SqVSvFxsbql19+0aOPPqo2bdroyJEjN9xPZGSkunTpot9++02tWrXSU089pYSEhBtu4+7urqeeekrz5s2ztcXExKhv376Z1u3du7e2b9+ub775Rps3b5ZhGGrVqpWuXbsmSdq6dav69eunF154Qbt27VJERITeeustu338+OOP6tmzp4YOHao//vhDH330kWJiYvT222/n9O0CACDPyL3kXsDGAFCozZs3z/D397ctr1+/3pBkLFu27KbbVq9e3Zg2bZptuUKFCsb7779vW5ZkjBo1yrZ86dIlQ5Lx/fffZ7vPpk2bGkOHDjV27dplFC1a1Lh06ZLxww8/GMHBwca1a9eM2rVrG2PHjjUMwzD++usvQ5KxceNG2/Znz541vLy8jK+++sowDMN48sknjVatWtn10bVrV7tjfvjhh40JEybYrfP5558bpUqVuul7AACAo8i95F7gZtycV+IDyE8NGjSwW7506ZLGjRunFStW6MSJE0pLS9OVK1du+q16rVq1bP/28fGRn5+fTp8+fdP+a9eurSpVqmjx4sVav369evToITc3+1POn3/+KTc3N4WFhdnaihUrpqpVq+rPP/+0rdO+fXu77cLDw7Vy5Urb8q+//qqNGzfafYuenp6ulJQUXb582ZR73wAAuBlyL7kXyEChDdymfHx87JaHDx+uNWvWaPLkyapcubK8vLzUqVMnpaam3nA/RYoUsVu2WCyyWq05iqFv376aMWOG/vjjD23bts2xA3DApUuXFBkZqQ4dOmR6zdPTM9/6BQDgn8i915F7AQpt4I6xceNG9e7d2/YN9aVLl3To0KF87bN79+4aPny4ateurXvvvTfT69WqVVNaWpq2bt2qBx54QJJ07tw57d2717Z+tWrVtHXrVrvttmzZYrdcr1497d27V5UrV86nIwEAwHHkXuDORaEN3CGqVKmipUuXqk2bNrJYLBo9enSOvx3PrcDAQJ04cSLTN/P/jKlt27bq37+/PvroIxUtWlQjRoxQmTJl1LZtW0nSkCFD1KhRI02ePFlt27bVqlWr7IauSdKYMWPUunVrlS9fXp06dZKLi4t+/fVX/f7775kmbwEAoKCQe4E7F7OOA3eI9957T4GBgXrggQfUpk0btWzZUvXq1cv3fgMCAjINpfunefPmqX79+mrdurXCw8NlGIa+++472x8I999/v2bPnq0PPvhAtWvX1urVqzVq1Ci7fbRs2VL//e9/tXr1at133326//779f7776tChQr5emwAANwIuRe4c1kMwzCcHQQAAAAAALcLrmgDAAAAAGAiCm0AAAAAAExEoQ0AAAAAgIkotAEAAAAAMBGFNgAAAAAAJqLQBgAAAADARBTaAAAAAACYiEIbAAAAAAATUWgDAAAAAGAiCm0AAAAAAExEoQ0AAAAAgIkotAEAAAAAMNH/A8fdFJlOyc31AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x380 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot NTK cosine mean ± std per opt_mode, two subplots (one per task)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_ntk_mean_std(ntk_df_in, tasks=(\"mc_rtt_prepend\",\"perich_miller_population_2018/t_20130903_center_out_reaching\", \"mc_area2bump_prepend\"), order=(\"scratch\", \"finetune\")):\n",
    "    if ntk_df_in is None or len(ntk_df_in) == 0:\n",
    "        print(\"ntk_df is empty; compute it first.\")\n",
    "        return\n",
    "    df = ntk_df_in.copy()\n",
    "    palette = {\"scratch\": \"tab:orange\", \"finetune\": \"tab:blue\", \"unknown\": \"gray\"}\n",
    "\n",
    "    # Use provided mean/std columns if present; else fall back to point estimate and zero std\n",
    "    if \"ntk_cosine_mean\" not in df.columns and \"ntk_cosine_init_vs_best\" in df.columns:\n",
    "        df[\"ntk_cosine_mean\"] = df[\"ntk_cosine_init_vs_best\"].astype(float)\n",
    "    if \"ntk_cosine_std\" not in df.columns:\n",
    "        df[\"ntk_cosine_std\"] = 0.0\n",
    "\n",
    "    # Ensure types\n",
    "    df[\"opt_mode\"] = df[\"opt_mode\"].astype(str)\n",
    "    df[\"train_mode\"] = df[\"train_mode\"].astype(str).str.lower()\n",
    "\n",
    "    for om in sorted(df[\"opt_mode\"].unique()):\n",
    "        sub = df[df[\"opt_mode\"] == om]\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 3.8), sharey=True)\n",
    "        for ax, task in zip(axes, tasks):\n",
    "            g = sub[sub[\"task\"] == task].copy()\n",
    "            ax.set_title('RTT' if task == 'mc_rtt_prepend' else 'Area2Bump')\n",
    "            ax.set_xlabel(\"Train Mode\")\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.grid(True, axis=\"y\", alpha=0.15, zorder=0)\n",
    "            if g.empty:\n",
    "                continue\n",
    "            # Clip visually to [-1, 1] to avoid tiny numerical overshoots\n",
    "            means = g[\"ntk_cosine_mean\"].astype(float).clip(-1, 1).values\n",
    "            stds = g[\"ntk_cosine_std\"].astype(float).values\n",
    "            tms = g[\"train_mode\"].astype(str).values\n",
    "            # Map train_mode to x positions and add small jitter for visibility\n",
    "            x_map = {tm: i for i, tm in enumerate(order)}\n",
    "            rng = np.random.default_rng(0)\n",
    "            xs_center = np.array([x_map.get(tm, len(order)) for tm in tms], dtype=float)\n",
    "            xs = xs_center + rng.normal(0, 0.05, size=xs_center.shape)\n",
    "            colors = [palette.get(tm, \"gray\") for tm in tms]\n",
    "            # Error bars (mean ± std)\n",
    "            ax.errorbar(xs, means, yerr=stds, fmt=\"o\", ms=4, lw=1, ecolor=\"k\", elinewidth=0.8, capsize=2, color=\"k\", alpha=0.85, zorder=2)\n",
    "            # Overlay colored points at category centers for legend cues\n",
    "            ax.scatter(xs_center, means, c=colors, s=28, alpha=0.9, zorder=3)\n",
    "            ax.set_xticks(range(len(order)))\n",
    "            ax.set_xticklabels(order)\n",
    "            ax.set_ylabel(\"NTK cosine similarity\")\n",
    "        fig.suptitle(f\"NTK Cosine Similarity Bet\", fontsize=14)\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "# Run the plot for current ntk_df\n",
    "fig = plot_ntk_mean_std(ntk_df)\n",
    "WRITE_FIG_DIR = '/cs/student/projects1/ml/2024/mlaimon/UCL-ML-Thesis/Writeup/figures'\n",
    "\n",
    "fig.savefig(os.path.join(WRITE_FIG_DIR,\"ntk_cosine_mean_std_per_optmode.pdf\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dabd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2961973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>train_mode</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>finetune</th>\n",
       "      <th>scratch</th>\n",
       "      <th>delta_finetune_minus_scratch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perich_miller_population_2018/t_20130909_cente...</td>\n",
       "      <td>0.877347</td>\n",
       "      <td>0.898996</td>\n",
       "      <td>-0.021649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perich_miller_population_2018/t_20130819_cente...</td>\n",
       "      <td>0.787701</td>\n",
       "      <td>0.812708</td>\n",
       "      <td>-0.025007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perich_miller_population_2018/t_20130823_cente...</td>\n",
       "      <td>0.843992</td>\n",
       "      <td>0.874293</td>\n",
       "      <td>-0.030301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>perich_miller_population_2018/t_20130905_cente...</td>\n",
       "      <td>0.782842</td>\n",
       "      <td>0.831280</td>\n",
       "      <td>-0.048438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>perich_miller_population_2018/t_20130903_cente...</td>\n",
       "      <td>0.800289</td>\n",
       "      <td>0.856410</td>\n",
       "      <td>-0.056121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perich_miller_population_2018/t_20130821_cente...</td>\n",
       "      <td>0.826908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "train_mode                                       dataset_name  finetune  \\\n",
       "0           perich_miller_population_2018/t_20130909_cente...  0.877347   \n",
       "1           perich_miller_population_2018/t_20130819_cente...  0.787701   \n",
       "2           perich_miller_population_2018/t_20130823_cente...  0.843992   \n",
       "3           perich_miller_population_2018/t_20130905_cente...  0.782842   \n",
       "4           perich_miller_population_2018/t_20130903_cente...  0.800289   \n",
       "5           perich_miller_population_2018/t_20130821_cente...  0.826908   \n",
       "\n",
       "train_mode   scratch  delta_finetune_minus_scratch  \n",
       "0           0.898996                     -0.021649  \n",
       "1           0.812708                     -0.025007  \n",
       "2           0.874293                     -0.030301  \n",
       "3           0.831280                     -0.048438  \n",
       "4           0.856410                     -0.056121  \n",
       "5                NaN                           NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot r2 per dataset_name comparing finetune vs scratch for l2_reaching_checkpoint and task=pm_center_out\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use in-memory downstream_df if available, else try to load the saved CSV\n",
    "try:\n",
    "    df_src = downstream_df\n",
    "except NameError:\n",
    "    df_src = pd.read_csv('results/raw_downstream_performances.csv')\n",
    "\n",
    "# Filter\n",
    "_df = df_src.copy()\n",
    "_df['train_mode'] = _df['train_mode'].astype(str).str.lower()\n",
    "mask = (\n",
    "    (_df['checkpoint_short'] == 'l2_reaching_checkpoint') &\n",
    "    (_df['task'] == 'pm_center_out') &\n",
    "    (_df['opt_mode'].isin(['all']))\n",
    ")\n",
    "subset = _df.loc[mask, ['dataset_name', 'train_mode', 'r2']].dropna(subset=['dataset_name', 'r2'])\n",
    "\n",
    "# Pivot with mean aggregation in case of multiple runs per group\n",
    "pivot = pd.pivot_table(\n",
    "    subset,\n",
    "    index='dataset_name',\n",
    "    columns='train_mode',\n",
    "    values='r2',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# Ensure both columns exist and order them\n",
    "for col in ['finetune', 'scratch']:\n",
    "    if col not in pivot.columns:\n",
    "        pivot[col] = np.nan\n",
    "pivot = pivot[['finetune', 'scratch']]\n",
    "\n",
    "# Add delta column for quick comparison\n",
    "pivot['delta_finetune_minus_scratch'] = pivot['finetune'] - pivot['scratch']\n",
    "\n",
    "# Sort for readability and display\n",
    "pivot = pivot.sort_values('delta_finetune_minus_scratch', ascending=False).reset_index()\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30a7f54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "from foundational_ssm.models import SSMFoundationalDecoder\n",
    "art_epoch0 = 'melinajingting-ucl/foundational_ssm_pretrain/l2_reaching_checkpoint:epoch_0'\n",
    "art_best = 'melinajingting-ucl/foundational_ssm_pretrain/l2_reaching_checkpoint:epoch_500'\n",
    "model0, state0, _ = load_model_and_state_from_checkpoint_wandb(art_epoch0, model_cls=SSMFoundationalDecoder)\n",
    "modelB, stateB, _ = load_model_and_state_from_checkpoint_wandb(art_best, model_cls=SSMFoundationalDecoder)\n",
    "\n",
    "\n",
    "# Parameter-space distances\n",
    "p0_arr, _ = eqx.partition(model0, eqx.is_inexact_array)\n",
    "pB_arr, _ = eqx.partition(modelB, eqx.is_inexact_array)\n",
    "diff_arr = jax.tree_util.tree_map(lambda b, a: b - a, pB_arr, p0_arr)\n",
    "norm_init = _tree_l2_norm(p0_arr)\n",
    "norm_final = _tree_l2_norm(pB_arr)\n",
    "norm_diff = _tree_l2_norm(diff_arr)\n",
    "param_rel_l2 = float(norm_diff / (norm_init + 1e-12))\n",
    "param_abs_l2 = float(norm_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d70ad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005.7750244140625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# Per-leaf L2 norms for init/final/delta parameters\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def _leaf_paths_and_arrays(tree):\n",
    "    \"\"\"Return (names, arrays) for float leaves; try to use key paths if available.\"\"\"\n",
    "    names = []\n",
    "    arrays = []\n",
    "    try:\n",
    "        from jax.tree_util import tree_flatten_with_path, keystr  # newer JAX\n",
    "        pairs, _ = tree_flatten_with_path(tree)\n",
    "        for kp, leaf in pairs:\n",
    "            arr = jnp.asarray(leaf)\n",
    "            if jnp.issubdtype(arr.dtype, jnp.floating):\n",
    "                try:\n",
    "                    nm = keystr(kp)\n",
    "                except Exception:\n",
    "                    nm = str(kp)\n",
    "                names.append(nm)\n",
    "                arrays.append(arr)\n",
    "    except Exception:\n",
    "        # Fallback: plain flatten with index-based names\n",
    "        leaves = jax.tree_util.tree_leaves(tree)\n",
    "        for i, leaf in enumerate(leaves):\n",
    "            arr = jnp.asarray(leaf)\n",
    "            if jnp.issubdtype(arr.dtype, jnp.floating):\n",
    "                names.append(f\"leaf[{i}]\")\n",
    "                arrays.append(arr)\n",
    "    return names, arrays\n",
    "\n",
    "\n",
    "def compute_per_leaf_norm_table(p0_arr, pB_arr):\n",
    "    \"\"\"Build a DataFrame with per-leaf L2 norms for init/final and their difference.\n",
    "    Expects p0_arr and pB_arr to have identical pytree structure (e.g., from eqx.partition).\n",
    "    \"\"\"\n",
    "    names0, L0 = _leaf_paths_and_arrays(p0_arr)\n",
    "    namesB, LB = _leaf_paths_and_arrays(pB_arr)\n",
    "    if len(L0) != len(LB):\n",
    "        raise ValueError(f\"Mismatched number of leaves: {len(L0)} vs {len(LB)}\")\n",
    "    # If names differ but lengths match, prefer names0\n",
    "    rows = []\n",
    "    for i, (nm, a0, aB) in enumerate(zip(names0, L0, LB)):\n",
    "        d = aB - a0\n",
    "        n0 = float(jnp.sqrt(jnp.sum(a0 * a0)))\n",
    "        nB = float(jnp.sqrt(jnp.sum(aB * aB)))\n",
    "        nd = float(jnp.sqrt(jnp.sum(d * d)))\n",
    "        rel = float(nd / (n0 + 1e-12)) if n0 > 0 else np.inf\n",
    "        rows.append({\n",
    "            'idx': i,\n",
    "            'leaf': nm,\n",
    "            'shape': tuple(a0.shape),\n",
    "            'init_norm': n0,\n",
    "            'final_norm': nB,\n",
    "            'diff_norm': nd,\n",
    "            'rel_change': rel,\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7fbb3a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals — init: 1005.37, final: 1005.99, diff: 240.913, rel: 0.239626\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>leaf</th>\n",
       "      <th>shape</th>\n",
       "      <th>init_norm</th>\n",
       "      <th>final_norm</th>\n",
       "      <th>diff_norm</th>\n",
       "      <th>rel_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>.ssm_blocks[1].ssm.Lambda_re</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>168.956604</td>\n",
       "      <td>166.900909</td>\n",
       "      <td>41.725227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>.ssm_blocks[0].glu.w2.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.218109</td>\n",
       "      <td>77.363251</td>\n",
       "      <td>77.923035</td>\n",
       "      <td>8.453256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>.ssm_blocks[1].glu.w2.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.213978</td>\n",
       "      <td>66.753723</td>\n",
       "      <td>67.373550</td>\n",
       "      <td>7.312103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>.ssm_blocks[0].glu.w1.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.243192</td>\n",
       "      <td>65.004967</td>\n",
       "      <td>65.636040</td>\n",
       "      <td>7.101015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>.ssm_blocks[0].ssm.Lambda_re</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>59.352539</td>\n",
       "      <td>55.734386</td>\n",
       "      <td>13.933597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>.ssm_blocks[1].glu.w1.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.230971</td>\n",
       "      <td>51.106293</td>\n",
       "      <td>51.959572</td>\n",
       "      <td>5.628830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>.ssm_blocks[0].ssm.C</td>\n",
       "      <td>(256, 64, 2)</td>\n",
       "      <td>16.036882</td>\n",
       "      <td>38.254009</td>\n",
       "      <td>41.538425</td>\n",
       "      <td>2.590181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>.ssm_blocks[1].ssm.Lambda_im</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>708.838501</td>\n",
       "      <td>673.616821</td>\n",
       "      <td>39.415257</td>\n",
       "      <td>0.055605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>.ssm_blocks[0].ssm.B</td>\n",
       "      <td>(64, 256, 2)</td>\n",
       "      <td>11.271930</td>\n",
       "      <td>36.830017</td>\n",
       "      <td>38.468803</td>\n",
       "      <td>3.412797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>.ssm_blocks[1].ssm.B</td>\n",
       "      <td>(64, 256, 2)</td>\n",
       "      <td>11.327927</td>\n",
       "      <td>36.696239</td>\n",
       "      <td>38.331257</td>\n",
       "      <td>3.383784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>.ssm_blocks[1].ssm.C</td>\n",
       "      <td>(256, 64, 2)</td>\n",
       "      <td>15.933751</td>\n",
       "      <td>34.590973</td>\n",
       "      <td>38.108116</td>\n",
       "      <td>2.391660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>.ssm_blocks[0].ssm.D</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>15.551065</td>\n",
       "      <td>22.468735</td>\n",
       "      <td>27.957760</td>\n",
       "      <td>1.797803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>.ssm_blocks[0].ssm.Lambda_im</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>708.838501</td>\n",
       "      <td>705.916260</td>\n",
       "      <td>20.464912</td>\n",
       "      <td>0.028871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>.ssm_blocks[1].ssm.D</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>15.727285</td>\n",
       "      <td>1.219755</td>\n",
       "      <td>15.870595</td>\n",
       "      <td>1.009112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>.ssm_blocks[1].glu.w2.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.573836</td>\n",
       "      <td>10.049811</td>\n",
       "      <td>10.038828</td>\n",
       "      <td>17.494241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>.ssm_blocks[0].ssm.log_step</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>45.886635</td>\n",
       "      <td>47.833954</td>\n",
       "      <td>8.886709</td>\n",
       "      <td>0.193667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>.ssm_blocks[0].glu.w2.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.581888</td>\n",
       "      <td>7.543868</td>\n",
       "      <td>7.565376</td>\n",
       "      <td>13.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>.ssm_blocks[1].ssm.log_step</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>45.227451</td>\n",
       "      <td>46.479919</td>\n",
       "      <td>6.945665</td>\n",
       "      <td>0.153572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>.ssm_blocks[0].glu.w1.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.573033</td>\n",
       "      <td>5.157808</td>\n",
       "      <td>5.157888</td>\n",
       "      <td>9.001039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>.ssm_blocks[1].glu.w1.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.602957</td>\n",
       "      <td>3.296454</td>\n",
       "      <td>3.349164</td>\n",
       "      <td>5.554566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>23</td>\n",
       "      <td>.decoder.weight</td>\n",
       "      <td>(2, 256)</td>\n",
       "      <td>0.832183</td>\n",
       "      <td>1.168687</td>\n",
       "      <td>1.352699</td>\n",
       "      <td>1.625483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>.decoder.bias</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>0.050260</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.057112</td>\n",
       "      <td>1.136324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>.encoder.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.762446</td>\n",
       "      <td>0.762446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>.context_embedding</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>.encoder.weight</td>\n",
       "      <td>(256, 130)</td>\n",
       "      <td>9.211541</td>\n",
       "      <td>9.211541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                          leaf         shape   init_norm  final_norm  \\\n",
       "0    13  .ssm_blocks[1].ssm.Lambda_re         (64,)    4.000000  168.956604   \n",
       "1    11  .ssm_blocks[0].glu.w2.weight    (256, 256)    9.218109   77.363251   \n",
       "2    21  .ssm_blocks[1].glu.w2.weight    (256, 256)    9.213978   66.753723   \n",
       "3     9  .ssm_blocks[0].glu.w1.weight    (256, 256)    9.243192   65.004967   \n",
       "4     3  .ssm_blocks[0].ssm.Lambda_re         (64,)    4.000000   59.352539   \n",
       "5    19  .ssm_blocks[1].glu.w1.weight    (256, 256)    9.230971   51.106293   \n",
       "6     6          .ssm_blocks[0].ssm.C  (256, 64, 2)   16.036882   38.254009   \n",
       "7    14  .ssm_blocks[1].ssm.Lambda_im         (64,)  708.838501  673.616821   \n",
       "8     5          .ssm_blocks[0].ssm.B  (64, 256, 2)   11.271930   36.830017   \n",
       "9    15          .ssm_blocks[1].ssm.B  (64, 256, 2)   11.327927   36.696239   \n",
       "10   16          .ssm_blocks[1].ssm.C  (256, 64, 2)   15.933751   34.590973   \n",
       "11    7          .ssm_blocks[0].ssm.D        (256,)   15.551065   22.468735   \n",
       "12    4  .ssm_blocks[0].ssm.Lambda_im         (64,)  708.838501  705.916260   \n",
       "13   17          .ssm_blocks[1].ssm.D        (256,)   15.727285    1.219755   \n",
       "14   22    .ssm_blocks[1].glu.w2.bias        (256,)    0.573836   10.049811   \n",
       "15    8   .ssm_blocks[0].ssm.log_step       (64, 1)   45.886635   47.833954   \n",
       "16   12    .ssm_blocks[0].glu.w2.bias        (256,)    0.581888    7.543868   \n",
       "17   18   .ssm_blocks[1].ssm.log_step       (64, 1)   45.227451   46.479919   \n",
       "18   10    .ssm_blocks[0].glu.w1.bias        (256,)    0.573033    5.157808   \n",
       "19   20    .ssm_blocks[1].glu.w1.bias        (256,)    0.602957    3.296454   \n",
       "20   23               .decoder.weight      (2, 256)    0.832183    1.168687   \n",
       "21   24                 .decoder.bias          (2,)    0.050260    0.009115   \n",
       "22    2                 .encoder.bias        (256,)    0.762446    0.762446   \n",
       "23    0            .context_embedding          (0,)    0.000000    0.000000   \n",
       "24    1               .encoder.weight    (256, 130)    9.211541    9.211541   \n",
       "\n",
       "     diff_norm  rel_change  \n",
       "0   166.900909   41.725227  \n",
       "1    77.923035    8.453256  \n",
       "2    67.373550    7.312103  \n",
       "3    65.636040    7.101015  \n",
       "4    55.734386   13.933597  \n",
       "5    51.959572    5.628830  \n",
       "6    41.538425    2.590181  \n",
       "7    39.415257    0.055605  \n",
       "8    38.468803    3.412797  \n",
       "9    38.331257    3.383784  \n",
       "10   38.108116    2.391660  \n",
       "11   27.957760    1.797803  \n",
       "12   20.464912    0.028871  \n",
       "13   15.870595    1.009112  \n",
       "14   10.038828   17.494241  \n",
       "15    8.886709    0.193667  \n",
       "16    7.565376   13.001422  \n",
       "17    6.945665    0.153572  \n",
       "18    5.157888    9.001039  \n",
       "19    3.349164    5.554566  \n",
       "20    1.352699    1.625483  \n",
       "21    0.057112    1.136324  \n",
       "22    0.000000    0.000000  \n",
       "23    0.000000         inf  \n",
       "24    0.000000    0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "art_epoch0 = 'melinajingting-ucl/foundational_ssm_downstream_sweep/scratch_l2_reaching_mc_rtt_prepend_all_checkpoint:epoch_0'\n",
    "art_best = 'melinajingting-ucl/foundational_ssm_downstream_sweep/finetuned_l2_reaching_mc_rtt_prepend_all_checkpoint:epoch_0'\n",
    "model0, state0, _ = load_model_and_state_from_checkpoint_wandb(art_epoch0, model_cls=SSMDownstreamDecoder)\n",
    "modelB, stateB, _ = load_model_and_state_from_checkpoint_wandb(art_best, model_cls=SSMDownstreamDecoder)\n",
    "\n",
    "\n",
    "# Parameter-space distances\n",
    "p0_arr, _ = eqx.partition(model0, eqx.is_inexact_array)\n",
    "pB_arr, _ = eqx.partition(modelB, eqx.is_inexact_array)\n",
    "diff_arr = jax.tree_util.tree_map(lambda b, a: b - a, pB_arr, p0_arr)\n",
    "norm_init = _tree_l2_norm(p0_arr)\n",
    "norm_final = _tree_l2_norm(pB_arr)\n",
    "norm_diff = _tree_l2_norm(diff_arr)\n",
    "param_rel_l2 = float(norm_diff / (norm_init + 1e-12))\n",
    "param_abs_l2 = float(norm_diff)\n",
    "\n",
    "leaf_df = compute_per_leaf_norm_table(p0_arr, pB_arr)\n",
    "leaf_df_sorted = leaf_df.sort_values('diff_norm', ascending=False).reset_index(drop=True)\n",
    "# Print summary totals to cross-check against whole-tree norms\n",
    "print(f\"Totals — init: {norm_init:.6g}, final: {norm_final:.6g}, diff: {norm_diff:.6g}, rel: {param_rel_l2:.6g}\")\n",
    "# Show top-k leaves by change; adjust k as needed\n",
    "k = 50\n",
    "display_cols = ['idx','leaf','shape','init_norm','final_norm','diff_norm','rel_change']\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(leaf_df_sorted[display_cols].head(k))\n",
    "except Exception:\n",
    "    print(leaf_df_sorted[display_cols].head(k).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c0d9039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totals — init: 1005.78, final: 1039.91, diff: 353.186, rel: 0.351158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>leaf</th>\n",
       "      <th>shape</th>\n",
       "      <th>init_norm</th>\n",
       "      <th>final_norm</th>\n",
       "      <th>diff_norm</th>\n",
       "      <th>rel_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>.ssm_blocks[1].ssm.Lambda_re</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>168.956604</td>\n",
       "      <td>166.900909</td>\n",
       "      <td>41.725227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>.encoders[5].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.243948</td>\n",
       "      <td>120.745110</td>\n",
       "      <td>120.594513</td>\n",
       "      <td>13.045780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>.encoders[6].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.222424</td>\n",
       "      <td>119.452431</td>\n",
       "      <td>119.349434</td>\n",
       "      <td>12.941222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.encoders[0].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.227246</td>\n",
       "      <td>111.767258</td>\n",
       "      <td>111.671295</td>\n",
       "      <td>12.102343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>.encoders[3].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.225576</td>\n",
       "      <td>105.279434</td>\n",
       "      <td>105.222168</td>\n",
       "      <td>11.405484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>.encoders[2].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.236206</td>\n",
       "      <td>76.625015</td>\n",
       "      <td>76.631821</td>\n",
       "      <td>8.296894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>.ssm_blocks[0].glu.w2.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.272792</td>\n",
       "      <td>77.363251</td>\n",
       "      <td>76.324532</td>\n",
       "      <td>8.231020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>.encoders[1].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.220180</td>\n",
       "      <td>67.577545</td>\n",
       "      <td>67.503502</td>\n",
       "      <td>7.321278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>.ssm_blocks[1].glu.w2.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.263729</td>\n",
       "      <td>66.753723</td>\n",
       "      <td>66.546471</td>\n",
       "      <td>7.183551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>.ssm_blocks[0].glu.w1.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.202188</td>\n",
       "      <td>65.004967</td>\n",
       "      <td>63.515987</td>\n",
       "      <td>6.902270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>.encoders[4].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.231981</td>\n",
       "      <td>59.016392</td>\n",
       "      <td>59.213848</td>\n",
       "      <td>6.413991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>.ssm_blocks[0].ssm.Lambda_re</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>59.352539</td>\n",
       "      <td>55.734386</td>\n",
       "      <td>13.933597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>.ssm_blocks[1].glu.w1.weight</td>\n",
       "      <td>(256, 256)</td>\n",
       "      <td>9.235198</td>\n",
       "      <td>51.106293</td>\n",
       "      <td>51.196819</td>\n",
       "      <td>5.543662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>.encoders[7].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.246503</td>\n",
       "      <td>41.665657</td>\n",
       "      <td>41.560890</td>\n",
       "      <td>4.494769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>.ssm_blocks[1].ssm.Lambda_im</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>708.838501</td>\n",
       "      <td>673.616821</td>\n",
       "      <td>39.415257</td>\n",
       "      <td>0.055605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>.encoders[8].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.236485</td>\n",
       "      <td>36.896626</td>\n",
       "      <td>36.802753</td>\n",
       "      <td>3.984498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23</td>\n",
       "      <td>.ssm_blocks[0].ssm.C</td>\n",
       "      <td>(256, 64, 2)</td>\n",
       "      <td>15.944093</td>\n",
       "      <td>38.254009</td>\n",
       "      <td>35.717567</td>\n",
       "      <td>2.240176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>.ssm_blocks[1].ssm.B</td>\n",
       "      <td>(64, 256, 2)</td>\n",
       "      <td>11.302349</td>\n",
       "      <td>36.696239</td>\n",
       "      <td>35.707115</td>\n",
       "      <td>3.159265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>.ssm_blocks[1].ssm.C</td>\n",
       "      <td>(256, 64, 2)</td>\n",
       "      <td>16.001944</td>\n",
       "      <td>34.590973</td>\n",
       "      <td>34.815170</td>\n",
       "      <td>2.175684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22</td>\n",
       "      <td>.ssm_blocks[0].ssm.B</td>\n",
       "      <td>(64, 256, 2)</td>\n",
       "      <td>11.341507</td>\n",
       "      <td>36.830017</td>\n",
       "      <td>34.349930</td>\n",
       "      <td>3.028692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>.ssm_blocks[0].ssm.Lambda_im</td>\n",
       "      <td>(64,)</td>\n",
       "      <td>708.838501</td>\n",
       "      <td>705.916260</td>\n",
       "      <td>20.464912</td>\n",
       "      <td>0.028871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34</td>\n",
       "      <td>.ssm_blocks[1].ssm.D</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>15.360961</td>\n",
       "      <td>1.219755</td>\n",
       "      <td>14.324844</td>\n",
       "      <td>0.932549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>.ssm_blocks[0].ssm.D</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>16.527153</td>\n",
       "      <td>22.468735</td>\n",
       "      <td>11.672741</td>\n",
       "      <td>0.706277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39</td>\n",
       "      <td>.ssm_blocks[1].glu.w2.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.575683</td>\n",
       "      <td>10.049811</td>\n",
       "      <td>10.034254</td>\n",
       "      <td>17.430178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29</td>\n",
       "      <td>.ssm_blocks[0].glu.w2.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.599884</td>\n",
       "      <td>7.543868</td>\n",
       "      <td>7.551497</td>\n",
       "      <td>12.588252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18</td>\n",
       "      <td>.encoders[9].weight</td>\n",
       "      <td>(256, 625)</td>\n",
       "      <td>9.239593</td>\n",
       "      <td>3.481111</td>\n",
       "      <td>5.758482</td>\n",
       "      <td>0.623240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>.ssm_blocks[0].glu.w1.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.588691</td>\n",
       "      <td>5.157808</td>\n",
       "      <td>5.134376</td>\n",
       "      <td>8.721688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>37</td>\n",
       "      <td>.ssm_blocks[1].glu.w1.bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.573235</td>\n",
       "      <td>3.296454</td>\n",
       "      <td>3.262134</td>\n",
       "      <td>5.690748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>25</td>\n",
       "      <td>.ssm_blocks[0].ssm.log_step</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>46.029636</td>\n",
       "      <td>47.833954</td>\n",
       "      <td>3.241286</td>\n",
       "      <td>0.070417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>35</td>\n",
       "      <td>.ssm_blocks[1].ssm.log_step</td>\n",
       "      <td>(64, 1)</td>\n",
       "      <td>45.333878</td>\n",
       "      <td>46.479919</td>\n",
       "      <td>2.184234</td>\n",
       "      <td>0.048181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15</td>\n",
       "      <td>.encoders[7].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.370114</td>\n",
       "      <td>1.915895</td>\n",
       "      <td>1.898917</td>\n",
       "      <td>5.130629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>17</td>\n",
       "      <td>.encoders[8].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.377619</td>\n",
       "      <td>1.847092</td>\n",
       "      <td>1.815484</td>\n",
       "      <td>4.807718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>.encoders[4].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.362643</td>\n",
       "      <td>1.624743</td>\n",
       "      <td>1.664909</td>\n",
       "      <td>4.591046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13</td>\n",
       "      <td>.encoders[6].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.391585</td>\n",
       "      <td>1.618365</td>\n",
       "      <td>1.603412</td>\n",
       "      <td>4.094670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>.encoders[1].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.365585</td>\n",
       "      <td>1.513428</td>\n",
       "      <td>1.467677</td>\n",
       "      <td>4.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>11</td>\n",
       "      <td>.encoders[5].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.364774</td>\n",
       "      <td>1.440684</td>\n",
       "      <td>1.382583</td>\n",
       "      <td>3.790247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>.encoders[0].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.372244</td>\n",
       "      <td>1.424409</td>\n",
       "      <td>1.378711</td>\n",
       "      <td>3.703778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>.encoders[3].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.378843</td>\n",
       "      <td>1.343759</td>\n",
       "      <td>1.334453</td>\n",
       "      <td>3.522442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>.encoders[2].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.389135</td>\n",
       "      <td>1.343439</td>\n",
       "      <td>1.319234</td>\n",
       "      <td>3.390171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>.decoder.weight</td>\n",
       "      <td>(2, 256)</td>\n",
       "      <td>0.792687</td>\n",
       "      <td>1.168687</td>\n",
       "      <td>0.894782</td>\n",
       "      <td>1.128796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>19</td>\n",
       "      <td>.encoders[9].bias</td>\n",
       "      <td>(256,)</td>\n",
       "      <td>0.380291</td>\n",
       "      <td>0.143278</td>\n",
       "      <td>0.237012</td>\n",
       "      <td>0.623240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>.decoder.bias</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>0.039217</td>\n",
       "      <td>0.888653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                          leaf         shape   init_norm  final_norm  \\\n",
       "0    30  .ssm_blocks[1].ssm.Lambda_re         (64,)    4.000000  168.956604   \n",
       "1    10           .encoders[5].weight    (256, 625)    9.243948  120.745110   \n",
       "2    12           .encoders[6].weight    (256, 625)    9.222424  119.452431   \n",
       "3     0           .encoders[0].weight    (256, 625)    9.227246  111.767258   \n",
       "4     6           .encoders[3].weight    (256, 625)    9.225576  105.279434   \n",
       "5     4           .encoders[2].weight    (256, 625)    9.236206   76.625015   \n",
       "6    28  .ssm_blocks[0].glu.w2.weight    (256, 256)    9.272792   77.363251   \n",
       "7     2           .encoders[1].weight    (256, 625)    9.220180   67.577545   \n",
       "8    38  .ssm_blocks[1].glu.w2.weight    (256, 256)    9.263729   66.753723   \n",
       "9    26  .ssm_blocks[0].glu.w1.weight    (256, 256)    9.202188   65.004967   \n",
       "10    8           .encoders[4].weight    (256, 625)    9.231981   59.016392   \n",
       "11   20  .ssm_blocks[0].ssm.Lambda_re         (64,)    4.000000   59.352539   \n",
       "12   36  .ssm_blocks[1].glu.w1.weight    (256, 256)    9.235198   51.106293   \n",
       "13   14           .encoders[7].weight    (256, 625)    9.246503   41.665657   \n",
       "14   31  .ssm_blocks[1].ssm.Lambda_im         (64,)  708.838501  673.616821   \n",
       "15   16           .encoders[8].weight    (256, 625)    9.236485   36.896626   \n",
       "16   23          .ssm_blocks[0].ssm.C  (256, 64, 2)   15.944093   38.254009   \n",
       "17   32          .ssm_blocks[1].ssm.B  (64, 256, 2)   11.302349   36.696239   \n",
       "18   33          .ssm_blocks[1].ssm.C  (256, 64, 2)   16.001944   34.590973   \n",
       "19   22          .ssm_blocks[0].ssm.B  (64, 256, 2)   11.341507   36.830017   \n",
       "20   21  .ssm_blocks[0].ssm.Lambda_im         (64,)  708.838501  705.916260   \n",
       "21   34          .ssm_blocks[1].ssm.D        (256,)   15.360961    1.219755   \n",
       "22   24          .ssm_blocks[0].ssm.D        (256,)   16.527153   22.468735   \n",
       "23   39    .ssm_blocks[1].glu.w2.bias        (256,)    0.575683   10.049811   \n",
       "24   29    .ssm_blocks[0].glu.w2.bias        (256,)    0.599884    7.543868   \n",
       "25   18           .encoders[9].weight    (256, 625)    9.239593    3.481111   \n",
       "26   27    .ssm_blocks[0].glu.w1.bias        (256,)    0.588691    5.157808   \n",
       "27   37    .ssm_blocks[1].glu.w1.bias        (256,)    0.573235    3.296454   \n",
       "28   25   .ssm_blocks[0].ssm.log_step       (64, 1)   46.029636   47.833954   \n",
       "29   35   .ssm_blocks[1].ssm.log_step       (64, 1)   45.333878   46.479919   \n",
       "30   15             .encoders[7].bias        (256,)    0.370114    1.915895   \n",
       "31   17             .encoders[8].bias        (256,)    0.377619    1.847092   \n",
       "32    9             .encoders[4].bias        (256,)    0.362643    1.624743   \n",
       "33   13             .encoders[6].bias        (256,)    0.391585    1.618365   \n",
       "34    3             .encoders[1].bias        (256,)    0.365585    1.513428   \n",
       "35   11             .encoders[5].bias        (256,)    0.364774    1.440684   \n",
       "36    1             .encoders[0].bias        (256,)    0.372244    1.424409   \n",
       "37    7             .encoders[3].bias        (256,)    0.378843    1.343759   \n",
       "38    5             .encoders[2].bias        (256,)    0.389135    1.343439   \n",
       "39   40               .decoder.weight      (2, 256)    0.792687    1.168687   \n",
       "40   19             .encoders[9].bias        (256,)    0.380291    0.143278   \n",
       "41   41                 .decoder.bias          (2,)    0.044131    0.009115   \n",
       "\n",
       "     diff_norm  rel_change  \n",
       "0   166.900909   41.725227  \n",
       "1   120.594513   13.045780  \n",
       "2   119.349434   12.941222  \n",
       "3   111.671295   12.102343  \n",
       "4   105.222168   11.405484  \n",
       "5    76.631821    8.296894  \n",
       "6    76.324532    8.231020  \n",
       "7    67.503502    7.321278  \n",
       "8    66.546471    7.183551  \n",
       "9    63.515987    6.902270  \n",
       "10   59.213848    6.413991  \n",
       "11   55.734386   13.933597  \n",
       "12   51.196819    5.543662  \n",
       "13   41.560890    4.494769  \n",
       "14   39.415257    0.055605  \n",
       "15   36.802753    3.984498  \n",
       "16   35.717567    2.240176  \n",
       "17   35.707115    3.159265  \n",
       "18   34.815170    2.175684  \n",
       "19   34.349930    3.028692  \n",
       "20   20.464912    0.028871  \n",
       "21   14.324844    0.932549  \n",
       "22   11.672741    0.706277  \n",
       "23   10.034254   17.430178  \n",
       "24    7.551497   12.588252  \n",
       "25    5.758482    0.623240  \n",
       "26    5.134376    8.721688  \n",
       "27    3.262134    5.690748  \n",
       "28    3.241286    0.070417  \n",
       "29    2.184234    0.048181  \n",
       "30    1.898917    5.130629  \n",
       "31    1.815484    4.807718  \n",
       "32    1.664909    4.591046  \n",
       "33    1.603412    4.094670  \n",
       "34    1.467677    4.014600  \n",
       "35    1.382583    3.790247  \n",
       "36    1.378711    3.703778  \n",
       "37    1.334453    3.522442  \n",
       "38    1.319234    3.390171  \n",
       "39    0.894782    1.128796  \n",
       "40    0.237012    0.623240  \n",
       "41    0.039217    0.888653  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from foundational_ssm.models import SSMFoundationalDecoder\n",
    "art_epoch0 = 'melinajingting-ucl/foundational_ssm_pretrain/l2_reaching_checkpoint:epoch_0'\n",
    "art_best = 'melinajingting-ucl/foundational_ssm_pretrain/l2_reaching_checkpoint:epoch_500'\n",
    "model0, state0, _ = load_model_and_state_from_checkpoint_wandb(art_epoch0, model_cls=SSMFoundationalDecoder)\n",
    "modelB, stateB, _ = load_model_and_state_from_checkpoint_wandb(art_best, model_cls=SSMFoundationalDecoder)\n",
    "\n",
    "\n",
    "# Parameter-space distances\n",
    "p0_arr, _ = eqx.partition(model0, eqx.is_inexact_array)\n",
    "pB_arr, _ = eqx.partition(modelB, eqx.is_inexact_array)\n",
    "diff_arr = jax.tree_util.tree_map(lambda b, a: b - a, pB_arr, p0_arr)\n",
    "norm_init = _tree_l2_norm(p0_arr)\n",
    "norm_final = _tree_l2_norm(pB_arr)\n",
    "norm_diff = _tree_l2_norm(diff_arr)\n",
    "param_rel_l2 = float(norm_diff / (norm_init + 1e-12))\n",
    "param_abs_l2 = float(norm_diff)\n",
    "\n",
    "leaf_df = compute_per_leaf_norm_table(p0_arr, pB_arr)\n",
    "leaf_df_sorted = leaf_df.sort_values('diff_norm', ascending=False).reset_index(drop=True)\n",
    "# Print summary totals to cross-check against whole-tree norms\n",
    "print(f\"Totals — init: {norm_init:.6g}, final: {norm_final:.6g}, diff: {norm_diff:.6g}, rel: {param_rel_l2:.6g}\")\n",
    "# Show top-k leaves by change; adjust k as needed\n",
    "k = 50\n",
    "display_cols = ['idx','leaf','shape','init_norm','final_norm','diff_norm','rel_change']\n",
    "display(leaf_df_sorted[display_cols].head(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e0130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
