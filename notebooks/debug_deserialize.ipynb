{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610d9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools as ft\n",
    "import pathlib\n",
    "from collections.abc import Callable\n",
    "from contextlib import contextmanager\n",
    "from typing import Any, BinaryIO\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as jtu\n",
    "import numpy as np\n",
    "from jaxtyping import PyTree\n",
    "import equinox as eqx\n",
    "\n",
    "\n",
    "\n",
    "class TreePathError(RuntimeError):\n",
    "    path: tuple\n",
    "\n",
    "\n",
    "def _ordered_tree_map(\n",
    "    f: Callable[..., Any],\n",
    "    tree: Any,\n",
    "    *rest: Any,\n",
    "    is_leaf: Callable[[Any], bool] | None = None,\n",
    ") -> Any:\n",
    "    \"\"\"Like jax.tree_util.tree_map, but guaranteed to iterate over the tree\n",
    "    in fixed order. (Namely depth-first left-to-right.)\n",
    "    \"\"\"\n",
    "    # Discussion: https://github.com/patrick-kidger/equinox/issues/136\n",
    "    paths_and_leaves, treedef = jtu.tree_flatten_with_path(tree, is_leaf)\n",
    "    all_leaves = list(zip(*paths_and_leaves)) + [treedef.flatten_up_to(r) for r in rest]\n",
    "\n",
    "    @ft.wraps(f)\n",
    "    def _f(path, *xs):\n",
    "        try:\n",
    "            return f(*xs)\n",
    "        except TreePathError as e:\n",
    "            combo_path = path + e.path\n",
    "            exc = TreePathError(f\"Error at leaf with path {combo_path}\")\n",
    "            exc.path = combo_path\n",
    "            raise exc from e\n",
    "        except Exception as e:\n",
    "            exc = TreePathError(f\"Error at leaf with path {path}\")\n",
    "            exc.path = path\n",
    "            raise exc from e\n",
    "\n",
    "    return treedef.unflatten(_f(*xs) for xs in zip(*all_leaves))\n",
    "\n",
    "\n",
    "def _with_suffix(path):\n",
    "    path = pathlib.Path(path)\n",
    "    if path.suffix == \"\":\n",
    "        return path.with_suffix(\".eqx\")\n",
    "    else:\n",
    "        return path\n",
    "    \n",
    "def default_deserialise_filter_spec(f: BinaryIO, x: Any) -> Any:\n",
    "    \"\"\"Default filter specification for deserialising saved data.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "    -   `f`: file-like object\n",
    "    -   `x`: The leaf for which the data needs to be loaded.\n",
    "\n",
    "    **Returns**\n",
    "\n",
    "    The new value for datatype `x`.\n",
    "\n",
    "    !!! info\n",
    "\n",
    "        This function can be extended to customise the deserialisation behaviour for\n",
    "        leaves.\n",
    "\n",
    "    !!! example\n",
    "\n",
    "        Skipping loading of jax.Array.\n",
    "\n",
    "        ```python\n",
    "        import jax.numpy as jnp\n",
    "        import equinox as eqx\n",
    "\n",
    "        tree = (jnp.array([4,5,6]), [1,2,3])\n",
    "        new_filter_spec = lambda f,x: (\n",
    "            x if isinstance(x, jax.Array) else eqx.default_deserialise_filter_spec(f, x)\n",
    "        )\n",
    "        new_tree = eqx.tree_deserialise_leaves(\"some_filename.eqx\", tree, filter_spec=new_filter_spec)\n",
    "        ```\n",
    "    \"\"\"  # noqa: E501\n",
    "    # try:\n",
    "    if isinstance(x, (jax.Array, jax.ShapeDtypeStruct)):\n",
    "        return jnp.load(f)\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        # Important to use `np` here to avoid promoting NumPy arrays to JAX.\n",
    "        return np.load(f)\n",
    "    elif eqx.is_array_like(x):\n",
    "        # np.generic gets deserialised directly as an array, so convert back to a scalar\n",
    "        # type here.\n",
    "        # See also https://github.com/google/jax/issues/17858\n",
    "        out = np.load(f)\n",
    "        if isinstance(x, jax.dtypes.bfloat16):\n",
    "            out = out.view(jax.dtypes.bfloat16)\n",
    "        if np.size(out) == 1:\n",
    "            return type(x)(out.item())\n",
    "    else:\n",
    "        return x\n",
    "    # except:\n",
    "    #     print(\"Failed to load data for leaf with shape/ value:\", x.shape if hasattr(x, 'shape') else x)\n",
    "    #     return x \n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def _maybe_open(path_or_file: str | pathlib.Path | BinaryIO, mode: str):\n",
    "    \"\"\"A function that unifies handling of file objects and path-like objects\n",
    "    by opening the latter.\"\"\"\n",
    "    if isinstance(path_or_file, (str, pathlib.Path)):\n",
    "        file = open(_with_suffix(path_or_file), mode)\n",
    "        try:\n",
    "            yield file\n",
    "        finally:\n",
    "            file.close()\n",
    "    else:  # file-like object\n",
    "        yield path_or_file\n",
    "\n",
    "\n",
    "def _assert_same(array_impl_type):\n",
    "    def _assert_same_impl(path, new, old):\n",
    "        typenew = type(new)\n",
    "        typeold = type(old)\n",
    "        if typeold is jax.ShapeDtypeStruct:\n",
    "            typeold = array_impl_type\n",
    "        if typenew is not typeold:\n",
    "            raise RuntimeError(\n",
    "                f\"Deserialised leaf at path '{jtu.keystr(path)}' has changed type from \"\n",
    "                f\"{type(old)} in `like` to {type(new)} on disk.\"\n",
    "            )\n",
    "        if isinstance(new, (np.ndarray, jax.Array)):\n",
    "            if new.shape != old.shape:\n",
    "                raise RuntimeError(\n",
    "                    f\"Deserialised leaf at path {path} has changed shape from \"\n",
    "                    f\"{old.shape} in `like` to {new.shape} on disk.\"\n",
    "                )\n",
    "            if new.dtype != old.dtype:\n",
    "                raise RuntimeError(\n",
    "                    f\"Deserialised leaf at path {path} has changed dtype from \"\n",
    "                    f\"{old.dtype} in `like` to {new.dtype} on disk.\"\n",
    "                )\n",
    "\n",
    "    return _assert_same_impl\n",
    "\n",
    "def tree_deserialise_leaves(\n",
    "    path_or_file: str | pathlib.Path | BinaryIO,\n",
    "    like: PyTree,\n",
    "    filter_spec=default_deserialise_filter_spec,\n",
    "    is_leaf: Callable[[Any], bool] | None = None,\n",
    ") -> PyTree:\n",
    "    \"\"\"Load the leaves of a PyTree from a file.\n",
    "\n",
    "    **Arguments:**\n",
    "\n",
    "    - `path_or_file`: The file location to load values from or a binary file-like\n",
    "        object.\n",
    "    - `like`: A PyTree of same structure, and with leaves of the same type, as the\n",
    "        PyTree being loaded. Those leaves which are loaded will replace the\n",
    "        corresponding leaves of `like`.\n",
    "    - `filter_spec`: Specifies how to load each kind of leaf. By default all JAX\n",
    "        arrays, NumPy arrays, Python bool/int/float/complexes are loaded, and\n",
    "        all other leaf types are not loaded, and will retain their\n",
    "        value from `like`. (See [`equinox.default_deserialise_filter_spec`][].)\n",
    "    - `is_leaf`: Called on every node of `like`; if `True` then this node will be\n",
    "        treated as a leaf.\n",
    "\n",
    "    **Returns:**\n",
    "\n",
    "    The loaded PyTree, formed by iterating over `like` and replacing some of its leaves\n",
    "    with the leaves saved in `path`.\n",
    "\n",
    "    !!! example\n",
    "\n",
    "        This can be used to load a model from file.\n",
    "\n",
    "        ```python\n",
    "        import equinox as eqx\n",
    "        import jax.random as jr\n",
    "\n",
    "        model_original = eqx.nn.MLP(2, 2, 2, 2, key=jr.PRNGKey(0))\n",
    "        eqx.tree_serialise_leaves(\"some_filename.eqx\", model_original)\n",
    "        model_loaded = eqx.tree_deserialise_leaves(\"some_filename.eqx\", model_original)\n",
    "\n",
    "        # To partially load weights, do model surgery. In this case load everything\n",
    "        # except the final layer.\n",
    "        model_partial = eqx.tree_at(lambda mlp: mlp.layers[-1], model_loaded, model_original)\n",
    "        ```\n",
    "\n",
    "    !!! example\n",
    "\n",
    "        A common pattern is the following:\n",
    "\n",
    "        ```python\n",
    "        def run(..., load_path=None):\n",
    "            if load_path is None:\n",
    "                model = Model(...hyperparameters...)\n",
    "            else:\n",
    "                model = eqx.filter_eval_shape(Model, ...hyperparameters...)\n",
    "                model = eqx.tree_deserialise_leaves(load_path, model)\n",
    "        ```\n",
    "        in which either a model is created directly (e.g. at the start of training), or\n",
    "        a suitable `like` is constructed (e.g. when resuming training), where\n",
    "        [`equinox.filter_eval_shape`][] is used to avoid creating spurious short-lived\n",
    "        arrays taking up memory.\n",
    "\n",
    "    !!! info\n",
    "\n",
    "        `filter_spec` should typically be a function `(File, Any) -> Any`, which takes\n",
    "        a file handle and a leaf from `like`, and either returns the corresponding\n",
    "        loaded leaf, or returns the leaf from `like` unchanged.\n",
    "\n",
    "        It can also be a PyTree of such functions, in which case the PyTree structure\n",
    "        should be a prefix of `pytree`, and each function will be mapped over the\n",
    "        corresponding sub-PyTree of `pytree`.\n",
    "    \"\"\"  # noqa: E501\n",
    "    with _maybe_open(path_or_file, \"rb\") as f:\n",
    "\n",
    "        def _deserialise(spec, x):\n",
    "            def __deserialise(y):\n",
    "                return spec(f, y)\n",
    "\n",
    "            return _ordered_tree_map(__deserialise, x, is_leaf=is_leaf)\n",
    "\n",
    "        out = _ordered_tree_map(_deserialise, filter_spec, like)\n",
    "    with jax.ensure_compile_time_eval():\n",
    "        # ArrayImpl isn't a public type, so this is how we get access to it instead.\n",
    "        # `ensure_compile_time_eval` just in case someone is doing deserialisation\n",
    "        # inside JIT. Which would be weird, but still.\n",
    "        array_impl_type = type(jnp.array(0))\n",
    "    jtu.tree_map_with_path(_assert_same(array_impl_type), out, like, is_leaf=is_leaf)\n",
    "    return out\n",
    "\n",
    "\n",
    "def file_to_tree(\n",
    "    path_or_file: str | pathlib.Path | BinaryIO,\n",
    "    like: PyTree,\n",
    "    filter_spec=default_deserialise_filter_spec,\n",
    "    is_leaf: Callable[[Any], bool] | None = None,\n",
    ") -> PyTree:\n",
    "    \"\"\"\n",
    "    \"\"\"  # noqa: E501\n",
    "    with _maybe_open(path_or_file, \"rb\") as f:\n",
    "\n",
    "        def _deserialise(spec, x):\n",
    "            def __deserialise(y):\n",
    "                return spec(f, y)\n",
    "\n",
    "            return _ordered_tree_map(__deserialise, x, is_leaf=is_leaf)\n",
    "\n",
    "        out = _ordered_tree_map(_deserialise, filter_spec, like)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312a56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import equinox as eqx\n",
    "import os \n",
    "\n",
    "# Foundational SSM imports\n",
    "from omegaconf import OmegaConf\n",
    "import tempfile \n",
    "from foundational_ssm.models import SSMDownstreamDecoder, SSMFoundationalDecoder\n",
    "from foundational_ssm.utils import h5_to_dict\n",
    "from foundational_ssm.transform import smooth_spikes\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from typing import Any, BinaryIO\n",
    "\n",
    "\n",
    "def load_model_and_state_from_checkpoint_wandb(artifact_full_name, model_cls=SSMFoundationalDecoder, model_cfg=None):\n",
    "    \"\"\"Load model, optimizer state, epoch, and step from a checkpoint file.\"\"\"\n",
    "    api = wandb.Api()\n",
    "    try:\n",
    "        artifact = api.artifact(artifact_full_name, type=\"checkpoint\")\n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError(f\"Could not find checkpoint artifact: {artifact_full_name}\")\n",
    "    \n",
    "    if model_cfg is None:\n",
    "        run = artifact.logged_by()\n",
    "        run_cfg = OmegaConf.create(run.config)\n",
    "        print(run_cfg)\n",
    "        model_cfg = OmegaConf.create(run_cfg.model)\n",
    "    \n",
    "    model_template, state_template = eqx.nn.make_with_state(model_cls)(\n",
    "        **model_cfg\n",
    "    )\n",
    "    model_template = eqx.nn.inference_mode(model_template, False)\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        artifact.download(temp_dir)\n",
    "        model = eqx.tree_deserialise_leaves(os.path.join(temp_dir, \"model.ckpt\"), model_template, default_deserialise_filter_spec)\n",
    "        state = eqx.tree_deserialise_leaves(os.path.join(temp_dir, \"state.ckpt\"), state_template, default_deserialise_filter_spec)\n",
    "\n",
    "    meta = artifact.metadata\n",
    "    return model, state, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff12501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'dt_max': 0.01, 'dt_min': 0.001, 'ssm_dim': 128, 'rng_seed': 42, 'dropout_p': 0.01, 'output_dim': 2, 'ssm_io_dim': 512, 'ssm_num_layers': 4, 'ssm_init_diag_blocks': 4}, 'wandb': {'tags': ['neural', 'behavior', 'masking'], 'entity': 'melinajingting-ucl', 'project': 'foundational_ssm_pretrain', 'resume_run_id': None, 'run_name_postfix': '_normalized'}, 'rng_seed': 42, 'training': {'epochs': 1001, 'log_val_every': 50, 'checkpoint_every': 1}, 'model_cfg': 'configs/model/l4.yaml', 'optimizer': {'lr': 0.001, 'mode': 'all', 'weight_decay': 0.01}, 'val_loader': {'sampler': 'SequentialFixedWindowSampler', 'dataset_args': {'lazy': True, 'split': 'val', 'keep_files_open': False}, 'sampler_args': {'drop_short': False, 'window_length': 3.28, 'min_window_length': 0.88}, 'sampling_rate': 200, 'dataloader_args': {'batch_size': 1024, 'num_workers': 0, 'persistent_workers': False}}, 'dataset_cfg': 'configs/dataset/reaching.yaml', 'train_loader': {'sampler': 'RandomFixedWindowSampler', 'dataset_args': {'lazy': True, 'split': 'train', 'keep_files_open': False}, 'sampler_args': {'drop_short': False, 'window_length': 3.28, 'min_window_length': 0.88}, 'sampling_rate': 200, 'dataloader_args': {'batch_size': 512, 'num_workers': 24, 'persistent_workers': True}}, 'skip_timesteps': 56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact l4_reaching_normalized_checkpoint:best, 66.53MB. 3 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
      "Done. 0:0:0.4 (181.4MB/s)\n"
     ]
    }
   ],
   "source": [
    "artifact_full_name = f\"melinajingting-ucl/foundational_ssm_pretrain/l4_reaching_normalized_checkpoint:best\"\n",
    "\n",
    "api = wandb.Api()\n",
    "try:\n",
    "    artifact = api.artifact(artifact_full_name, type=\"checkpoint\")\n",
    "except Exception as e:\n",
    "    raise FileNotFoundError(f\"Could not find checkpoint artifact: {artifact_full_name}\")\n",
    "\n",
    "run = artifact.logged_by()\n",
    "run_cfg = OmegaConf.create(run.config)\n",
    "print(run_cfg)\n",
    "model_cfg = OmegaConf.create(run_cfg.model)\n",
    "\n",
    "model_template, state_template = eqx.nn.make_with_state(SSMFoundationalDecoder)(\n",
    "    **model_cfg\n",
    ")\n",
    "model_template = eqx.nn.inference_mode(model_template, False)\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    artifact.download(temp_dir)\n",
    "    out = file_to_tree(os.path.join(temp_dir, \"model.ckpt\"), model_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f463bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSMFoundationalDecoder(\n",
       "  context_embedding=Embedding(\n",
       "    num_embeddings=12, embedding_size=4, weight=f32[10,4]\n",
       "  ),\n",
       "  encoders=[\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[508,625],\n",
       "      bias=f32[508],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=f32[],\n",
       "      bias=bool[],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    Linear(\n",
       "      weight=bool[],\n",
       "      bias=f32[64],\n",
       "      in_features=625,\n",
       "      out_features=508,\n",
       "      use_bias=True\n",
       "    )\n",
       "  ],\n",
       "  encoder_dropout=Dropout(p=None, inference=None),\n",
       "  ssm_blocks=[\n",
       "    S5Block(\n",
       "      norm=BatchNorm(\n",
       "        weight=None,\n",
       "        bias=None,\n",
       "        ema_first_time_index=None,\n",
       "        ema_state_index=None,\n",
       "        batch_counter=StateIndex(marker=0, init=_Sentinel()),\n",
       "        batch_state_index=StateIndex(marker=1, init=_Sentinel()),\n",
       "        axis_name='batch',\n",
       "        inference=None,\n",
       "        input_size=512,\n",
       "        eps=1e-05,\n",
       "        channelwise_affine=False,\n",
       "        momentum=0.99,\n",
       "        mode='batch'\n",
       "      ),\n",
       "      ssm=S5Layer(\n",
       "        Lambda_re=f32[512],\n",
       "        Lambda_im=f32[64,1],\n",
       "        B=i32[],\n",
       "        C=i32[],\n",
       "        D=bool[],\n",
       "        log_step=bool[],\n",
       "        H=1,\n",
       "        P=None,\n",
       "        conj_sym=None,\n",
       "        clip_eigs=None,\n",
       "        step_rescale=None\n",
       "      ),\n",
       "      glu=GLU(\n",
       "        w1=Linear(\n",
       "          weight=f32[],\n",
       "          bias=bool[],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        ),\n",
       "        w2=Linear(\n",
       "          weight=bool[],\n",
       "          bias=f32[64],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        )\n",
       "      ),\n",
       "      drop=Dropout(p=None, inference=None)\n",
       "    ),\n",
       "    S5Block(\n",
       "      norm=BatchNorm(\n",
       "        weight=None,\n",
       "        bias=None,\n",
       "        ema_first_time_index=None,\n",
       "        ema_state_index=None,\n",
       "        batch_counter=StateIndex(marker=2, init=_Sentinel()),\n",
       "        batch_state_index=StateIndex(marker=3, init=_Sentinel()),\n",
       "        axis_name='batch',\n",
       "        inference=None,\n",
       "        input_size=512,\n",
       "        eps=1e-05,\n",
       "        channelwise_affine=False,\n",
       "        momentum=0.99,\n",
       "        mode='batch'\n",
       "      ),\n",
       "      ssm=S5Layer(\n",
       "        Lambda_re=f32[512],\n",
       "        Lambda_im=f32[64,1],\n",
       "        B=i32[],\n",
       "        C=i32[],\n",
       "        D=bool[],\n",
       "        log_step=bool[],\n",
       "        H=1,\n",
       "        P=None,\n",
       "        conj_sym=None,\n",
       "        clip_eigs=None,\n",
       "        step_rescale=None\n",
       "      ),\n",
       "      glu=GLU(\n",
       "        w1=Linear(\n",
       "          weight=f32[],\n",
       "          bias=bool[],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        ),\n",
       "        w2=Linear(\n",
       "          weight=bool[],\n",
       "          bias=f32[64],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        )\n",
       "      ),\n",
       "      drop=Dropout(p=None, inference=None)\n",
       "    ),\n",
       "    S5Block(\n",
       "      norm=BatchNorm(\n",
       "        weight=None,\n",
       "        bias=None,\n",
       "        ema_first_time_index=None,\n",
       "        ema_state_index=None,\n",
       "        batch_counter=StateIndex(marker=4, init=_Sentinel()),\n",
       "        batch_state_index=StateIndex(marker=5, init=_Sentinel()),\n",
       "        axis_name='batch',\n",
       "        inference=None,\n",
       "        input_size=512,\n",
       "        eps=1e-05,\n",
       "        channelwise_affine=False,\n",
       "        momentum=0.99,\n",
       "        mode='batch'\n",
       "      ),\n",
       "      ssm=S5Layer(\n",
       "        Lambda_re=f32[512],\n",
       "        Lambda_im=f32[64,1],\n",
       "        B=i32[],\n",
       "        C=i32[],\n",
       "        D=bool[],\n",
       "        log_step=bool[],\n",
       "        H=1,\n",
       "        P=None,\n",
       "        conj_sym=None,\n",
       "        clip_eigs=None,\n",
       "        step_rescale=None\n",
       "      ),\n",
       "      glu=GLU(\n",
       "        w1=Linear(\n",
       "          weight=f32[],\n",
       "          bias=bool[],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        ),\n",
       "        w2=Linear(\n",
       "          weight=bool[],\n",
       "          bias=f32[64],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        )\n",
       "      ),\n",
       "      drop=Dropout(p=None, inference=None)\n",
       "    ),\n",
       "    S5Block(\n",
       "      norm=BatchNorm(\n",
       "        weight=None,\n",
       "        bias=None,\n",
       "        ema_first_time_index=None,\n",
       "        ema_state_index=None,\n",
       "        batch_counter=StateIndex(marker=6, init=_Sentinel()),\n",
       "        batch_state_index=StateIndex(marker=7, init=_Sentinel()),\n",
       "        axis_name='batch',\n",
       "        inference=None,\n",
       "        input_size=512,\n",
       "        eps=1e-05,\n",
       "        channelwise_affine=False,\n",
       "        momentum=0.99,\n",
       "        mode='batch'\n",
       "      ),\n",
       "      ssm=S5Layer(\n",
       "        Lambda_re=f32[512],\n",
       "        Lambda_im=f32[64,1],\n",
       "        B=i32[],\n",
       "        C=i32[],\n",
       "        D=bool[],\n",
       "        log_step=bool[],\n",
       "        H=1,\n",
       "        P=None,\n",
       "        conj_sym=None,\n",
       "        clip_eigs=None,\n",
       "        step_rescale=None\n",
       "      ),\n",
       "      glu=GLU(\n",
       "        w1=Linear(\n",
       "          weight=f32[],\n",
       "          bias=bool[],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        ),\n",
       "        w2=Linear(\n",
       "          weight=f32[2,512],\n",
       "          bias=f32[2],\n",
       "          in_features=512,\n",
       "          out_features=512,\n",
       "          use_bias=True\n",
       "        )\n",
       "      ),\n",
       "      drop=Dropout(p=0.01, inference=False)\n",
       "    )\n",
       "  ],\n",
       "  decoder=Linear(\n",
       "    weight=f32[2,512],\n",
       "    bias=f32[2],\n",
       "    in_features=512,\n",
       "    out_features=2,\n",
       "    use_bias=True\n",
       "  ),\n",
       "  decoder_dropout=Dropout(p=0.01, inference=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ffd62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundational_ssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
